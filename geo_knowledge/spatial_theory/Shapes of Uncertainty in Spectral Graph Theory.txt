SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
1
Shapes of Uncertainty in Spectral Graph Theory
Wolfgang Erb
!
Abstract
We present a ﬂexible framework for uncertainty principles in spectral graph theory. In this framework, general ﬁlter
functions modeling the spatial and spectral localization of a graph signal can be incorporated. It merges several existing
uncertainty relations on graphs, among others the Landau-Pollak principle describing the joint admissibility region of two
projection operators, and uncertainty relations based on spectral and spatial spreads. Using theoretical and computational
aspects of the numerical range of matrices, we are able to characterize and illustrate the shapes of the uncertainty curves
and to study the space-frequency localization of signals inside the admissibility regions.
Keywords
Uncertainty principle, spectral graph theory, numerical range of matrices, space-frequency analysis of signals on graphs
1
Introduction
U
ncertainty principles are important cornerstones in signal analysis. They describe inherent
limitations of a signal to be localized simultaneously in a complementary pair of domains, usually
referred to as space and frequency (or spectral) domains. Uncertainty relations can be formulated in
a multitude of ways. Exemplarily, the ﬁrst uncertainty principle discovered by Heisenberg [15] can
be written in terms of a commutator relation of a position with a momentum operator. In other
contexts, uncertainty relations are described in terms of inequalities, by the space-frequency support
or the smoothness of functions, or in form of boundary curves for an uncertainty region. A survey
on diﬀerent description possibilities can be found in [11], a wider theory is given in [14].
In signal processing on graphs, uncertainty relations play a crucial role as well. They are used to
describe the limitations of space-frequency localization [1, 35], to study sampling properties on graphs
[26, 36], or to analyse space-frequency atoms and wavelet decompositions [1, 30, 31]. The discrete
harmonic structure in spectral graph theory (as introduced in [5]) allows to transfer many uncertainty
relations developed in classical settings directly onto a graph structure. This has led to a quite
fragmented zoo of available uncertainty relations. As the discrete geometry of a graph can vary from
a very homogeneous, symmetric geometry to a very inhomogeneous structure, not every uncertainty
principle is equally useful for every graph. To give an example, it is shown in [3, 35] that particular
graphs, as for instance complete graphs, exhibit a harmonic structure in which the support theorem
of Elad and Bruckstein [7] provides only a very week uncertainty relation. For graphs it is therefore
important to have a ﬂexible framework of uncertainty principles at hand that can be adapted to the
graph structure or to particular applications in graph signal processing.
In spectral graph theory, the complementary pair of domains in which localization is measured is
given by a space domain consisting of a discrete set of graph nodes and a spectral domain provided
by the eigendecomposition of a graph Laplacian [5]. The description of uncertainty principles on
graphs relies on this graph-dependent spatial and spectral structure. The second key ingredient for
the formulation of an uncertainty principle is a proper concept for the measurement of space and
Università degli Studi di Padova, Dipartimento di Matematica ”Tullio Levi-Civita”, Padova, Italy, wolfgang.erb@lissajous.it.
arXiv:1909.10865v1  [eess.SP]  19 Sep 2019

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
2
frequency localization. Suitable localization measures on graphs should be consistent with the given
harmonic structure, but also be adjustable to prerequisites determined by applications.
The goal of this article is to oﬀer a new more general perspective on uncertainty principles in
spectral graph theory, able to incorporate a large number of diﬀerent localization measures. These
measures will be deﬁned in terms of localization operators built upon a space and a frequency ﬁlter.
For any given pair of ﬁlters we want to visualize and characterize the shapes of the corresponding
uncertainty regions. For this, we combine existing results on operator-based uncertainty principles in
signal processing with computational methods developed for the numerical range of matrices. In this
way, we get a powerful uniﬁed framework for the analysis, the computation and the illustration of
uncertainty in spectral graph theory.
Main contributions. Our uncertainty framework on graphs is a synthesis and extension of several
established results. It is built on the following ideas, compactly illustrated in Table 1.
• The theoretical starting point of this framework is the space-frequency analysis studied by
Landau, Pollak and Slepian [19, 20, 21, 32, 33, 34] for signals on the real line and its relative
on graphs [36, 39]. In Sections 3 and 4, we will extend this theory from projection operators
to general symmetric, positive-semideﬁnite operators. In this way, we are able to merge the
Landau-Pollak uncertainty for projection operators with uncertainty relations based on spectral
and spatial spreads on graphs as formulated in [1, 24, 25]. Our main new theoretical result in
this part is the uncertainty estimate given in Theorem 4.3.
• The second key technology implemented in this framework consists of theoretical and compu-
tational aspects of the numerical range of matrices [4, 13, 16, 17, 22, 37]. In Section 5, we show
that the uncertainty regions related to the space and frequency localization measures can be
formulated and calculated with help of a convex numerical range. In this way, we obtain the
eﬃcient Algorithm 1 for the computation and visualization of the uncertainty curves and, in
addition, the theoretical bounds in Theorems 5.3 and 5.5 for the uncertainty regions. This
simpliﬁes the methods derived in [1] for the calculation of the convex uncertainty curve.
• In a Landau-Pollak-Slepian type space-frequency analysis, it is possible to formulate error es-
timates for the approximation of space-frequency localized signals [9, 10, 20]. In our general
framework on graphs, these estimates will be derived in Section 6.
Compared to existing uncertainty relations on graphs that are based on predeﬁned single space-
frequency ﬁlters, the ﬁlter pairs in our general framework are ﬂexible. This gives the interesting
opportunity to design ﬁlter functions for a graph-adapted space-frequency analysis. In particular, the
generality of our framework has the following advantages:
• The Landau-Pollak-Slepian space-frequency analysis is based on a set-oriented localization while
the spectral spreads deﬁned in [1] favor signals localized at the lower end of the graph spectrum.
In our framework arbitrary distance functions on the graph or its spectrum can be implemented
to measure diﬀerent types of space-frequency localization. This allows us to design localization
measures that contain additional spatial, directional or spectral information of the graph. We
will provide some examples in Section 7.
• By using projection ﬁlters in the Landau-Pollak-Slepian setting the spectrum of the space-
frequency operator clusters at the values 0 and 1 [21, 33]. This leads to numerical instability
when calculating the corresponding eigendecomposition directly. In Section 7, we will observe a
similar clustering for graphs. By the usage of alternative ﬁlters, this clustering can be avoided.
• In graph convolutional neural networks, spatial and spectral ﬁlters are extracted in an optimiza-
tion process [6, 38]. The generality of our framework allows to express uncertainty relations also
for such learned ﬁlter functions.

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
3
Uniﬁed framework
of uncertainty principles
in spectral graph theory
Landau-Pollak-Slepian theory
In signal processing: [19, 33, 34]
On graphs: [36]
Numerical range
of matrices
[4, 17, 22, 37]
Uncertainty principle
based on graph spreads
and spectral spreads [1]
provides theory
and estimates
for boundary
provides concept for
space-frequency analysis
computational
methods
results on
approximation
and boundary
particular
ﬁlter functions
description of
uncertainty
curve
Table 1: Main conceptual inﬂuences for the uncertainty framework studied in this work.
2
Background
2.1
Spectral graph theory
The goal of this section is to give a broad overview on spectral graph theory and the notion of
harmonic analysis on a graph G, essential for the formulation of space-frequency decompositions or
uncertainty principles. A profound introduction to spectral graph theory can be found in [5]. For an
introduction to the Fourier transform and space-frequency concepts on graphs, we refer to [31].
We describe the graph G as a triplet G = (V, E, A), where V = {v1, . . . , vn} denotes the set of
vertices (or nodes) of the graph, E ⊆V × V is the set of (directed or undirected) edges connecting
the nodes and A ∈Rn×n is a weighted, symmetric and non-negative adjacency matrix containing
the connection weights of the edges. The entire harmonic structure of the graph G is encoded and
described by this adjacency matrix A. Note that, although G can also be a directed graph, the
symmetric matrix A gives an undirected harmonic structure on G.
We aim at studying signals x on the graph G, i.e. functions x : V →R that associate a real value
to each node of V . Since the number of nodes in G is ﬁxed (i.e. n) and the set V is ordered, we can
naturally represent the signal x as a vector x = (x1, . . . , xn) ∈Rn. Depending on the context, we will
switch between these two representations.
To deﬁne the Fourier transform on G, we consider the (normalized) graph Laplacian L associated
to the adjacency matrix A:
L := In −T−1
2AT−1
2.
Here, In is the n × n identity matrix, and T is the degree matrix with entries given as
(T)ij :=



Pn
k=0(A)ik,
if i = j
0,
otherwise .
Since the adjacency matrix A is symmetric, also L is a symmetric operator and we can compute its
orthonormal eigendecomposition as
L = UMλU⊺,
where Mλ = diag(λ) = diag(λ1, . . . , λn) is the diagonal matrix with the increasingly ordered eigen-
values λi, i ∈{1, . . . , n}, of L as diagonal entries, i.e.,
(Mλ)ij :=

diag(λ)

ij =



λi
if i = j
0
otherwise .
The columns u1, . . . , un of the orthonormal matrix U are normalized eigenvectors of L with respect
to the eigenvalues λ1, . . . , λn. The ordered set ˆG = {u1, . . . , un} of eigenvectors is an orthonormal
basis for the space of signals on the graph G. We call ˆG the spectrum of the graph G.

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
4
2.2
Fourier transform on graphs
In classical Fourier analysis, as for instance the Euclidean space or the torus, the Fourier transform
can be deﬁned in terms of the eigenvalues and eigenfunctions of the Laplace operator. In analogy, we
consider the elements of ˆG, i.e. the eigenvectors {u1, . . . , un}, as the Fourier basis on the graph G.
In particular, going back to our spatial signal x, we can deﬁne the graph Fourier transform of x as
ˆx := U⊺x,
and its inverse graph Fourier transform as
x := Uˆx.
The entries ˆxi = u⊺
i x of ˆx are the frequency components or coeﬃcients of the signal x with respect
to the basis function ui. For this reason, ˆx : ˆG →R can be seen as a distribution on the spectral
domain ˆG of the graph G. To keep the notation simple, we will however usually represent spectral
distributions ˆx as vectors (ˆx1, . . . , ˆxn) in Rn. Regarding the eigenvalues of the normalized graph
Laplacian L it is well-known that (see [5, Lemma 1.7])
0 = λ1 ≤λ2 ≤· · · ≤λn ≤2.
2.3
Spatial and spectral ﬁltering on graphs
By using the graph Fourier transform to switch between spatial and spectral domain, we can now
deﬁne (pointwise) multiplication and convolution between two signals x and y. As there is no
immediate description of translation on G, it is easier to deﬁne the convolution in the spectral
domain, using an analogy to classical Fourier analysis in which the convolution of two signals is
calculated as the pointwise product of their Fourier transforms. We deﬁne
x ∗y := U (ˆx ⊙ˆy) = U ((U⊺x) ⊙(U⊺y)) ,
(1)
where ˆx ⊙ˆy := (ˆx1ˆy1, . . . , ˆxnˆyn) denotes the pointwise Hadamard product of the two vectors ˆx and
ˆy. The Hadamard product x ⊙y between two signals x and y can be formulated in matrix-vector
notation as x⊙y = Mxy by applying the diagonal matrix Mx = diag(x) to the vector y. In the same
way, we get also for functions ˆx and ˆy on ˆG the notion ˆx ⊙ˆy = Mˆxˆy. In this way, according to (1),
we obtain for the convolution the identities
x ∗y = UMˆxU⊺y = UMˆyU⊺x.
3
Space and frequency localization on graphs
3.1
General setting
We are going to study a space-frequency analysis for signals x on the graph G based on two
nonnegative normalized ﬁlter functions f, g ∈Rn with the properties
0 ≤f, g ≤1
and
∥f∥∞= ∥g∥∞= 1.
(2)
Given the two ﬁlters f and g we introduce the following two operators
Mfx := f ⊙x,
Cgx := g ∗x = UMˆgU⊺x.
The point-wise multiplication Mf with the ﬁlter f will be referred to as space localization operator,
the convolution Cg as frequency localization operator. From the properties of f and g in (2) it follows

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
5
immediately that both operators Mf and Cg are symmetric and positive-semideﬁnite and the spectral
norm of both operators is exactly 1. For the operators Mf and Cg we deﬁne the expectation values
¯mf(x) := ⟨Mfx, x⟩
∥x∥2
,
¯cg(x) := ⟨Cgx, x⟩
∥x∥2
.
We say that a signal x on G is space-localized with respect to the window function f if ¯mf(x) is
close to one. In the same way, we say that x on G is frequency-localized with respect to g if ¯cg(x)
approaches one. Based on the mean values ¯mf(x) and ¯cg(x), we deﬁne the set of admissible values
related to the operators Mf and Cg as
W(Mf, Cg) := {( ¯mf(x), ¯cg(x)) | ∥x∥= 1} ⊂[0, 1]2.
(3)
Due to a relation profoundly described in Section 5, we call W(Mf, Cg) also the numerical range of
the pair (Mf, Cg) of operators. All the uncertainty principles studied in this work are linked to the
boundaries of the set W(Mf, Cg).
3.2
Space-frequency operators on graphs
To investigate the joint localization of a signal x with respect to the spatial ﬁlter f and the frequency
ﬁlter g, as well as for the description of the set W(Mf, Cg), we consider the following two space-
frequency operators on the graph G:
R(θ)
f,g := cos(θ) Mf + sin(θ) Cg
and
Sf,g := Cg1/2MfCg1/2.
The linear combination R(θ)
f,g of the two symmetric matrices Mf and Cg is symmetric for any angle
0 ≤θ < 2π and positive semideﬁnite if 0 ≤θ ≤
π
2. The operator norm of R(θ)
f,g is bounded by
| cos θ|+| sin θ| ≤
√
2. The composition Sf,g ∈Rn×n is a positive semideﬁnite, symmetric matrix with
spectral norm bounded by 1.
To study the space-frequency operators R(θ)
f,g and Sf,g we focus on their eigendecompositions
R(θ)
f,g = ΦMρΦ⊺,
and
Sf,g = ΨMσΨ⊺.
The decreasingly ordered eigenvalues ρ = ρ(θ) = (ρ(θ)
1 , . . . ρ(θ)
n ) of the matrix R(θ)
f,g are real and contained
in [−
√
2,
√
2]. The decreasingly ordered eigenvalues σ = (σ1, . . . σn) of Sf,g, are non-negative and
smaller than 1. The columns {φ(θ)
1 , . . . , φ(θ)
n } of Φ and {ψ1, . . . , ψn} of Ψ form a complete set of
orthonormal eigenvectors of the operators R(θ)
f,g and Sf,g, respectively. We say that a signal x is
space-frequency localized with respect to the ﬁlters f and g if the expectation values
¯r(θ)
f,g(x) := ⟨R(θ)
f,gx, x⟩
∥x∥2
= cos(θ) ¯mf(x) + sin(θ) ¯cg(x)
and
¯sf,g(x) := ⟨Sf,gx, x⟩
∥x∥2
get close to one. The largest eigenvalues ρ(θ)
1
and σ1 and the corresponding eigenvectors φ(θ)
1
and ψ1,
will be of major importance of us. For the largest eigenvalue σ1 of the space-frequency operator Sf,g
we get additionally the following characterizations.
Property 3.1. The largest eigenvalue σ1 of the space-frequency operator Sf,g corresponds to the
following spectral operator norms:
σ1 = ∥Sf,g∥= ∥Mf1/2Cg1/2∥2 = ∥Cg1/2Mf1/2∥2 = ∥Mf1/2CgMf1/2∥.

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
6
3.3
Examples of space-frequency ﬁlters on graphs
(1) (Landau-Pollak-Slepian ﬁlters or projection-projection ﬁlters) Let χA denote the indicator func-
tion of a set A, i.e.
χA(v) :=
(
1
if v ∈A,
0
if v /∈A.
For a subset A of the node set V and a subset B of the spectrum ˆG, we deﬁne the ﬁlter functions
f and g as
f = χA
ˆg = χB.
(4)
Both, the space-localization Mf and the frequency-localization operator Cg deﬁned in terms
of f and ˆg = U⊺g in (4) are projection operators satisfying M2
f = Mf and C2
g = Cg. The
space-frequency operator Sf,g is in this case equivalently given as Sf,g = CgMfCg. For signals
on the real line, the space-frequency analysis related to these projection operators, including the
study of uncertainty principle and the distribution of the eigenvalues σi was studied intensively by
Landau, Pollak and Slepian in a series of papers in the sixties of the last century, cf. [19, 20, 32, 34].
A variant of this theory on the unit sphere is given in [27, 29]. A general theory based on two
projection operators in an abstract Hilbert spaces, can be found in [14, Chapter 3 §1]. The
translation to the graph setting was conducted in [36].
(2) (Distance-projection ﬁlters) As a second spatial ﬁlter, we want to generate a window function
that limits a signal x if the distance d(v, w) to a point w on the graph gets large. In general,
d(v, w) can be any distance metric on the nodes V of the graph. In this article, we will use
the geodesic distance on the graph as a metric d, i.e. d(v, w) is the length of the shortest path
connecting the nodes v and w. We further set
dw(v) := d(v, w),
d(∞)
w
:= max
v∈V d(v, w).
Then, as spatial ﬁlter f and frequency ﬁlter g, we deﬁne
f(v) = 1 −dw(v)/d(∞)
w , v ∈V,
and
ˆg = χB,
(5)
i.e., the spatial ﬁlter f incorporates the distance dw to a reference node w and the frequency
ﬁlter g, as before, describes the projection on a spectral subset B ⊂ˆG. For f we have
Mfx = In −
1
d(∞)
w Mdwx,
¯mf(x) = 1 −x⊺Mdwx
d(∞)
w
∥x∥2 .
Similar distance-projection ﬁlters were used in a continuous setup for orthogonal expansions on
the interval [−1, 1] [8, 9, 18] and on the unit sphere [10].
(3) (Modiﬁed distance-projection ﬁlters) While the projection ﬁlter ˆg = χB generates bandlimited
signals on the graph G (with support in the frequency "band" B ⊂ˆG), in applications it is often
relevant to additionally soften the higher frequencies. This can be achieved by multiplying the
projection ﬁlter χB in the spectral domain with a ﬁlter function ˆg(β) in which the coeﬃcients
0 ≤ˆg(β)
k
≤1 decay for increasing frequency k. Also for the distance ﬁlter f given in (5) slight
modiﬁcations can be useful in order to alter the inﬂuence of the distance. A simple possibility
here is to add an additional power α > 0 to the distance function. In this way, we get as modiﬁed
ﬁlters
f(v) = 1 −
 dw(v)
d(∞)
w
!α
,
ˆg = χB ⊙ˆg(β).
(6)
The eﬀects of such modiﬁcations to the shape of the uncertainty principles will be investigated
in Section 7. An example of such a modiﬁed ﬁlter function in the frequency domain is given in
[39]. Here, the author proposes to use the eigenvalues λi of the graph Laplacian to deﬁne the
components ˆg(β)
i
of the additional ﬁlter.

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
7
(4) (Distance-Laplace ﬁlter) Another spectral ﬁlter ˆg = (ˆg1, . . . , ˆgn) on ˆG can be deﬁned as
ˆgk = 1 −λk/2,
(7)
where λk denotes the k-th. smallest eigenvalue of the graph Laplacian L. In this case, we get
Cgx = U(In −1
2Mλ)U⊺x = (In −1
2L)x.
Dividing by the factor 2 in (7) guarantees that the spectrum of Cg is contained in [0, 1] (as the
spectrum of the normalized Laplacian L is contained in [0, 2]). Using the modiﬁed distance ﬁlter
from (6) with α = 2 as a spatial ﬁlter, we get
¯mf(x) = 1 −
x⊺Md2wx
(d(∞)
w
)2∥x∥2,
¯cg(x) = 1 −x⊺Lx
2∥x∥2.
In [1], the measure ¯cUλ(x) = x⊺Lx/∥x∥2 is called the spectral spread of x while the measure
¯md2w(x) = x⊺Md2wx/∥x∥2 is denoted as the graph spread of x with respect to the node w. In [1]
an uncertainty principle on graphs is formulated in terms of these two spreads. We will show
that this uncertainty principle ﬁts as a special case in our more general framework.
(5) (Laplace-Laplace ﬁlter) Instead of deﬁning the operators Mf and Cg for signals on the graph
domain, it is also possible to deﬁne them in terms of distributions ˆx in the spectral domain ˆG.
In this sense, we can introduce the operators M ˆf and Cˆg as
M ˆf ˆx = ˆf ⊙ˆx,
Cˆgˆx = ˆg ∗ˆx = UMˆˆgU⊺ˆx.
An example of such a ﬁltering is given in [3]. Here, f and g are given as
ˆf = 1 −1
2λ,
ˆg = 1 −1
2λ.
In [3], the ﬁlters are actually formulated in terms of ˆf = ˆg = λ. The reformulation above
guarantees that the entries ˆf and ˆg are between 0 and 1 and that the relevant part of the
uncertainty curve is located at (1, 1) instead of (0, 0).
3.4
Comparison to space-frequency analysis based on windowed Fourier transform
An interesting source for uncertainty principles and space-frequency analysis on graphs is based on
the windowed Fourier transform [26, 30, 31]. For this, we want to give a brief comparison between the
space-frequency concepts studied in this article and those related to the windowed Fourier transform.
For a window function h : G →R, the windowed Fourier transform Fhx of a signal x is deﬁned in
the domain G × ˆG as
Fhx(vi, uk) := x⊺(MukCeih),
(8)
where ei = χvi, i ∈{1, . . . , n} simply denote the standard basis vectors for the space of signals on G.
In this deﬁnition, Ceih can be interpreted as a generalized shift of the window h on G whereas Muk
describes a generalized modulation in terms of the Fourier basis uk. The space-frequency analysis
related to the windowed Fourier transform uses the coeﬃcients Fhx(vi, uk) to analyse the signal x.
Further, the system {MukCeih}i,k provides a frame for the space of signals on G if ˆh1 ̸= 0. Compared
to the space-frequency analysis studied in this paper, there are some conceptual diﬀerences:
1) The windowed Fourier transform is based on the choice of a single window function h, compared
to the two ﬁlters f and g for the operators Sf,g and R(θ)
f,g.
2) The space-frequency analysis related to the windowed Fourier transform is based on the frame
system {MukCeih}i,k (cf. [31]) compared to the orthogonal basis of eigenfunctions {ψk} and
{φ(θ)
k } of the operators Sf,g and R(θ)
f,g.
3) Uncertainty relations are formulated in terms of the frame coeﬃcients in (8), see [26].
There are several possibilities to vary the deﬁnition in (8), leading to a similar space-frequency
analysis. A simple example here is to exchange the order of Muk and Cei in (8). More detailed
discussions about the windowed Fourier transform and frame decompositions can be found in [26, 31].

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
8
4
Uncertainty principles related to the operator Sf,g
We start with a ﬁrst uncertainty relation for general ﬁlter functions f and g with the normalization (2)
that rely on the maximal eigenvalue σ1 of the space-frequency operator Sf,g. This type of uncertainty
principle was ﬁrst studied by Landau and Pollak [19] for projection operators acting on functions on
the real line. The corresponding relation for projection operators on graphs was formulated in [36]. In
our setting, this corresponds to ﬁlter functions f and g deﬁned in terms of an indicator function, i.e.
the setting of Example (1) in Section 3.3. Goal of this section is to prove this uncertainty principle
now for general localization operators Mf and Cg.
If ∥Sf,g∥= σ1 < 1, we can specify this uncertainty relation on G by providing an explicit bound
for the admissibility region W(Mf, Cg). This bound is based on the curve
γf,g : [σ1, 1] →R :
γf,g(t) :=

(t σ1)
1
2 + ((1 −t)(1 −σ1))
1
2
2.
Lemma 4.1. Assume that σ1 < 1. If ¯mf(x)¯cg(x) ≥σ1, then the inequality
arccos ¯mf(x)
∥Mfx∥+ arccos ¯cg(x)
∥Cgx∥≥arccos
q
¯mf(x)
q
¯cg(x)
∥Mfx∥∥Cgx∥
√σ1
(9)
holds true. This implies the upper bound
¯cg(x) ≤γf,g( ¯mf(x)) =

( ¯mf(x)σ1)
1
2 + ((1 −¯mf(x))(1 −σ1))
1
2
2
(10)
for ¯cg(x) in the domain ¯mf(x)¯cg(x) ≥σ1.
Proof. Let x be a normalized signal on the graph G with ∥x∥= 1. Further, we consider the two
normalized vectors
y1 =
1
∥Mfx∥Mfx
and
y =
1
∥Cgx∥Cgx.
The angular distance is a metric for vectors on the unit sphere. In particular, the sum of the angular
distances between the vectors y1 and x, and y2 and x is always larger than the angular distance
between y1 and y2, i.e.
arccos⟨y1, x⟩+ arccos⟨y2, x⟩≥arccos⟨y1, y2⟩.
(11)
For the term ⟨y1, y2⟩, we can ﬁnd an upper bound using the Cauchy-Schwarz-inequality:
⟨y1, y2⟩≤|⟨y1, y2⟩| = |⟨Mfx, Cgx⟩|
∥Mfx∥∥Cgx∥= |⟨Mf1/2x, Mf1/2Cgx⟩|
∥Mfx∥∥Cgx∥
≤∥Mf1/2x∥∥Mf1/2Cgx∥
∥Mfx∥∥Cgx∥
=
q
¯mf(x)
q
⟨Cg1/2MfCgx, Cg1/2x⟩
∥Mfx∥∥Cgx∥
≤
q
¯mf(x)
q
¯cg(x)
q
⟨Cg1/2MfCg1/2x, x⟩
∥Mfx∥∥Cgx∥
≤
q
¯mf(x)
q
¯cg(x)
∥Mfx∥∥Cgx∥
√σ1.
As we assume that ¯mf(x)¯cg(x) ≥σ1 the last expression is smaller than 1. Therefore in (11), we get
⟨y1, y2⟩≤
q
¯mf(x)
q
¯cg(x)
∥Mfx∥∥Cgx∥
√σ1 ≤1,
⟨y1, x⟩= ¯mf(x)
∥Mfx∥,
⟨y2, x⟩= ¯cg(x)
∥Cgx∥,
and, thus, precisely the inequality (9) To demonstrate the second inequality we make use of the
following fact:
if 0 < a ≤b ≤1, then arccos bt −arccos at is a decreasing function in t ∈
h
−1
b, 1
b
i
.
(12)

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
9
Therefore, by setting a =
√
¯cg(x)
∥Cgx∥
√σ1 ≤
¯cg(x)
∥Cgx∥
q
¯mf(x) ≤
q
¯mf(x) = b ≤1, we can apply (12) to
inequality (10) and obtain
arccos
q
¯mf(x) + arccos ¯cg(x)
∥Cgx∥≥arccos
q
¯cg(x)
∥Cgx∥
√σ1.
Applying (12) a second time with a = √σ1 ≤
q
¯cg(x) = b ≤1, we get
arccos
q
¯mf(x) + arccos
q
¯cg(x) ≥arccos √σ1
in the domain ¯mf(x)¯cg(x) ≥σ1. Applying the trigonometric identity cos(α −β) = cos α cos β −
sin α cos β we ﬁnally obtain the inequality (10) as
¯cg(x)
1
2 ≤cos(arccos √σ1 −arccos
q
¯mf(x)) = ( ¯mf(x)σ1)
1
2 + ((1 −¯mf(x))(1 −σ1))
1
2.
Remark 4.2. Note that for t ∈[σ1, 1] we have the following inequalities
σ1 ≤σ1
t ≤−t + 1 + σ1 ≤γf,g(t) ≤1.
Therefore, in the square [σ1, 1]2 we have the relations
n
(t, s) ∈[σ1, 1]2 | s ≥γf,g(t)
o
⊂
n
(t, s) ∈[σ1, 1]2 | ts ≥σ1
o
⊂[σ1, 1]2.
Lemma 4.1 provides a general restriction of the set W(Mf, Cg) in the upper right corner [σ1, 1]2
of the unit square. By simple reﬂections, we get an analogous result for the other three corners.
To simplify the notation we deﬁne the corresponding reﬂection operator ∗on the ﬁlters f and g as
f ∗= 1 −f and g∗= 1 −g. Further, to distinguish eigenvalues σ1 for diﬀerent ﬁlters, we use in this
part the extended notation σ(f,g)
1
to denote the largest eigenvalue of the operator Sf,g. We consider
now the following subdomain of the square [0, 1]2 (see Figure 1 (left)):
Wγ :=













(t, s) ∈[0, 1]2

s ≤γf,g(t)
if ts ≥σ(f,g)
1
,
1 −s ≤γf,g∗(t)
if t(1 −s) ≥σ(f,g∗)
1
,
s ≤γf∗,g(1 −t)
if (1 −t)s ≥σ(f∗,g)
1
,
1 −s ≤γf∗,g∗(1 −t)
if (1 −t)(1 −s) ≥σ(f∗,g∗)
1













.
Lemma 4.1 now implies the following:
Theorem 4.3. The range W(Mf, Cg) is contained in Wγ.
Remark 4.4.
1) If σ1 = σ(f,g)
1
< 1 (or, similarly, if σ(f∗,g)
1
< 1, σ(f,g∗)
1
< 1 or σ(f∗,g∗)
1
< 1) then Theorem 4.3 is an
uncertainty relation for the operators Mf and Cg. It states that a signal x on the graph can not
be well localized with respect to both operators Mf and Cg. In particular, the vector of mean
values ( ¯mf(x), ¯cg(x)) can not get close to (1, 1).
2) The uncertainty statement in Theorem 4.3 can get sharp in the sense that if Mf and Cg are two
projection operators, then we get equality W(Mf, Cg) = Wγ in Theorem 4.3. For graphs this is
shown in [36, Theorem 3.1]. This fact can be interpreted in the following way: among all pairs of
positive deﬁnite operators with spectral norm 1 and eigenvalues σ(f,g)
1
, σ(f∗,g)
1
, σ(f,g∗)
1
, and σ(f∗,g∗)
1
,
a pair of projection operators gives the weakest possible uncertainty relation in Theorem 4.3. In
other words, pairs of projection operators have the smallest mutual correlation between space-
and frequency localization according to this uncertainty relation.

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
10
¯cg(x)
¯mf(x)
1
1
W(Mf, Cg)
Wγ
σ(f,g)
1
1 −σ(f ∗,g∗)
1
1 −σ(f ∗,g∗)
1
σ(f ∗,g)
1
σ(f,g∗)
1
1 −σ(f ∗,g)
1
σ(f,g)
1
1 −σ(f,g∗)
1
¯cg(x)
¯mf(x)
1
1

¯mf(φ(θ)
1 ), ¯cg(φ(θ)
1 )

W(Mf, Cg)
H(θ)∩[0,1]2
L(θ)
Fig. 1: Illustration of the uncertainty principles in Theorem 4.3 (left) and in Theorem 5.3 (right).
4.1
Do we always have uncertainty on graphs?
In our uncertainty framework, the answer is no. Compared to the real line setting studied in [19], the
scenario σ1 = 1 is possible on some graphs, as pointed out it [36]. This implies that in some cases
there are signals x satisfying ¯mf(x) = ¯cg(x) = 1, i.e. x is perfectly localized in space and frequency
simultaneously. Therefore, we can not expect that every pair of ﬁlters (f, g) induces an uncertainty
principle on G. Nevertheless, in a lot of cases the condition σ1 < 1 can be guaranteed. One of these
conditions is the following:
Proposition 4.5. Let f and g be two ﬁlter functions on a graph G satisfying (2). If the maximal
eigenvalue 1 of Mf and Cg is simple, then σ1 = ∥Sf,g∥< 1.
Proof. Assume that σ1 = 1, then by Property 3.1 we can ﬁnd a normalized signal x such that
1 = ∥Cg1/2Mf1/2x∥. As the spectral norms of Cg1/2 and Mf1/2 are one, this is only possible if x
is an eigenvector of Mf1/2 with respect to the eigenvalue 1. As Mf1/2 is a diagonal matrix and the
eigenvalue 1 is simple, we have x = ±ei for some i ∈{1, . . . , n}, i.e. x is up to the factor ± a canonical
basis vector. Therefore, we get 1 = ∥Cg1/2ei∥, i.e. ei is also an eigenvector of Cg1/2 with respect to
the largest eigenvalue 1. As the eigenvalue 1 of Cg1/2 is simple this implies that ei corresponds (up
to a possible sign) to one of the columns of U, that is, ei is an eigenvector of the normalized graph
Laplacian L. This on the other hand is not possible by the given structure of the adjacency matrix
A as the vertex vi is connected by at least one edge to another vertex vj.
For some graphs, the conditions of Proposition 4.5 on the ﬁlters f and g can not be weakened in
order to still guarantee σ1 < 1. We give two counterexamples.
Counterexample 4.6.
(1) (Bipartite graphs) We consider a bipartite graph G with 4 nodes {v1, v2, v3, v4} and two undi-
rected edges connecting v1 with v2 and v3 with v4. For this graph we obtain the graph Laplacian
L and its spectral decomposition as
L =





1
−1
0
0
−1
1
0
0
0
0
1
−1
0
0
−1
1




,
U = 1
√
2





1
0
1
0
1
0
−1
0
0
1
0
1
0
1
0
−1




,
Mλ =





0
0
0
0
0
0
0
0
0
0
2
0
0
0
0
2




.
In particular λ1 = λ2 = 0 and λ3 = λ4 = 2 are double eigenvalues of L with a corresponding

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
11
two-dimensional eigenspace. Now, if we choose the ﬁlters f and g as
f = (1, 0, 1, 0),
ˆg = (1, 0, 1, 0),
we get
( ¯mf(e1), ¯cg(e1)) = (1, 1),
( ¯mf(e2), ¯cg(e2)) = (0, 1),
( ¯mf(e3), ¯cg(e3)) = (1, 0),
( ¯mf(e4), ¯cg(e4)) = (0, 0).
The convexity of the numerical range (established in Theorem 5.1 below) therefore implies that
W(Mf, Cg) = [0, 1]2, i.e. we encounter no uncertainty in this example.
In a similar way, we can check for the ﬁlters f = (1, 0, 0, 0), ˆg = (1, 0, 1, 0) or f = (1, 1, 0, 0),
ˆg = (1, 0, 0, 0) that the right upper corner (1, 1) is contained in W(Mf, Cg), i.e., that σ1 = 1.
Therefore, in this example also the conditions of Proposition 4.5 can not be weakened. Similar
counterexamples can be constructed on larger bipartite graphs with an even number of nodes.
(2) (Complete graphs) We consider now a complete graph G with 4 nodes {v1, v2, v3, v4} in which
each node is connected to all other nodes by an undirected edge. For this graph we obtain the
graph Laplacian L and its spectral decomposition as
L = 1
3





3
−1
−1
−1
−1
3
−1
−1
−1
−1
3
−1
−1
−1
−1
3




,
U = 1
2






1
1
√
2
0
1
1
−
√
2
0
1
−1
0
√
2
1
−1
0
−
√
2





,
Mλ =





0
0
0
0
0
4/3
0
0
0
0
4/3
0
0
0
0
4/3




.
For the ﬁlter functions f and g given by
f = (1, 1, 0, 0),
ˆg = (0, 0, 1, 0),
we get ( ¯mf(u3), ¯cg(u3)) = (1, 1). Thus, also in this example of a connected graph the right upper
corner (1, 1) is contained in W(Mf, Cg) and σ1 = 1. In this example it is therefore not possible
to weaken the condition for the spatial ﬁlter f in Proposition 4.5. Also on general complete
graphs with n ≥3 nodes a similar counterexample can be constructed.
5
Computation of Uncertainty principles and the numerical range W(Mf, Cg)
For a normalized vector x ∈Rn we have
¯mf(x) + i ¯cg(x) = x⊺Mfx + i x⊺Cgx = x⊺(Mf + i Cg)x.
Thus, by identifying the complex numbers C with the plane R2 the admissibility region W(Mf, Cg)
can be seen as a part of the numerical range W(Mf + iCg) of the matrix Mf + iCg given by
W(Mf + iCg) := {¯x⊺(Mf + iCg)x | x ∈Cn, ∥x∥= 1} .
The deﬁnition of W(Mf, Cg) in (3) and of W(Mf + iCg) are very similar, the only diﬀerence being
that W(Mf +iCg) is classically deﬁned in terms of complex-valued vectors x. In Theorem 5.1 below,
we will see that the two sets coincide if the number of nodes is n ≥3. For this reason, we call the
admissibility region W(Mf, Cg) also the numerical range of the pair (Mf, Cg). The deep link between
the numerical range and uncertainty principles is pointed out in several works, among others in the
original work [19] of Landau and Pollak and the subsequent study in [22]. In [18], this link is used
to derive uncertainty principles on an interval in terms of general spatial localization measures.

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
12
5.1
Uncertainty principle related to the operator R(θ)
f,g
The correspondence of W(Mf, Cg) with W(Mf + iCg) is important for us, as we can use a broad
arsenal of available results for W(Mf + iCg) to describe and approximate W(Mf, Cg). A second
crucial property for our investigations is the convexity of W(Mf, Cg).
Theorem 5.1 (Theorem 2.1, 2.2. and Remark 1 in [4]).
If n ≥3, the set W(Mf, Cg) is convex, compact and corresponds to the numerical range W(Mf +iCg).
In the case n = 2, the set W(Mf, Cg) corresponds to the elliptical boundary of W(Mf + iCg).
Remark 5.2. The convexity of W(Mf + iCg) is the well-known Hausdorﬀ-Toeplitz Theorem (cf. the
original works [13, 37] of Hausdorﬀand Toeplitz, proofs in english are given in [12, Theorem 1.1-2]
or [16, Section 1.3]). Theorem 5.1, and, thus, the correspondence of the range W(Mf, Cg) with the
classical numerical range W(Mf +iCg), is proven in [4]. Actually, in [4] this correspondence is shown
by ﬁrst proving the convexity of W(Mf, Cg). A simpliﬁed and uniﬁed proof for the convexity of the
two sets is given in [2]. In the exceptional case n = 2, the set W(Mf, Cg) is an ellipse, a circle or
a degenerate ellipse in form of a line segment or a point (cf. [4]). The compactness of W(Mf, Cg)
follows from the fact that x →( ¯mf(x), ¯cg(x)) is a continuous mapping from the compact unit sphere
in Rn onto W(Mf, Cg) (see also [12, Theorem 5.1-1]).
Using the convexity of W(Mf, Cg), we derive now further properties that are useful for the
formulation of an uncertainty principle as well as for the numerical computation of W(Mf, Cg). The
following derivations can already be found in a similar form in the ﬁrst works [13, 37] of Hausdorﬀ
and Toeplitz for the range W(Mf + iCg). The results regarding the approximation of the numerical
range with polygons can be found in [17] or in [16, Section 1.5].
We ﬁrst observe that for (t, s) ∈W(Mf, Cg) the largest possible value of the coordinate t is attained
for a normalized eigenvector of Mf with respect to the largest eigenvalue. By our deﬁnition of the
space-frequency operator R(θ)
f,g, these are given as ρ(0)
1
(the largest eigenvalue) and φ(0)
1
(a respective
eigenvector) of the matrix R(0)
f,g = Mf. In particular, we have
ρ(0)
1
= φ(0)⊺
1
Mfφ(0)
1
= max
t∈R {t | (t, s) ∈W(Mf, Cg)}.
Therefore the vertical line L(0) = {(ρ(0)
1 , s) | s ∈R} is a supporting hyperplane for the numerical
range W(Mf, Cg) such that the half-plane {(t, s) | t ≤ρ(0)
1 } contains W(Mf, Cg). Further, the point
(φ(0)⊺
1
Mfφ(0)
1 , φ(0)⊺
1
Cgφ(0)
1 ) ∈L(0) ∩W(Mf, Cg) is on the boundary of W(Mf, Cg).
In a next step, we consider for θ ∈[0, 2π) the (clockwise oriented) rotation matrix
R(θ) :=
 
cos θ
sin θ
−sin θ
cos θ
!
.
The rotated numerical range R(θ) W(Mf, Cg) can be written as
R(θ) W(Mf, Cg) = W(cos θ Mf + sin θ Cg, −sin θ Mf + cos θ Cg).
Thus, by considering the largest eigenvalue ρ(θ)
1
of the symmetric matrix R(θ)
f,g = cos(θ)Mf +sin(θ)Cg,
and a corresponding eigenvector φ(θ)
1 , the argument above implies that the line
L(θ) := {ρ(θ)
1 (cos θ, sin θ) + τ(−sin θ, cos θ) | τ ∈R} = {(t, s) | cos(θ) t + sin(θ) s = ρ(θ)
1 }
is a supporting hyperplane of W(Mf, Cg). In particular, W(Mf, Cg) is completely contained in the
half-plane
H(θ) := {(t, s) | cos(θ) t + sin(θ) s ≤ρ(θ)
1 }
and the point
p(θ) := (φ(θ)⊺
1
Mfφ(θ)
1 , φ(θ)⊺
1
Cgφ(θ)
1 ) ∈L(θ) ∩W(Mf, Cg)

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
13
lies on the boundary of the numerical range. We summarize this argumentation line in the following
uncertainty principle related to the operators R(θ)
f,g as well as in a characterization of the boundary
curve of W(Mf, Cg). For the complex-valued numerical range W(Mf +iCg) this result was originally
given in [37]. We will use a formulation closer to the one given in [17, Theorem 1 & 2 & 3].
Theorem 5.3 (Uncertainty principle related to R(θ)
f,g).
For every 0 ≤θ < 2π, we have the inclusion
W(Mf, Cg) ⊆[0, 1]2 ∩H(θ),
in which the supporting line L(θ) intersects the boundary of W(Mf, Cg). On the other hand, for every
point p on the boundary of W(Mf, Cg) we have an angle 0 ≤θ < 2π such that p ∈L(θ). For this
angle, we get an eigenvector φ(θ)
1
(not necessarily unique) corresponding to the largest eigenvalue ρ(θ)
1
of R(θ)
f,g such that
p = (φ(θ)⊺
1
Mfφ(θ)
1 , φ(θ)⊺
1
Cgφ(θ)
1 ).
Remark 5.4.
1) The second statement of Theorem 5.3 follows from the convexity of W(Mf, Cg) in the case
n ≥3. For n = 2, we use the fact that W(Mf, Cg) corresponds to the boundary of the convex
numerical range W(Mf + iCg). Both is guaranteed by Theorem 5.1. Theorem 5.3 is illustrated
graphically in Figure 1 (right).
2) For θ = π/4, Theorem 5.3 implies that
√
2ρ(π/4)
n
≤¯mf(x) + ¯cg(x) ≤
√
2ρ(π/4)
1
.
Deﬁning, as in Example 3.3.5 the space and frequency operators in the spectral domain instead
of in the graph domain, we obtain similarly the inequalities
√
2ρ(π/4)
n
≤¯m ˆf(ˆx) + ¯cˆg(ˆx) ≤
√
2ρ(π/4)
1
,
in which ρ(π/4)
1
and ρ(π/4)
n
are the largest and the smallest eigenvalue of the matrix (M ˆf +Cˆg)/
√
2.
Using the Laplace-Laplace ﬁlter described in Example 3.3.5 a variant of this inequality was
formulated in [3, Theorem 4.1] as an uncertainty principle on graphs.
5.2
Approximation of the numerical range W(Mf, Cg) with polygons
We proceed now one step further and construct polygons based on a set Θ = {θ1, . . . θK} ⊂[0, 2π)
of K ≥3 diﬀerent angles to approximate the numerical range W(Mf, Cg) from the interior as well
as from the exterior. Using the notation of Section 5.1, we deﬁne the two K-gons
P(Θ)
out (Mf, Cg) :=
K
\
k=1
H(θ) =
K
\
k=1
n
(t, s) | cos(θk) t + sin(θk) s ≤ρ(θk)
1
o
,
P(Θ)
in (Mf, Cg) := conv{p(θ1), p(θ2), . . . p(θK)}.
The convexity of the numerical range W(Mf, Cg) (for n ≥3) combined with the statements of
Theorem 5.3 imply the following result.
Theorem 5.5 (Theorem 4 in [17]). Let Θ = {θ1, . . . θK} ⊂[0, 2π) be a set of K ≥3 diﬀerent angles
and n ≥3. Then,
P(Θ)
in (Mf, Cg) ⊆W(Mf, Cg) ⊆P(Θ)
out (Mf, Cg).
Remark 5.6. The vertices of the outer polygon P(Θ)
out (Mf, Cg) can be calculated explicitly. A corre-
sponding formula based on the eigenvalues ρ(θk)
1
is given in [17] and adapted to the notation of this
article in equation (13). Note that compared to [17], the orientation of the rotation is reversed.

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
14
5.3
Algorithm for the numerical approximation of the numerical range W(Mf, Cg)
Using the version of Theorem 5.5 for the range W(Mf + iCg), two algorithms for the polygonal
approximation of the convex set W(Mf + iCg) (one from the interior, the other from the exterior)
were derived in [17]. In this article, we can additionally exploit the symmetry of the matrices Mf and
Cg. The resulting purely real-valued method to obtain the polygonal approximations of W(Mf, Cg)
is listed in Algorithm 1.
Remark 5.7.
1) In Algorithm 1, we didn’t specify a strategy for the selection of the angles θk. Such strategies
are studied in [28] in which the resulting method for the approximation of an arbitrary convex
set in R2 is called sandwich algorithm (as the boundary of the convex set is sandwiched by an
inner and an outer polygon). In [28], it is shown that if an adaptive angle bisection is applied
then the sandwich algorithm converges quadratically in the number of vertices K.
2) In [1], the sandwich algorithm was applied to approximate a part of the boundary of W(Mf, Cg)
(denoted as uncertainty curve) in case of the ﬁlter pair (f, g) given in Section 3.3 (4). Compared
to Theorem 5.3, a slightly diﬀerent characterization of the boundary points of W(Mf, Cg) was
derived in [1, Theorem 1]. Namely, instead of a rotation angle θ a slope parameter α was used.
Although the characterization with a slope parameter α is elegant, it has the slight disadvantage
that the entire boundary of W(Mf, Cg) can not be described with a single parametrization.
Algorithm 1: Calculation of interior and exterior approximations to W(Mf, Cg)
Input: The matrices Mf, Cg, the angles
0 ≤θ1 <θ2 <· · ·<θK < 2π, with K ≥3.
Set θ0 = θK.
for k ∈{1, 2, . . . , K} do
Create R(θk)
f,g = cos(θk)Mf + sin(θk)Cg ;
Calculate normalized eigenvector φ(θk)
1
for
the maximal eigenvalue ρ(θk)
1
;
Create the boundary point
p(θk) =

φ(θk)⊺
1
Mfφ(θk)
1
, φ(θk)⊺
1
Cgφ(θk)
1

.
Generate the interior polygon
P(Θ)
in (Mf, Cg) = conv{p(θ1), . . . p(θK)}
as an approximation to W(Mf, Cg).
for k ∈{1, 2, . . . , K} do
Create the outer vertex q(θk) as
q(θk) = R(−θk)
 
ρ(θk)
1
, ρ(θk)
1
cos(θk −θk−1) −ρ
(θk−1)
1
sin(θk −θk−1)
!
. (13)
Generate P(Θ)
out (Mf, Cg) = conv{q(θ1), . . . q(θK)}
as a polygon exterior to W(Mf, Cg).
Fig. Alg. 1: Interior and exterior approximation
of the numerical range W(Mf, Cg) based on
Algorithm 1 using an interior and an exterior
polygon with K = 7 vertices.
6
Error estimates for space-frequency localized signals
The orthogonal basis of eigenvectors {ψ1, . . . , ψn} and {φ(θ)
1 , . . . , φ(θ)
n } of the matrices Sf,g and R(θ)
f,g
are natural candidates to decompose a signal x on G into single space-frequency components. In
particular, we can expand every signal x as
x =
n
X
k=1
(ψ⊺
kx) ψk
and
x =
n
X
k=1
(φ(θ)⊺
k
x) φ(θ)
k ,

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
15
with the coeﬃcients ψ⊺
kx and φ(θ)⊺
k
x giving information about the space-frequency localization of x.
If the signal x itself is space-frequency localized with respect to the operators Sf,g or R(θ)
f,g, or if the
variance terms
var[Sf,g](x) := x⊺(Sf,g −¯sf,g(x))2x
∥x∥2
,
var[R(θ)
f,g](x) := x⊺(R(θ)
f,g −¯r(θ)
f,g(x))2x
∥x∥2
are small, we can approximate the signal x well with only a few eigenvectors. This is speciﬁed in the
following result.
Theorem 6.1. Let s < σ1 and r < ρ(θ)
1 . For a signal x on G, we have the inequalities
x −
X
k: σk≥s
(ψ⊺
kx)ψk

2
≤σ1 −¯sf,g(x)
σ1 −s
∥x∥2,

x −
X
k: ρ(θ)
k ≥r
(φ(θ)⊺
k
x)φ(θ)
k

2
≤ρ(θ)
1
−¯r(θ)
f,g(x)
ρ(θ)
1
−r
∥x∥2.
(14)
Further, for a > 0, deﬁne the intervals Is,a = [¯sf,g(x)−a,¯sf,g(x)+a], and Ir,a = [¯r(θ)
f,g(x)−a, ¯r(θ)
f,g(x)+a].
Then, we get the error bounds
x −
X
k: σk∈Is,a
(ψ⊺
kx)ψk

2
≤var[Sf,g](x)
a2
∥x∥2,

x −
X
k: ρ(θ)
k ∈Ir,a
(φ(θ)⊺
k
x)φ(θ)
k

2
≤var[R(θ)
f,g](x)
a2
∥x∥2. (15)
Proof. We provide the proof only for the space-frequency analysis related to the operator Sf,g. For
R(θ)
f,g the argumentation line is identical.
For a signal x on G, the orthonormality of the eigenbasis {ψ1, . . . ψn} gives
x −
X
k: σk≥s
(ψ⊺
kx)ψk

2
=
X
k: σk<s
(ψ⊺
kx)2 ≤
1
σ1 −s
X
k: σk<s
(ψ⊺
kx)2(σ1 −σk) ≤
1
σ1 −s
n
X
k=1
(ψ⊺
kx)2(σ1 −σk)
Since, ∥x∥2 = Pn
k=1(ψ⊺
kx)2 (Pythagoras) and Pn
k=1 σk(ψ⊺
kx)2 = ¯sf,g(x)∥x∥2 (spectral decomposition of
Sf,g), we get the inequality (14). Similarly, we can prove the bound in (15). Namely, we have
x −
X
k: σk∈Is,a
(ψ⊺
kx)ψk

2
=
X
k: σk∈R\Is,a
(ψ⊺
kx)2 ≤1
a2
X
k: σk∈R\Is,a
(ψ⊺
kx)2(¯sf,g(x) −σk)2
≤1
a2
n
X
k=1
(ψ⊺
kx)2(¯sf,g(x) −σk)2 = var[Sf,g](x)
a2
∥x∥2.
This completes the proof of (15) for the operator Sf,g.
Remark 6.2. For a normalized signal x on G with ∥x∥= 1, the vector µ(x) = (µ1(x), . . . , µn(x)) given
by µk(x) = (ψ⊺
kx)2 can be considered as a probability distribution on the spectrum of Sf,g (similarly
also for the operator R(θ)
f,g). The two inequalities (14) and (15) stated in Theorem 6.1 can therefore be
seen as variants of the Markov and the Chebyshev inequality for a µ(x)-distributed random variable,
(see [23, p. 114]). For orthogonal polynomials on the interval [−1, 1], similar error estimates were
derived in [9].
7
Shapes of uncertainty - Examples and Illustrations
As a ﬁnal part of this work, we want to study and illustrate the uncertainty regions for concrete ﬁlter
pairs (f, g). Further, we want to analyze the eﬀects of the diﬀerent ﬁlter pairs on the space-frequency
localization on graphs. For this, we conduct several numerical experiments on two explicit graphs.

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
16
Fig. 2: Experimental setup on the sensor network G1. The spatial ﬁlters f1, f2, f3 and f4 described
in Section 7.1.2 are plotted from left to right.
7.1
Experimental setup for graphs and ﬁlters
7.1.1
The graphs
As undirected and unweighted test graphs, we consider point clouds in R2 in which two nodes v1 and
v2 get connected if the euclidean distance satisﬁes |v1 −v2| ≤R for some chosen radius R > 0. In
particular, we study the following two settings:
(1) G1 is a sensor network with n1 = 253 random nodes in the square [0, 1]2. With the radius
R = 1/6, we obtain a graph with 2369 edges. G1 is illustrated in Figure 2.
(2) The node set of G2 is a reduced point cloud taken from the Stanford bunny (Source: Stanford
University Computer Graphics Laboratory). It contains n2 = 900 nodes projected in the xy-
plane. Choosing as radius R = 0.01 we obtain the graph G2 with 7325 edges. The Stanford
bunny G2 is illustrated in Figure 3.
Fig. 3: Experimental setup on the Stanford bunny G2. The spatial ﬁlters f1, f2, f3 and f4 described
in Section 7.1.2 are plotted from left to right.
7.1.2
The space and frequency ﬁlters
We test four diﬀerent ﬁlter pairs:
(1) (f1, g1) is a projection-projection pair as described in Section 3.3 (1). It corresponds to the
space-frequency setting studied in [36]. For the spatial ﬁlter f1 = χA, we choose the circular set
A = {v ∈V | |v −w| ≤r}, i.e. A consists of all nodes of the point cloud V that are within an
euclidean distance r to the central node w. The matrix Mf1 is then the orthogonal projection
onto the signals supported in A. For G1, we choose r = 0.25, for the bunny G2 we take r = 0.015.
In the spectral domain, we use the ﬁlter ˆg = χB with B = {u1, . . . , uN} ⊂ˆG and N < n, i.e.,
Cg1 is the orthogonal projection onto the bandlimited signals spanned by the basis B. For the
graph G1, we use as bandwidth N = 100, for the bunny G2 we take N = 200.
(2) (f2, g2) is a distance-projection pair as deﬁned in Section 3.3 (2). The spatial ﬁlter f2 is deﬁned
as f2 = 1 −dw/d(∞)
w , where dw(v) is the number of edges of the shortest path connecting w

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
17
with v ∈V . To compare f2 with f1, we use for both ﬁlters the same central node w. Further, g2
coincides with the projection ﬁlter g1 = χB described above in (1).
(3) (f3, g3) is a modiﬁed distance-projection pair from Section 3.3 (3). The two ﬁlters f and g are
given for α > 0, β > 0, as
f3 = 1 −

dw
d(∞)
w
α
,
ˆg3 = χB ⊙

1 −

λ
2
β
.
Here, xα is deﬁned as xα = (xα
1, . . . , xα
n). The set B is the same as for the ﬁlters g1 = g2. In our
experiments we choose α = 1/2 and β = 2.
(4) (f4, g4) is the distance-Laplace pair discussed in Section 3.3 (4) and a variant of the uncertainty
setting studied in [1]. This pair is given as
f4 = 1 −

dw
d(∞)
w
2
,
ˆg4 = 1 −λ/2.
In particular, the spatial ﬁlter f4 corresponds to the ﬁlter f3 with the parameter α = 2.
7.2
Shapes of uncertainty and space-frequency localization of eigenvectors
7.2.1
Description
As a ﬁrst experiment, we apply Algorithm 1 and plot the numerical ranges W(Mf, Cg) of the four ﬁlter
pairs (f1, g1), (f2, g2), (f3, g3), and (f4, g4) on the two test graphs G1 and G2. Further, we calculate
the space-frequency localization of the eigenvectors of the matrices Sf,g and R(θ)
f,g, θ = 9π/20, inside
W(Mf, Cg). The corresponding results are illustrated in Figure 4 and Figure 5. As an additional
analysis tool, we display in Figure 6 the decay of the eigenvalues of Sf,g and R(θ)
f,g.
Fig. 4: The numerical range W(Mf, Cg) for the ﬁlter pairs (f1, g1), (f2, g2), (f3, g3), (f4, g4) on the
sensor graph G1 (from left to right). The black dots represent the position ( ¯mf(ψk), ¯cg(ψk)) of the
eigenvectors of the operator Sf,g. The ringed black dot indicates the position of ψ1.
7.2.2
Discussion of the shapes
From the shape of the uncertainty curves it is possible to extract qualitative information about the
applied ﬁlter functions, and in case of (f4, g4) also about the underlying graph G. All four ﬁlter
pairs display an uncertainty, the projection ﬁlter pair (f1, g1) giving the largest admissibility region
W(Mf1, Cg1), or in other words, the weakest uncertainty relation. That W(Mf1, Cg1) describes in
fact an uncertainty relation is only visible by a proper zoom, as displayed in Figure 6 (left).
The parameter α > 0 of the modiﬁed distance ﬁlter f3 has a visible impact on the shape of the
uncertainty curve close to (1, 1). While decreasing the parameter α results in an uncertainty curve
distant to the point (1, 1), increasing α has the opposite eﬀect. The spectral ﬁlters g1, g2 and g3 are
all three bandlimiting ﬁlters. This is visible in the ﬁrst three illustrations of Figure 4 and Figure 5
as the lower boundary of the numerical range intersects the axis s = 0. The fourth ﬁlter g4 contains
spectral information of the graph. In Figure 4 and 5 (right) we see that the operator Cg4 is invertible,
and, thus that the largest eigenvalue of the graph Laplacian certainly satisﬁes λn < 2.

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
18
Fig. 5: Comparison of W(Mf, Cg) for the ﬁlter pairs (f1, g1), (f2, g2), (f3, g3), (f4, g4) on the graph
G2 (from left to right). The black dots represent the location

¯mf(φ(θ)
k ), ¯cg(φ(θ)
k )

of the eigenvectors
of the operator R(θ)
f,g with θ = 9π/20. The ringed black dot indicates the position of φ(θ)
1 .
Fig. 6: Left: Zoom of the upper right corner of Figure 4 (left). Middle: Decay of the eigenvalues σk
of Sf,g for the ﬁlter pairs (f1, g1), (f2, g2), (f3, g3), (f4, g4) on G1. Right: Decay of the eigenvalues ρ(θ)
k
of R(θ)
f,g (θ = 9π/20) for the ﬁlter pairs (f1, g1), (f2, g2), (f3, g3), (f4, g4) on the graph G2.
7.2.3
Discussion of the space-frequency localization of the eigenvectors of Sf,g and R(θ)
f,g
We ﬁrst have a look at the decay of the eigenvalues of Sf,g and R(θ)
f,g in Figure 6 (middle) and (left).
The bandlimiting behavior of the spectral ﬁlters g1, g2 and g3 is visible by the jumps of the eigenvalues
at the bandwidth N, whereas for g4 we see a smooth decay of the eigenvalues. For the projection-
projection pair (f1, g1) an earlier drop of the eigenvalues is visible in case of the operator Sf,g and a
clustering at the values 0, cos θ, sin θ and 1 in case of the operator R(θ)
f,g. The distance ﬁlters f2 and
f3 on the other hand provide smoothly decaying eigenvalues until the rapid drop at N.
The bandlimiting property of the ﬁlters g1, g2 and g3 is also visible in the space-frequency locations
of the eigenvectors of Sf,g and R(θ)
f,g shown in Figure 4 and 5. For these ﬁlters, we see a clear separation
between bandlimited eigenvectors in the range and the eigenvectors spanning the kernel of Sf,g and
R(θ)
f,g, respectively. For the pairs (f1, g1) and (f3, g3) additional eﬀects are visible as f1 is a projection
ﬁlter (enlarging the kernel of Sf,g and R(θ)
f,g) and as ˆg3 contains an additional smoothing factor ˆg(β).
For the ﬁlter pair (f4, g4) such a separation is not visible.
7.3
Space localization of bandlimited signals for distance-projection ﬁlters
In case of the distance-projection pair (f2, g2) further interesting eﬀects are visible in the space-
frequency behavior of the eigendecomposition of the operator Sf,g. In the example given in Figure 4

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
19
Fig. 7: The eigenvectors ψ1 ψ10, ψ50 and ψ200 of Sf2,g2 on G2 (from left to right).
(middle left), we observe that the frequency measure of an eigenvector ψk is either ¯cg(ψk) = 1 (i.e.
the eigenvector ψk is bandlimited) or ¯cg(ψk) = 0 (if k > N, i.e. the support of ˆψk is outside of B).
We can further order the bandlimited eigenvectors of Sf,g with respect to their spatial localization
¯mf. This corresponds to the natural ordering of the bandlimited eigenvectors ψk with respect to the
decreasing eigenvalues of Sf,g. In particular, the optimally space-localized eigenvector with respect
to the localization measure ¯mf inside the band B is ψ1, the least space-localized is the eigenvector
ψN. For the distance ﬁlter f2 on the graph G2, diﬀerent bandlimited eigenvectors ψk are illustrated
in Figure 7. It gets visible that the eigenvectors ψk are localized on G2 in a ring with a certain graph
distance to the center node w. This distance is linked to the index k.
7.4
Space-frequency behavior of the optimally localized eigenvectors
Fig. 8: Top row: the eigenvectors ψ1 of the operator Sf,g for the graph G1 and the ﬁlter pairs (f1, g1),
(f2, g2), (f3, g3), and (f4, g4) (from left to right).
Bottom row: the eigenvectors φ(θ)
1
of the operator R(θ)
f,g with θ =
9
20π for the graph G2 and the ﬁlter
pairs (f1, g1), (f2, g2), (f3, g3), and (f4, g4) (from left to right).
Finally, we compare the space-frequency behavior of the optimally space-frequency localized eigen-
vectors ψ1 and φ(θ)
1
for the four ﬁlter pairs in Section 7.1.2. The spatial and spectral distributions of
these localized eigenvectors are illustrated in Figure 8 and Figure 9, respectively.

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
20
Fig. 9: The Fourier coeﬃcients of the eigenvectors displayed in Figure 8.
Top row: the absolute value of the Fourier coeﬃcients ˆψ1 of the eigenvector ψ1 for the graph G1 and
the ﬁlter pairs (f1, g1), (f2, g2), (f3, g3), and (f4, g4) (from left to right).
Bottom row: the absolute value of the Fourier coeﬃcients ˆφ(θ)
1
of the eigenvector φ(θ)
1
(θ =
9
20π) for
the graph G2 and the ﬁlter pairs (f1, g1), (f2, g2), (f3, g3), and (f4, g4) (from left to right).
Regarding the space localization, all four ﬁlter pairs provide eigenvectors ψ1 and φ(θ)
1
that are
localized around the center node w of the spatial ﬁlter. The kind of localization of the eigenvectors
follows roughly the structure of the spatial ﬁlters given in Figure 2 and Figure 3. In particular,
whereas f1 gives a set-oriented localization measure, the ﬁlters f2, f3 and f4 are distance-oriented
(with respect to the center w). The eﬀects of the spectral ﬁlters on the eigenvectors get mainly visible
in case of the ﬁlters g3 and g4. The decaying Fourier coeﬃcients ˆg3 and ˆg4 have a blurring eﬀect on
the optimal eigenvectors, in particular in case of the pair (f4, g4).
In the spectral domain, we see that the bandlimiting ﬁlters g1 = g2 and g3 are rather rough
localization measures in the spectrum of the graph. In principle, they mainly push the optimal
eigenvector to be in the given frequency band B. On the other hand, the Laplace ﬁlter g4 generates
optimal eigenvectors with a much stronger frequency localization in the lower part of the spectral
domain corresponding to the small eigenvalues of the graph Laplacian.
8
Conclusion
In this work, we presented a ﬂexible framework for uncertainty relations in spectral graph theory
that allows to characterize and compute uncertainty regions for a broad family of diﬀerent space
and frequency ﬁlters. In particular, the usage of a polygonal approximation method for the convex
numerical range enabled us to visualize the boundaries of the uncertainty regions very eﬃciently.
This visualization technique and the related descriptions of uncertainty curves and space-frequency
decompositions of signals make this framework into a promising tool to study and analyze new ﬁlter
designs for a graph-adapted space-frequency analysis.

SHAPES OF UNCERTAINTY IN SPECTRAL GRAPH THEORY
21
Acknowledgment
The project was supported by the European Union’s Horizon 2020 research and innovation programme
ERA-PLANET, grant agreement no. 689443.
References
[1]
Agaskar, A. and Lu, Y. M.
A spectral graph uncertainty principle. IEEE Trans. Inform. Theory 59, 7 (2013), 4338–4356.
[2]
Au-Yeung, Y. H.
A simple proof of the convexity of the ﬁeld of values deﬁned by two hermitian forms. Aequations Math. 12 (1975),
82–83.
[3]
Benedetto, J.J., and Koprowski, P.J.
Graph theoretic uncertainty principles. 2015 International Conference on Sampling Theory
and Applications (SampTA) (2015), 357–361.
[4]
Brickman, L.
On the Field of Values of a Matrix. Proc. Amer. Math. Soc. 12 (1961), 61–66.
[5]
Chung, F. R. K. Spectral Graph Theory. American Mathematical Society, Providence, RI, 1997.
[6]
Defferrard, M., Bresson, X., and Vandergheynst, P. Convolutional Neural Networks on Graphs with Fast Localized Spectral
Filtering. In Advances in neural information processing systems (NIPS’16) (2016), 3844–3852.
[7]
Elad, M., and Bruckstein, A.M. A Generalized Uncertainty Principle and Sparse Representation in Pairs of Bases. IEEE Trans.
Inform. Theory 48, 9 (2002), 2558–2567.
[8]
Erb, W. Optimally space localized polynomials with applications in signal processing. J. Fourier Anal. Appl. 18, 1 (2012), 45–66.
[9]
Erb, W. An orthogonal polynomial analogue of the Landau-Pollak-Slepian time-frequency analysis. J. Approx. Theory 166 (2013),
56–77.
[10] Erb, W. and Mathias, S. An alternative to Slepian functions on the unit sphere - A space-frequency analysis based on localized
spherical polynomials. Appl. Comput. Harmon. Anal. 38, 2 (2015), 222–241.
[11] Folland, G. B., and Sitaram, A. The uncertainty principle: a mathematical survey. J. Fourier Anal. Appl. 3, 3 (1997), 207–233.
[12] Gustafson, K.E., and Rao, D.K.M Numerical Range: The Field of Values of Linear Operators and Matrices. Springer, New York,
1997.
[13] Hausdorff, F. Der Wertvorrat einer Bilinearform. Mathematische Zeitschrift 3 (1919), 314–316
[14] Havin, V., and Jöricke, B. The Uncertainty Principle in Harmonic Analysis. Springer-Verlag, Berlin, 1994.
[15] Heisenberg, W. Über den anschaulichen Inhalt der quantentheoretischen Kinematik und Mechanik. Z. f. Physik 43 (1927), 172–198.
[16] Horn, R. A., and Johnson, C .R. Topics in Matrix Analysis, Cambridge University Press, 1991.
[17] Johnson, C .R.
Numerical Determination of the Field of Values of a General Complex Matrix. SIAM J. Num. Anal. 15, 3 (1978),
595–602.
[18] Klaja, H. On Erb’s uncertainty principle. Studia Mathematica 232, 1 (2016), 7–17.
[19] Landau, H., and Pollak, H. Prolate spheroidal wave functions, Fourier analysis and uncertainty, II. Bell System Tech. J. 40 (1961),
65–84.
[20] Landau, H., and Pollak, H. Prolate spheroidal wave functions, Fourier analysis and uncertainty, III. Bell System Tech. J. 41 (1962),
1295–1336.
[21] Landau, H., and Widom, H. Eigenvalue distribution of time and frequency limiting. J. Math. Anal. Appl. 77 (1980), 469–481.
[22] Lenard, A. The Numerical Range of a Pair of Projections. J. Funct. Anal. 10 (1972), 410–423.
[23] Papoulis, A. Probability, Random Variables, and Stochastic Processes, third ed. McGraw-Hill, New York, 1991.
[24] Pasdeloup, B., Alami, R., Gripon, V., and Rabbat, M. G. Toward an uncertainty principle for weighted graphs. In IEEE 23rd
European Signal Processing Conference, (2015).
[25] Pasdeloup, B., Gripon, V., Alami, R., and Rabbat, M. G. Uncertainty principle on graphs. in Vertex-Frequency Analysis of Graph
Signals, Springer, (2019), 317–340.
[26] Perraudin, N., Ricaud, B., Shuman, D. I., and Vandergheynst, P. Global and local uncertainty principles for signals on graphs.
APSIPA Transactions on Signal and Information Processing 7 (2018).
[27] Plattner, A., and Simons, F. J. Spatiospectral concentration of vector ﬁelds on a sphere. Appl. Comput. Harm. Anal. 36, 1 (2014),
1 – 22.
[28] Rote, G. The convergence rate of the sandwich algorithm for approximating convex functions. Computing 48, 3-4 (1992), 337–361.
[29] Simons, F. J., Dahlen, F., and Wieczorek, M. A. Spatiospectral concentration on a sphere. SIAM Rev. 48, 3 (2006), 504–536.
[30] Shuman, D. I., Ricaud, B., and Vandergheynst, P. A windowed graph Fourier transform. in Proc. 2012 IEEE Statistical Signal
Processing Workshop (SSP), (2012), 133–136.
[31] Shuman, D. I., Ricaud, B., and Vandergheynst, P. Vertex-frequency analysis on graphs. Appl. Comput. Harm. Anal. 40, 2 (2016),
260–291.
[32] Slepian, D. Prolate spheroidal wave functions, Fourier analysis, and uncertainty, V: The discrete case. Bell System Tech. J. 57 (1978),
1371–1430.
[33] Slepian, D. Some comments on Fourier analysis, uncertainty and modeling. SIAM Rev. 25 (1983), 379–393.
[34] Slepian, D., and Pollak, H. O. Prolate spheroidal wave functions, Fourier analysis and uncertainty, I. Bell System Tech. J. 40
(1961), 43–63.
[35] Stanković, L., Daković, L., and Sejdić, E. Vertex-Frequency Energy Distributions. In Vertex-Frequency Analysis of Graph Signals,
Springer, (2019), 377–415.
[36] Tsitsvero, M., Barbarossa, S., and Di Lorenzo, P.
Signals on Graphs: Uncertainty Principle and Sampling. IEEE Trans. Sign.
Proc. 64, 18 (2016), 4845–4860.
[37] Toeplitz, O. Das algebraische Analogon zu einem Satze von Fejér. Mathematische Zeitschrift 2 (1918), 187–197.
[38] Tran, D. V., Navarin, N., and Sperduti, A. On ﬁlter size in graph convolutional networks In 2018 IEEE Symposium on Deep
Learning (SSCI), Bangolore, India (2018).
[39] Van De Ville, D. When Slepian Meets Fiedler: Putting a Focus on the Graph Spectrum. IEEE Signal Processing Letter 24, 7 (2017),
1001–1004.
