Proceedings of Machine Learning Research 230:1–18, 2024 Conformal and Probabilistic Prediction with Applications
Conformal Predictive Systems Under Covariate Shift
Jef Jonkers∗
jef.jonkers@ugent.be
IDLab, Department of Electronics and Information Systems, Ghent University, Belgium
Glenn Van Wallendael
glenn.vanwallendael@ugent.be
IDLab, Department of Electronics and Information Systems, Ghent University - imec, Belgium
Luc Duchateau
luc.duchateau@ugent.be
Biometrics Research Group, Department of Morphology, Imaging, Orthopedics, Rehabilitation and
Nutrition, Ghent University, Belgium
Sofie Van Hoecke
sofie.vanhoecke@ugent.be
IDLab, Department of Electronics and Information Systems, Ghent University - imec, Belgium
Editor: Simone Vantini, Matteo Fontana, Aldo Solari, Henrik Bostr¨om and Lars Carlsson
Abstract
Conformal predictive systems (CPS) offer a versatile framework for constructing predictive
distributions, allowing for calibrated inference and informative decision-making. However,
their applicability has been limited to scenarios adhering to the independent and identically
distributed (IID) model assumption. This paper extends CPS to accommodate scenarios
characterized by covariate shifts. We therefore propose weighted CPS (WCPS), akin to
weighted conformal prediction (WCP), leveraging likelihood ratios between training and
testing covariate distributions. This extension enables the construction of nonparametric
predictive distributions capable of handling covariate shifts. We present theoretical under-
pinnings and conjectures regarding the validity and efficacy of WCPS and demonstrate its
utility through empirical evaluations on both synthetic and real-world datasets. Our sim-
ulation experiments indicate that WCPS are probabilistically calibrated under covariate
shift.
Keywords: Conformal prediction, Conformal predictive systems, Predictive distributions,
Regression, Covariate shift
1. Introduction
Conformal predictive systems (CPS) are a relatively recent development in Conformal pre-
diction (CP) (Vovk et al., 2019, 2020a). CPS construct predictive distributions by arranging
p-values into a nonparametric probability distribution. This distribution satisfies a finite-
sample property of validity under the independent and identically distributed (IID) model,
i.e., the observations are produced independently from the same probability measure. CPS
can be seen as a generalization of point and conformal regressors since they can easily pro-
duce point predictions and prediction intervals by leveraging the generated predictive dis-
tributions. They allow for more informative and trustworthy decision-making (Vovk et al.,
2018). For example, an obvious use case for predictive distributions is to obtain threshold
values such that a decision-maker can determine the likelihood of a certain outcome falling
within a specific range. This is particularly useful in applications where understanding the
∗Corresponding author
© 2024 J. Jonkers, G. Van Wallendael, L. Duchateau & S. Van Hoecke.
arXiv:2404.15018v2  [cs.LG]  16 Sep 2024

Jonkers Van Wallendael Duchateau Van Hoecke
probability distribution of predictions is crucial, such as in risk management, medical diag-
nostics, and financial forecasting. By setting appropriate thresholds based on the predictive
distributions, one can make more informed decisions that balance the trade-offs between
different types of errors or risks.
In alignment with the inception of conformal regressors, several adaptations, and en-
hancements have emerged in the literature after the initial work of Vovk et al. (2019).
These include more computationally efficient variants (Vovk et al., 2020a), adaptive ver-
sions (Vovk et al., 2020b; Bostr¨om et al., 2021; Johansson et al., 2023; Jonkers et al., 2024a),
and proving the existence of universal consistent CPS (Vovk, 2022).
The exchangeability assumption, which allows for provably valid inference for CP and is
a weaker assumption than the IID assumption (Shafer and Vovk, 2008), and similarly, the
IID assumption for CPS, are standard in machine learning. However, distributional shifts
between training and inference data are common in time series, counterfactual inference,
and machine learning for scientific discovery but violate these assumptions. While a grow-
ing amount of literature has been contributed to extending CP beyond the exchangeability
assumptions (Tibshirani et al., 2019; Gibbs and Candes, 2021; Prinster et al., 2022; Yang
et al., 2022; Gibbs et al., 2023), allowing (conservatively) valid inference under various types
of distributional shifts, no contribution has been made towards extending CPS beyond the
IID model. For example, in treatment effect estimation, this extension allows for calibrated
predictive distribution beyond the randomized trial setting (Jonkers et al., 2024b), as in a
nonrandomized setting, the covariate distributions for treated and control subjects differ
from the target population. Therefore, this work extends CPS beyond the IID model by
proposing weighted CPS (WCPS) that constructs valid nonparametric predictive distribu-
tions for problems where the covariate distributions of the training and testing data differ,
assuming their likelihood ratio is known or can be estimated.
The remainder of this paper is organized as follows: in Section 2, we will give some back-
ground and restate propositions around CP, CPS, and covariate shifts. Section 3 presents
our modification of CPS to deal with covariate shift, followed by Section 4 and Section 5,
which discusses and summarizes the main findings, respectively.
2. Background
Let Z := X × R be the observation space where each observation z = (x, y) ∈Z consist of
an object x ∈X and its label y ∈R. Additionaly, lets z1, ..., zn be the training sequence
and zn+1 = (xn+1, yn+1) be the test observation.
2.1. Conformal Prediction
Conformal prediction (CP) (Vovk et al., 2022) is a model-agnostic and distribution-free
framework that allows us to give an implicit confidence estimate in a prediction by generat-
ing prediction sets at a specific significance level α. The framework provides (conservatively)
valid non-asymptotic confidence predictors under the exchangeability assumption. This ex-
changeability assumption assumes that the training/calibration data should be exchange-
able with the test data. The prediction sets in CP are formed by comparing nonconformity
scores of examples that quantify how unusual a predicted label is, i.e., these scores measure
the disagreement between the prediction and the actual target.
2

Conformal Predictive Systems Under Covariate Shift
To do so, we define a prediction interval ˆC(xn+1), for test object xn+1 ∈X, by calcu-
lating following conformity scores Ry
i , based on conformity measure A, for each y ∈R:
Ry
i = A(z1:n\i ∪(xn+1, y), zi),
i = 1, ..., n
(1)
and
Ry
n+1 = A(z1:n, (xn+1, y)).
(2)
The label y is then included in prediction interval ˆC(xn+1) if,
|i = 1, ..., n + 1 : Ry
i ≥Ry
n+1|
n + 1
> α
(3)
The procedure above is referred to as full or transductive conformal prediction and is
computationally heavy. Therefore, Papadopoulos et al. (2002) proposed a more applicable
variant of full CP, called inductive or split CP (ICP). ICP is computationally less demand-
ing and allows the use of CP in conjunction with machine learning algorithms, such as
neural networks and tree-based algorithms. ICP starts by splitting the training sequence
(x, y) = {(x1, y1), ..., (xn, yn)} into a proper training sequence {(x1, y1), ..., (xm, ym)} and
a calibration sequence {(xm+1, ym+1), ..., (xn, yn)}. The proper training sequence is used
to train a regression model. We then generate nonconformity scores Ri for (xi, yi) with
i = m + 1, ..., n from the calibration set, such as for the absolute error, Ri = |yi −ˆyi|.
These nonconformity scores are sorted in descending order: R∗
1, ..., R∗
n−m. For a new test
object xn+1, point prediction ˆyn+1, and a desired target coverage of 1 −α, ICP outputs the
following prediction interval:
[ˆyn+1 −R∗
s, ˆyn+1 + R∗
s]
(4)
where s = ⌊α(n −m + 1)⌋.
2.2. Covariate Shift
A covariate shift is a distributional shift where the test object (xn+1, yn+1) is differently
distributed, i.e. xn+1 ∼˜PX, than the training data zi = (xi, yi), i = 1, ..., n where xi ∼PX,
thus ˜PX ̸= PX. However, the relationship between inputs and labels remains fixed.
(xi, yi) iid
∼P = PX × PY |X,
i = 1, ..., n
(xn+1, yn+1) ∼˜P = ˜PX × PY |X
(5)
2.3. Weighted Conformal Prediction
Tibshirani et al. (2019) was one of the first works to extend conformal prediction beyond
the exchangeability assumption to deal with covariate shifts.
Specifically, they propose
weighted conformal prediction (WCP) to deal with covariate shifts where the likelihood
ratio between the training PX and test ˜PX covariate distributions is known. In WCP, the
empirical distribution of nonconformity scores at the calibration points gets reweighted, and
thus each nonconformity score Ri gets weighted by a probability pw
i (x) proportional to the
3

Jonkers Van Wallendael Duchateau Van Hoecke
likelihood ratio w(xi) = d ˜PX(xi)
dPX(xi):
pw
i (x) =
w(xi)
Pn
j=1 w(xj) + w(x),
i = 1, ..., n,
(6)
pw
n+1(x) =
w(x)
Pn
j=1 w(xj) + w(x).
(7)
This results in an adjusted empirical distribution of nonconformity scores depicted in Table
1. Tibshirani et al. (2019) showed that the validity of WCP remains even for the com-
Table 1: Empirical distribution of nonconformity scores (δa denotes a point mass at a).
Regular
Weighted
1
n+1
Pn
i=1 δRi +
1
n+1δ∞
Pn
i=1 pw
i (x)δRi + pw
n+1(x)δ∞
putational less-demanding split conformal prediction. However, this all does not come for
free; we are reducing the sample size by weighting nonconformity scores and consequen-
tially losing some reliability, i.e., variability in empirical coverage, compared to CP without
covariate shift and the same number of samples. Tibshirani et al. (2019) pointed out a pop-
ular heuristic from the covariate shift literature (Gretton et al., 2008; Reddi et al., 2015) to
determine the effective sample size ˆn of X1, ..., Xn training points, and a likelihood ratio w:
ˆn = [Pn
i=1 |w(xi)|]2
Pn
i=1 |w(xi)|2 = ||w(x1:n)||2
1
||w(x1:n)||2
2
(8)
where w(x1:n) = (w(x1), ..., w(xn)). Note that it is possible to learn the likelihood ratio
w(xi) = d ˜PX(xi)
dPX(xi) between training and test covariate distribution, as showed by Tibshirani
et al. (2019), if it is reasonably accurate.
2.4. Conformal Predictive Systems
Conformal predictive systems (CPS) allow the construction of predictive distributions by
extending upon full CP. CPS produces conformal predictive distributions by arranging p-
values into a probability distribution function (Vovk et al., 2019). These p-values are created
with the help of specific types of conformity measures. Vovk et al. (2019) defines a CPS as
a function that is both a conformal transducer (Definition 1) and a randomized predictive
system (RPS) (Definition 2).
Definition 1 (Conformal Transducer, Vovk et al. (2022)) The conformal transducer
determined by a conformity measure A is defined as,
Q(z1, ..., zn, (xn+1, y), τ) :=
n+1
X
i=1
[Ry
i < Ry
n+1]
1
n + 1 +
n+1
X
i=1
[Ry
i = Ry
n+1]
τ
n + 1
4

Conformal Predictive Systems Under Covariate Shift
where (z1, ..., zn) is the training sequence, τ ∈[0, 1], xn+1 is a test object, and for each label
y the corresponding conformity score Ry
i is defined as
Ry
i := A(z1, ..., zi−1, zi+1, ..., zn, (xn+1, y), zi),
i = 1, ..., n
Ry
n+1 := A(z1, ..., zn, (xn+1, y)).
Definition 2 (RPS, Vovk et al. (2019))
A function Q : Zn+1 × [0, 1] →[0, 1] is an
RPS if it satisfies the following requirements:
R1.1 For each training sequence (z1, ..., zn) ∈Zn and test object x ∈X, the function
Q(z1, ..., zn, (xn+1, y), τ) is monotonically increasing both in y and τ. Put differently,
for each τ ∈[0, 1], the function
y ∈R →Q(z1, ..., zn, (xn+1, y), τ)
is monotonically increasing, and for each y ∈R, the function
τ ∈[0, 1] →Q(z1, ..., zn, (xn+1, y), τ)
is also monotonically increasing.
R1.2 For each τ, τ ′ ∈[0, 1] and each test object xn+1 ∈X,
Q(z1, ..., zn, (xn+1, y), τ) ≥Q(z1, ..., zn, (xn+1, y′), τ ′),
if
y > y′
R1.3 For each training sequence (z1, ..., zn) ∈Zn and test object xn+1 ∈X,
lim
y→−∞Q(z1, ..., zn, (xn+1, y), 0) = 0
and
lim
y→∞Q(z1, ..., zn, (xn+1, y), 1) = 1
R2 As a function of random training observations z1 ∼P, ..., zn ∼P, zn+1 ∼P, and a
random number τ ∼Uniform(0, 1), all assumed to be independent, the distribution
of Q is uniform:
∀α ∈[0, 1] : P{Q(z1, ..., zn, zn+1, τ) ≤α} = α
Definition 2 that defines an RPS is in verbatim from Vovk et al. (2019), except require-
ment R1.2, which is appended to the definition as we believe this is a requirement which is
implicitly assumed by Vovk et al. (2019).
Note that a conformal transducer satisfies R2 by its validity property (see Proposition
2.11 in Vovk et al. (2022)). Additionally, in Vovk (2022) (Lemma 1), they show that a
conformal transducer defined by a monotonic conformity measure A is also an RPS and
thus a CPS if A follows the following three conditions:
5

Jonkers Van Wallendael Duchateau Van Hoecke
• for all n, all training data sequences (z1, ..., zn), and all test objects xn+1,
inf
y A(z1, ..., zn, (xn+1, y)) = inf An
(9)
sup
y A(z1, ..., zn, (xn+1, y)) = sup An;
(10)
• for each n, the infy in Equation 9 is either attained for all (z1, ..., zn) and xn+1, or not
attained for any (z1, ..., zn) and xn+1;
• for each n, the supy in Equation 10 is either attained for all (z1, ..., zn) and xn+1, or
not attained for any (z1, ..., zn) and xn+1.
2.4.1. Split Conformal Predictive Systems
Like CP, CPS has been adapted and made more computationally efficient by building upon
ICP, namely split conformal predictive systems (SCPS) (Vovk et al., 2020a). Here, the
p-values are created by a split conformity measure that needs to be isotonic and balanced.
A good and standard choice of split conformity measure, according to Vovk et al. (2020a),
is a (normalized) residual. In Appendix A, we present and discuss, similarly as for CPS,
definitions and propositions related to SCPS.
3. Weighted Conformal Predictive System
As WCP extends upon CP, we propose to reweigh the conformity scores with a probability
pw
i (x) proportional to the likelihood ratio w(xi) = d ˜PX(xi)
dPX(xi), to present a weighted conformal
transducer where the output is defined by conformity measure A and likelihood ratio w(x) =
d ˜PX(x)
dPX(x),
Q(z1, ..., zn, d ˜P
dP , (xn+1, y), τ) :=
n+1
X
i=1
[Ry
i < Ry
n+1]pw
i (x) +
n+1
X
i=1
[Ry
i = Ry
n+1]pw
i (x)τ
(11)
where τ is a random number sampled from a uniform distribution between 0 and 1. Note
that under the absence of a covariate shift, the probability weights become equal, pw
i (x) =
pw
n+1 =
1
n+1. In this scenario, the weighted conformal transducer (11) will become equivalent
to a conformal transducer.
A function is a weighted conformal predictive system (WCPS) if it is both a weighted
conformal transducer and a weighted RPS (WRPS), i.e., an RPS probabilistically calibrated
under covariate shift. To prove that under specific conformity measures A, e.g., monotonic
conformity measures, a weighted conformal transducer is also a WRPS, we need to prove
Conjecture 3, i.e., that the weighted conformal transducer is probabilistically calibrated.
Conjecture 3
Assume that
• zi = (xi, yi) ∈X × R, i = 1, ..., n are produced independently from P = PX × PY |X;
• zn+1 = (xn+1, yn+1) ∈X × R, is independently drawn from ˜P = ˜PX × PY |X;
• ˜PX is absolutely continuous with respect to PX;
• random number τ ∼Uniform(0, 1);
6

Conformal Predictive Systems Under Covariate Shift
• z1:n, zn+1, and τ to be independent.
Then the distribution of the weighted conformal transducer, defined by (11), is uniform:
∀α ∈[0, 1] : Pz1:n∼P,zn+1∼˜P {Q(z1, ..., zn, d ˜P
dP , zn+1, τ) ≤α} = α
(12)
We leave this proof for future work. However, if proven, Conjecture 4 can be easily proven
by following the same procedure as the proof of Lemma 1 in Vovk (2022) using Conjecture
3 instead of the property of validity of a conformal transducer.
Conjecture 4 (Weighted Version of Lemma 1 in Vovk (2022))
Suppose a mono-
tonic conformity measure A satisfies the following three conditions:
• for all n, all training data sequences (z1, ..., zn), and all test objects xn+1,
inf
y A(z1, ..., zn, (xn+1, y)) = inf An
(13)
sup
y A(z1, ..., zn, (xn+1, y)) = sup An;
(14)
• for each n, the infy in Equation 13 is either attained for all (z1, ..., zn) and xn+1 or
not attained for any (z1, ..., zn) and xn+1;
• for each n, the supy in Equation 14 is either attained for all (z1, ..., zn) and xn+1 or
not attained for any (z1, ..., zn) and xn+1.
Then, the weighted conformal transducer corresponding to A is a WRPS.
In other words, a weighted conformal transducer based on a monotonic conformity measure
satisfying the aforementioned requirements is also a WRPS.
3.1. Weighted Split Conformal Predictive Systems
Besides bringing WCPS to CPS, we also propose a more computationally efficient approach
to construct calibrated predictive distribution based on SCP by presenting a weighted split
conformal transducer determined by the split conformity measure A and likelihood ratio
w(x),
Q(z1, ..., zn, d ˜P
dP , (x, y), τ) :=
n
X
i=m+1
[Ri < Ry]pw
i (x) +
n
X
i=m+1
[Ri = Ry]pw
i (x)τ + pw
n+1(x)τ
(15)
Similarly to WCPS, a function is a weighted split conformal predictive system (WSCPS) if
it is both a weighted split conformal transducer and a WRPS. Thus, we also need to prove
a notion of validity in the form of calibration in probability, see Conjecture 5. We leave
this proof for future work, but we show in Section 4 with simulation experiments that this
empirically seems to be the case.
Conjecture 5
Assume that
7

Jonkers Van Wallendael Duchateau Van Hoecke
• the training sequence z1, ..., zn is split into two parts: the proper training sequence
z1, ..., zm and the calibration sequence zm+1, ..., zn;
• zi = (xi, yi) ∈Rd×R, i = m+1, ..., n are produced independently from P = PX ×PY |X;
• zn+1 = (xn+1, yn+1) ∈X × R, is independently drawn from ˜P = ˜PX × PY |X;
• ˜PX is absolutely continuous with respect to PX;
• random number τ ∼Uniform(0, 1);
• zm+1:n, zn+1, and τ to be independent.
Then is the distribution of weighted split conformal transducer, defined by (15), uniform:
∀α ∈[0, 1] : Pzm+1:n∼P,zn+1∼˜P {Q(z1, ..., zn, d ˜P
dP , zn+1, τ) ≤α} = α
(16)
Conjecture 6
The weighted split conformal transducer (15) is a WRPS if and only if it
is based on a balanced isotonic split conformity measure.
A proof of Conjecture 6 will follow the same procedure as the proof of Proposition 1
and 2 in Vovk et al. (2020a) using Conjecture 5 instead of the property of validity of a split
conformal transducer.
4. Experiments
We evaluate (weighted) CPS under a covariate shift on empirical and synthetic data, and use
(weighted) split CPS approaches for efficiency. For implementing WSCPS, we made an ex-
tension of the python package crepes (Bostr¨om, 2022), named crepes-weighted. A more
detailed description can be found in Appendix B. The Python code to reproduce the simu-
lation results can be found at https://github.com/predict-idlab/crepes-weighted.
4.1. Data
4.1.1. Empirical Data
We consider the airfoil dataset from the UCI Machine Learning Repository (Dua and Casey,
2017), which contains N = 1503 observation, where each observation consists of a response
value Y (scaled sound pressure level of NASA airfoils) and a vector of covariates X with
dimension 5 (log frequency, angle of attack, chord length, free-stream velocity, and suction
side log displacement thickness). We use the same experimental setting as Tibshirani et al.
(2019) to demonstrate the use of CPS under covariate shifts.
In total, we run 1000 experimental trials. For a single trial, the dataset is split into
three sets Dtrain, Dcal, Dtest, which are IID and respectively contain 25%, 25%, and 50%
of the data and have the following roles:
• Dtrain is used as proper training dataset for the CPS, i.e., to train a regression model
ˆµ.
• Dcal is used as calibration set to create conformity scores, we will use the residual as
conformity measure.
• Dtest is used as our test set and has no covariate shift compared to the other sets.
8

Conformal Predictive Systems Under Covariate Shift
To simulate a covariate shift, Tibshirani et al. (2019) propose to construct a fourth set
Dshift that samples with replacement from Dtest, with probabilities proportional to
w(x) = exp(xT β),
where
β = (−1, 0, 0, 0, 1).
(17)
We can view w(x) as the likelihood ratio of covariate distributions between the shifted
test set Dshift and training set Dtrain, since Dtrain and Dtest follow the same IID model.
Consequentially, w(x) is used to account for the covariate shift when using a WSCPS.
4.1.2. Synthetic Data
We also evaluate our approach on synthetic data to evaluate the assumed validity property,
i.e., calibrated in probability, of the WSCPS. We use the setting from Kang and Schafer
(2007), which is also used in Yang et al. (2022), where each observation i is generated in
the following way:
• (xi1, xi2, xi3, xi4)T is independently distributed as N(0, I4) where I4 represents the
4 × 4 identity matrix.
• yi = 210 + 27.4xi1 + 13.7xi2 + 13.7xi3 + 13.7xi4 + εi,
where
εi ∼N(0, 1)
• w(x) = exp(−xi1 + 0.5xi2 −0.25xi3 −0.1xi4), which represents the likelihood ratio of
the covariate distributions of the shifted test set Dshift and training set Dtrain.
We also run 1000 experimental trials for the synthetic data experiments.
4.2. Results
To evaluate the proposed WSCPS, we perform three different experiments on the empirical
and synthetic data. These evaluate the coverage of WSCPS-generated prediction intervals,
the quality of predictive distributions, and probabilistic calibration under covariate shift.
First, we evaluate the coverage of 80% prediction intervals generated with CPS under
the IID model and covariate shift, similarly as Tibshirani et al. (2019) for CP. We can con-
struct prediction intervals by extracting specific percentiles from the conformal predictive
distributions, e.g., the 10th and 90th percentile, which are the lower and upper bound of
the 80% prediction interval.
Next, we evaluate the performance of the predictive distributions generated by CPS
under the IID model and covariate shift. We consider the continuous ranked probability
score (CRPS) to evaluate this, as it is a proper scoring rule for probabilistic forecasting
(Gneiting and Raftery, 2007; Gneiting et al., 2007). The CRPS is defined as
CRPS(F, yi) =
Z ∞
−∞
(F(y) −1{y≥yi})2dy
(18)
where F is the distribution function F : R →[0, 1], yi is the observed label, and 1 represents
the indicator function. The CRPS most minimal value, 0, is achieved when all probability of
the predictive distribution is concentrated in yi. Otherwise, the CRPS will be positive. Since
SCPS and WSCPS are somewhat fuzzy, the CRPS cannot be computed directly. Therefore,
we use the modification of SCPS, proposed by Vovk et al. (2020a), and adapt it to WSCPS,
which ignores the fuzziness represented by the random variable τ ∼Uniform(0, 1).
9

Jonkers Van Wallendael Duchateau Van Hoecke
Finally, we validate by simulation Conjecture 5 by producing p-values with the (W)SCPS
by setting y to the label yn+1 and checking if their histogram follows a uniform distribution.
In the probabilistic forecasting literature, this is often referred to as probability integral
transforms (PIT) histograms (Gneiting et al., 2007).
Coverage of intervals under covariate shift
The results are depicted in Figure 1. We
observe similar results as WCP (Tibshirani et al., 2019); in row 1 of Figure 1) we observe
undercoverage for SCPS under covariate shift. The WSCPS brings the average coverage to
the desired level under covariate shift for both experiments, while the SCPS constructed
intervals considerably undercover; see row 2 of Figure 1. We also observe that the heuristic
for the reduced (effective) calibration set size due to the weighting operation of WCP, see
Equation 8, is also a good heuristic for WSCPS. This is shown in the third row of Figure
1, where we observe similar dispersion of coverage over experiment trials for WSCPS and
SCPS with a reduced calibration set.
Quality of predictive distribution under covariate shift
Figure 2 shows the perfor-
mance of different SCPS in terms of CRPS across the different trials. We see a performance
difference when a covariate shift is present and not. The WSCPS consistently (slightly)
outperforms the SCPS under covariate shift for both datasets. However, it is difficult to see
in the second row of Figure 2. Therefore, we also perform a post-hoc Friedman-Nemenyi
test (see Figure 3). The SCPS under no shift with a calibration set size equal to the effective
sample size of WSCPS has a significantly better CRPS score than WSCPS. This is expected
since under covariate shift, the model ˆµ is trained on training data differently distributed
as the test set, as Tibshirani et al. (2019) also indicated. Ideally, ˆµ should be adjusted for
the covariate shift; however, we leave this for future work.
Probabilistic calibration under covariate shift
We validate by simulation Conjecture
5, which states that under covariate shift, the weighted split conformal transducer produced
p-values are distributed uniformly on [0, 1] when we know the likelihood ratio of the covariate
distribution of the training and test set. The results of the simulation experiments, depicted
in Figure 4, indicate that Conjecture 5 is empirically valid and that it breaks when we do
not account for the covariate shift.
5. Conclusion
We have introduced a novel extension to conformal predictive systems (CPS) to address
covariate shifts in predictive modeling. Covariate shifts are a common challenge in real-
world machine learning applications. Our proposed approach, weighted (split) Conformal
predictive systems (W(S)CPS), leverages the likelihood ratio between training and testing
data distributions to construct calibrated predictive distributions.
We outlined the theoretical framework of WCPS and WSCPS, demonstrating their
formal definition and properties. Similarly, as Tibshirani et al. (2019), we built upon the
foundation of CPS and extended the concept to handle covariate shifts effectively. Our
theoretical analysis included conjectures regarding the probabilistic calibration of WCPS
under covariate shift, paving the way for future research in this area.
Additionally, we
successfully validated these conjectures with simulation experiments.
10

Conformal Predictive Systems Under Covariate Shift
0
50
100
150
200
250
Count
Method
SCPS (no shift)
SCPS (shift)
0
25
50
75
100
125
150
175
Count
Method
SCPS (shift)
WSCPS (shift)
0.5
0.6
0.7
0.8
0.9
1.0
Coverage
0
25
50
75
100
125
150
175
Count
Method
WSCPS (shift)
SCPS (no shift, reduced)
(a) Airfoil data
0
50
100
150
200
250
Count
Method
SCPS (no shift)
SCPS (shift)
0
25
50
75
100
125
150
175
200
Count
Method
SCPS (shift)
WSCPS (shift)
0.5
0.6
0.7
0.8
0.9
Coverage
0
25
50
75
100
125
150
175
Count
Method
WSCPS (shift)
SCPS (no shift, reduced)
(b) Synthetic data
Figure 1: Empirical coverage of 80% prediction intervals from (W)SCPS, computed using
1000 different random splits of the airfoil and synthetic dataset.
11

Jonkers Van Wallendael Duchateau Van Hoecke
0
50
100
150
200
250
300
Count
Method
SCPS (no shift)
SCPS (shift)
0
20
40
60
80
100
120
140
Count
Method
SCPS (shift)
WSCPS (shift)
1.5
2.0
2.5
3.0
CRPS
0
50
100
150
200
250
300
Count
Method
WSCPS (shift)
SCPS (no shift, reduced)
(a) Airfoil data
0
100
200
300
400
500
Count
Method
SCPS (no shift)
SCPS (shift)
0
50
100
150
200
250
Count
Method
SCPS (shift)
WSCPS (shift)
4
6
8
10
12
14
CRPS
0
50
100
150
200
250
300
350
400
Count
Method
WSCPS (shift)
SCPS (no shift, reduced)
(b) Synthetic data
Figure 2: Empirical CRPS of (W)SCPS, computed using 1000 different experiment trials
for both airfoil and synthetic datasets.
12

Conformal Predictive Systems Under Covariate Shift
0.3
0.4
0.5
0.6
0.7
0.8
0.9
SCPS (no shift) (0.29)
SCPS (no shift, reduced) (0.47)
(0.92) SCPS (shift)
(0.83) WSCPS (shift)
(a) Airfoil data
0.3
0.4
0.5
0.6
0.7
0.8
0.9
SCPS (no shift) (0.32)
SCPS (no shift, reduced) (0.48)
(0.88) SCPS (shift)
(0.81) WSCPS (shift)
(b) Synthetic data
Figure 3: Post-hoc Friedman-Nemenyi test for CRPS.
0.0
0.2
0.4
0.6
0.8
1.0
Q(X,y)
0
200
400
600
800
1000
Count
Kolmogorov
Smirnov test
Statistic: 0.0069
p-value: 0.7315
Distribution of SCPS(X,y)
(no shift)
0.0
0.2
0.4
0.6
0.8
1.0
Q(X,y)
Kolmogorov
Smirnov test
Statistic: 0.0802
p-value: 0.0000
Distribution of SCPS(X,y)
(shift)
0.0
0.2
0.4
0.6
0.8
1.0
Q(X,y)
Kolmogorov
Smirnov test
Statistic: 0.0071
p-value: 0.6941
Distribution of WSCPS(X,y)
(shift)
Figure 4: Distribution of p-values of SCPS under IID model (blue), covariate shift (orange),
and WSCPS (green). The red dashed line represents the uniform distribution the
p-values need to follow so that the (W)SCPS is probabilistically calibrated.
13

Jonkers Van Wallendael Duchateau Van Hoecke
In future work, we aim to provide rigorous proofs for the conjectures presented in this
paper to establish the theoretical underpinnings of our proposed methods. Additionally, we
will evaluate our proposed framework for counterfactual inference and incorporate it into
our recently proposed conformal Monte-Carlo meta-learners (Jonkers et al., 2024b), which
opens the possibility of giving validity guarantees for predictive distributions of individual
treatment effect beyond the randomized trial setting. Moreover, we believe that similar
applications and extensions of the WCP (Tibshirani et al., 2019), such as addressing label
shift (Podkopaev and Ramdas, 2021), feedback covariate shift (Fannjiang et al., 2022), and
survival analysis (Cand`es et al., 2023), could be applied to WSCPS. Overall, our contribu-
tions offer a promising avenue for addressing covariate shifts in predictive modeling, with
potential applications in diverse fields such as healthcare, finance, and climate science.
Acknowledgments
Part of this research was supported through the Flemish Government (AI Research Pro-
gram).
References
Henrik Bostr¨om.
crepes: a Python Package for Generating Conformal Regressors and
Predictive Systems.
In Proceedings of the Eleventh Symposium on Conformal and
Probabilistic Prediction with Applications, pages 24–41. PMLR, August 2022.
URL
https://proceedings.mlr.press/v179/bostrom22a.html. ISSN: 2640-3498.
Henrik Bostr¨om, Ulf Johansson, and Tuwe L¨ofstr¨om.
Mondrian conformal predictive
distributions.
In Proceedings of the Tenth Symposium on Conformal and Probabilis-
tic Prediction and Applications, pages 24–38. PMLR, September 2021.
URL https:
//proceedings.mlr.press/v152/bostrom21a.html.
Emmanuel J. Cand`es, Lihua Lei, and Zhimei Ren. Conformalized Survival Analysis, April
2023. URL http://arxiv.org/abs/2103.09763. arXiv:2103.09763 [stat].
Dheeru Dua and Graff Casey. UCI machine learning repository. 2017.
Clara Fannjiang, Stephen Bates, Anastasios N. Angelopoulos, Jennifer Listgarten, and
Michael I. Jordan. Conformal prediction under feedback covariate shift for biomolecular
design. Proceedings of the National Academy of Sciences, 119(43):e2204569119, October
2022. doi: 10.1073/pnas.2204569119. URL https://www.pnas.org/doi/abs/10.1073/
pnas.2204569119. Publisher: Proceedings of the National Academy of Sciences.
Isaac Gibbs and Emmanuel Candes.
Adaptive Conformal Inference Under Distribution
Shift. In Advances in Neural Information Processing Systems, volume 34, pages 1660–
1672. Curran Associates, Inc., 2021. URL https://proceedings.neurips.cc/paper/
2021/hash/0d441de75945e5acbc865406fc9a2559-Abstract.html.
Isaac Gibbs, John J. Cherian, and Emmanuel J. Cand`es.
Conformal Prediction With
Conditional Guarantees, December 2023.
URL http://arxiv.org/abs/2305.12616.
arXiv:2305.12616 [stat].
14

Conformal Predictive Systems Under Covariate Shift
Tilmann Gneiting and Adrian E Raftery.
Strictly Proper Scoring Rules, Predic-
tion, and Estimation.
Journal of the American Statistical Association, 102(477):
359–378, March 2007.
ISSN 0162-1459.
doi:
10.1198/016214506000001437.
URL
https://doi.org/10.1198/016214506000001437. Publisher: Taylor & Francis eprint:
https://doi.org/10.1198/016214506000001437.
Tilmann Gneiting, Fadoua Balabdaoui, and Adrian E. Raftery.
Probabilistic forecasts,
calibration and sharpness. Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 69(2):243–268, 2007.
ISSN 1467-9868.
doi: 10.1111/j.1467-9868.2007.
00587.x.
URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.
2007.00587.x.
Arthur Gretton, Alex Smola, Jiayuan Huang, Marcel Schmittfull, Karsten Borgwardt,
and Bernhard Sch¨olkopf. Covariate Shift by Kernel Mean Matching. In Dataset Shift
in Machine Learning. MIT Press, Cambridge, Mass., December 2008.
ISBN 978-0-
262-25510-3.
URL https://direct.mit.edu/books/edited-volume/3841/chapter/
125883/Covariate-Shift-by-Kernel-Mean-Matching.
Ulf Johansson, Tuwe L¨ofstr¨om, and Henrik Bostr¨om. Conformal Predictive Distribution
Trees. Annals of Mathematics and Artificial Intelligence, June 2023. ISSN 1573-7470. doi:
10.1007/s10472-023-09847-0. URL https://doi.org/10.1007/s10472-023-09847-0.
Jef Jonkers, Diego Nieves Avendano, Glenn Van Wallendael, and Sofie Van Hoecke. A novel
day-ahead regional and probabilistic wind power forecasting framework using deep CNNs
and conformalized regression forests.
Applied Energy, 361:122900, May 2024a.
ISSN
0306-2619. doi: 10.1016/j.apenergy.2024.122900. URL https://www.sciencedirect.
com/science/article/pii/S0306261924002836.
Jef Jonkers, Jarne Verhaeghe, Glenn Van Wallendael, Luc Duchateau, and Sofie Van Hoecke.
Conformal Convolution and Monte Carlo Meta-learners for Predictive Inference of In-
dividual Treatment Effects, June 2024b.
URL http://arxiv.org/abs/2402.04906.
arXiv:2402.04906 [cs, stat].
Joseph
D.
Y.
Kang
and
Joseph
L.
Schafer.
Demystifying
Double
Robust-
ness:
A
Comparison
of
Alternative
Strategies
for
Estimating
a
Population
Mean
from
Incomplete
Data.
Statistical
Science,
22(4):523–539,
Novem-
ber
2007.
ISSN
0883-4237,
2168-8745.
doi:
10.1214/07-STS227.
URL
https://projecteuclid.org/journals/statistical-science/volume-22/issue-4/
Demystifying-Double-Robustness--A-Comparison-of-Alternative-Strategies-for/
10.1214/07-STS227.full.
Harris Papadopoulos, Kostas Proedrou, Volodya Vovk, and Alex Gammerman. Inductive
Confidence Machines for Regression.
In Tapio Elomaa, Heikki Mannila, and Hannu
Toivonen, editors, Machine Learning: ECML 2002, Lecture Notes in Computer Science,
pages 345–356, Berlin, Heidelberg, 2002. Springer. ISBN 978-3-540-36755-0. doi: 10.
1007/3-540-36755-1 29.
15

Jonkers Van Wallendael Duchateau Van Hoecke
Aleksandr Podkopaev and Aaditya Ramdas. Distribution-free uncertainty quantification
for classification under label shift.
In Proceedings of the Thirty-Seventh Conference
on Uncertainty in Artificial Intelligence, pages 844–853. PMLR, December 2021. URL
https://proceedings.mlr.press/v161/podkopaev21a.html. ISSN: 2640-3498.
Drew Prinster, Anqi Liu, and Suchi Saria. JAWS: Auditing Predictive Uncertainty Under
Covariate Shift. Advances in Neural Information Processing Systems, 35:35907–35920,
December 2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/
hash/e944bacecce6b06374ac39b260348db0-Abstract-Conference.html.
Sashank Reddi, Barnabas Poczos, and Alex Smola. Doubly Robust Covariate Shift Cor-
rection. Proceedings of the AAAI Conference on Artificial Intelligence, 29(1), February
2015.
ISSN 2374-3468.
doi: 10.1609/aaai.v29i1.9576.
URL https://ojs.aaai.org/
index.php/AAAI/article/view/9576.
Glenn Shafer and Vladimir Vovk. A Tutorial on Conformal Prediction. Journal of Ma-
chine Learning Research, 9(12):371–421, 2008.
ISSN 1533-7928.
URL http://jmlr.
org/papers/v9/shafer08a.html.
Ryan J Tibshirani, Rina Foygel Barber, Emmanuel Candes, and Aaditya Ramdas. Confor-
mal Prediction Under Covariate Shift. In Advances in Neural Information Processing Sys-
tems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.
cc/paper/2019/hash/8fb21ee7a2207526da55a679f0332de2-Abstract.html.
Vladimir Vovk.
Universal predictive systems.
Pattern Recognition, 126:108536, June
2022.
ISSN 0031-3203.
doi:
10.1016/j.patcog.2022.108536.
URL https://www.
sciencedirect.com/science/article/pii/S0031320322000176.
Vladimir Vovk, Ilia Nouretdinov, Valery Manokhin, and Alex Gammerman.
Confor-
mal Predictive Distributions with Kernels.
In Lev Rozonoer, Boris Mirkin, and Ilya
Muchnik, editors, Braverman Readings in Machine Learning. Key Ideas from Inception
to Current State: International Conference Commemorating the 40th Anniversary of
Emmanuil Braverman’s Decease, Boston, MA, USA, April 28-30, 2017, Invited Talks,
Lecture Notes in Computer Science, pages 103–121. Springer International Publish-
ing, Cham, 2018.
ISBN 978-3-319-99492-5.
doi: 10.1007/978-3-319-99492-5 4.
URL
https://doi.org/10.1007/978-3-319-99492-5_4.
Vladimir Vovk, Jieli Shen, Valery Manokhin, and Min-Ge Xie. Nonparametric predictive
distributions based on conformal prediction. Machine Language, 108(3):445–474, March
2019. ISSN 0885-6125. doi: 10.1007/s10994-018-5755-8. URL https://doi.org/10.
1007/s10994-018-5755-8.
Vladimir Vovk, Ivan Petej, Ilia Nouretdinov, Valery Manokhin, and Alexander Gammer-
man. Computationally efficient versions of conformal predictive distributions. Neurocom-
puting, 397:292–308, July 2020a. ISSN 0925-2312. doi: 10.1016/j.neucom.2019.10.110.
URL https://www.sciencedirect.com/science/article/pii/S0925231219316042.
16

Conformal Predictive Systems Under Covariate Shift
Vladimir Vovk, Ivan Petej, Paolo Toccaceli, Alexander Gammerman, Ernst Ahlberg, and
Lars Carlsson. Conformal calibrators. In Proceedings of the Ninth Symposium on Confor-
mal and Probabilistic Prediction and Applications, pages 84–99. PMLR, August 2020b.
URL https://proceedings.mlr.press/v128/vovk20a.html. ISSN: 2640-3498.
Vladimir Vovk, Alexander Gammerman, and Glenn Shafer.
Algorithmic Learning in a
Random World. Springer International Publishing, Cham, 2022. ISBN 978-3-031-06648-
1 978-3-031-06649-8. doi: 10.1007/978-3-031-06649-8. URL https://link.springer.
com/10.1007/978-3-031-06649-8.
Yachong Yang, Arun Kumar Kuchibhotla, and Eric Tchetgen Tchetgen. Doubly Robust
Calibration of Prediction Sets under Covariate Shift, December 2022.
URL http://
arxiv.org/abs/2203.01761. arXiv:2203.01761 [math, stat].
Appendix A. Split Conformal Predictive System
For split CPS (SCPS), the same procedure is followed as a split conformal prediction; the
training sequence z1:n is split into two: a proper training sequence z1:m and calibration
sequence zm+1:n. Similarly as an CPS, an SCPS is defined as a function that is both a split
conformal transducer (Definition 8) and an RPS (Definition 2) (Vovk et al., 2020a).
Definition 7 (Inductive (Split) Conformity Measure, Vovk et al. (2022)) A split
conformity measure is a measurable function A : Zm × Z →R that is invariant with respect
to permutations of the proper training sequence z1:m.
Definition 8 (Split Conformal Transducer, Vovk et al. (2020a))
The split confor-
mal transducer determined by a split conformity measure A (see Definition 7) is defined
as,
Q(z1, ..., zn, (xn+1, y), τ) :=
n
X
i=m+1
[Ri < Ry
n+1]
1
n −m + 1
+
n
X
i=m+1
[Ri = Ry
n+1]
τ
n −m + 1
+
τ
n −m + 1
(19)
where conformity scores Ri and Ry are defined by
Ri := A(z1, ..., zm, (xi, yi)),
i = m + 1, ..., n,
Ry
n+1 := A(z1, ..., zm, (xn+1, yn+1)),
y ∈R.
Vovk et al. (2020a) proofs that any split conformal transducer is an RPS if and only if
it is based on a balanced isotonic split conformity measure (Definition 10).
Definition 9 (Isotonic Split Conformity Measure, Vovk et al. (2020a)) A split con-
formity measure A is isotonic if, for all m, z1:m, and x, A(z1, ..., zm, (x, y)) is isotonic in
y, i.e.,
y ≤y′ ⇒A(z1, ..., zm, (x, y)) ≤A(z1, ..., zm, (x, y′))
17

Jonkers Van Wallendael Duchateau Van Hoecke
Definition 10 (Balanced Isotonic Split Conformity Measure, Vovk et al. (2020a))
An isotonic split conformity measure A (see Definition 9) is balanced if, for any m and
z1, ..., zm, the set
conv A(z1, ..., zm, (x, R)) := conv {A(z1, ..., zm, (x, y))|y ∈R}
where conv stands for the convex closure in R.
Appendix B. Python Package: crepes-weighted
For the simulation experiments in this work, we implemented the proposed WSCPS and
the WCP (Tibshirani et al., 2019) in crepes-weighted, which is an extension of crepes
(Bostr¨om, 2022), a Python package that implements conformal classifiers, regressors, and
predictive systems on top of any standard classifier and regressor. crepes-weighted re-
lies on the same classes and functions as crepes, with the slight modification that for
the ConformalRegressor and ConformalPredictiveSystem classes, the methods fit and
predict needs to include the likelihood ratios of each calibration and test object respec-
tively.
The source code of crepes-weighted is made open-source and can be found at https:
//github.com/predict-idlab/crepes-weighted.
18
