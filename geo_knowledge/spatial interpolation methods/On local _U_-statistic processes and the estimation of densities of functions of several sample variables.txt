arXiv:0708.2227v1  [math.ST]  16 Aug 2007
The Annals of Statistics
2007, Vol. 35, No. 3, 1105â€“1145
DOI: 10.1214/009053607000000154
c
âƒInstitute of Mathematical Statistics, 2007
ON LOCAL U-STATISTIC PROCESSES AND THE ESTIMATION
OF DENSITIES OF FUNCTIONS OF SEVERAL
SAMPLE VARIABLES
By Evarist GinÂ´e1 and David M. Mason2
University of Connecticut and University of Delaware
A notion of local U-statistic process is introduced and central
limit theorems in various norms are obtained for it. This involves
the development of several inequalities for U-processes that may be
useful in other contexts. This local U-statistic process is based on
an estimator of the density of a function of several sample variables
proposed by Frees [J. Amer. Statist. Assoc. 89 (1994) 517â€“525] and,
as a consequence, uniform in bandwidth central limit theorems in the
sup and in the Lp norms are obtained for these estimators.
1. Introduction.
Let X,X1,X2,... be i.i.d. random variables taking val-
ues in R, with common density function f and consider the kernel density
estimator of f deï¬ned for t âˆˆR,
fn(t,hn) = (nhn)âˆ’1
n
X
i=1
K(hâˆ’1
n (t âˆ’Xi)) =: nâˆ’1
n
X
i=1
Khn(t âˆ’Xi),
(1.1)
where {hn}nâ‰¥1 is a sequence of positive constants converging to zero at the
rate nhn â†’âˆand the kernel K is an integrable (real) function of bounded
variation satisfying
R
R K(x)dx = 1 (Parzen [27]). It is easy to prove that,
subject to smoothness conditions on f, for each t âˆˆR,
p
hnun(t) :=
p
nhn{fn(t,hn) âˆ’Efn(t,hn)} â†’d N(0,âˆ¥Kâˆ¥2
2f(t)),
whereas for any choice of t1 Ì¸= t2 the random variables âˆšhnun(t1) and âˆšhnun(t2)
are asymptotically independent. This means that âˆšhnun cannot converge
weakly to a continuous bounded process on any nontrivial subinterval of R.
Received March 2005; revised May 2006.
1Supported in part by NSA Grant H98230-04-1-0075.
2Supported in part by NSA Grant MDA904-02-1-0034 and NSF Grant DMS-02-03865.
AMS 2000 subject classiï¬cations. 60F05, 60F15, 62E20, 62G30.
Key words and phrases. U-statistics, central limit theorems, empirical process, kernel
density estimation.
This is an electronic reprint of the original article published by the
Institute of Mathematical Statistics in The Annals of Statistics,
2007, Vol. 35, No. 3, 1105â€“1145. This reprint diï¬€ers from the original in
pagination and typographic detail.
1

2
E. GINÂ´E AND D. M. MASON
Since the bias Efn(t,hn) âˆ’f(t) can always be dealt with under the usual
conditions on K and f, this tells us that fn(t,hn) estimates the density f
at a much slower rate than nâˆ’1/2. On the other hand, Frees [15] discovered
the perhaps surprising fact that the densities fg(t) of some symmetric real
functions g(X1,...,Xm) of m > 1 i.i.d. random variables can be estimated
at each ï¬xed t at the rate nâˆ’1/2, using the U-statistic estimator
(n âˆ’m)!
n!
X
iâˆˆIm
n
Khn(t âˆ’g(Xi1,...,Xim)),
where i = (i1,...,im) and Im
n = {(i1,...,im):1 â‰¤ij â‰¤n,ij Ì¸= ik if j Ì¸= k}.
Schick and Wefelmeyer [32] consider the special case
g(X1,...,Xm) =
m
X
i=1
ui(Xi),
which however is not necessarily a symmetric function. Using convolution
kernels, they also obtain the (in probability) rate of nâˆ’1/2 for the sup norm
and the L1 norm measure of the discrepancy between the estimator and
the density (actually, they obtain limit theorems in distribution). These
results require smoothness conditions on the kernel, the density and certain
conditional densities.
Our aim is to extend the Schick and Wefelmeyer results to the Frees
framework and with g not necessarily symmetric. Moreover, we frame our
results uniform in bandwidth in the sup norm and the Lp norm with p â‰¥1 so
that they can be used with adaptive bandwidth estimators. Also, we do this
not necessarily in one dimension, but in Rd. These extensions substantially
increase the scope of applicability of the results and, as a consequence, we
can show how our results recover, extend and/or improve upon, previous
work by several authors. We shall not discuss removing the bias in general
but only in some examples and very brieï¬‚y. The bias is not probabilistic and
can always be treated by adding enough smoothness to the kernel and the
density (see, e.g., the two references just cited and Ahmad and Fan [1]).
We shall begin by generalizing the setup in GinÂ´e, Mason and Zaitsev
[21] (concretely, that of Examples 1.2 and 1.3 there) and Mason [25] to
U-statistics. Throughout this paper, we let X,Xi, i âˆˆN, be i.i.d. random
variables taking values in a measurable space (S,S); let g :Sm 7â†’Rd, 1 â‰¤d <
âˆ, be a measurable function; let K :Rd 7â†’R be an integrable measurable
function that integrates to 1 (a â€œkernelâ€); and let 0 < a â‰¤b < âˆ. Then, for
t âˆˆRd and Î» âˆˆ[a,b], we introduce the local U-statistic
Un(t,Î») := (n âˆ’m)!
n!
X
iâˆˆIm
n
KÎ»hn(t âˆ’g(Xi1,...,Xim)),
(1.2)

LOCAL U-STATISTIC PROCESS
3
where, here and elsewhere in this paper, for functions H :Rd 7â†’R and h > 0,
the notation
Hh(t) := hâˆ’1H(t/h1/d),
t âˆˆRd,
(1.3)
is in force. The term â€œlocalâ€ just reï¬‚ects the fact that the U-process (1.2)
is of a special kind, namely a convolution of an approximate identity KÎ»hn
with an â€œempirical measure,â€ in this case ((n âˆ’m)!/n!) P
Im
n Î´g(Xi1,...,Xim),
and therefore, for each value of t, the largest contributions to the statistic
come from the values g(Xi1,...,Xim) closest to t.
Special cases of Un(t,Î»), when X1,...,Xn are i.i.d. Rd valued, include
the interpoint distance studied by Jammalamadaka and Janson [23], with
g(x,y) = |x âˆ’y|,
hnUn(0,1) =
1
n(n âˆ’1)
X
iâˆˆI2n
I{|Xi1 âˆ’Xi2| â‰¤hn}
and the related short distance process studied by Eastwood and HorvÂ´ath
[12],
1
n(n âˆ’1)
X
iâˆˆI2n
I{d(Xi1,Xi2) â‰¤Î»hn},
0 â‰¤Î» â‰¤1,
where d is a distance on Rd, as well as the U-statistic estimator of the
density of the sum X1 + Â·Â·Â· + Xm,
(n âˆ’m)!
n!
X
iâˆˆIm
n
Khn(t âˆ’Xi1 âˆ’Â·Â·Â· âˆ’Xim).
Our goal is to obtain central limit theorems for the following local U -statistic
process formed from Un(t,Î»):
un,Î»(t) := âˆšn{Un(t,Î») âˆ’EKÎ»hn(t âˆ’g(X1,...,Xm))},
(1.4)
t âˆˆRd,Î» âˆˆ[a,b].
The case when m = 1 is a special case of the local empirical process studied
in Mason [25]. We shall conï¬ne our attention to the case m â‰¥2, which we
shall soon see has a radically diï¬€erent asymptotic behavior than the case
m = 1. Occasionally, we may restrict the process to t âˆˆD âŠ‚Rd, where D
may even consist of a single point.
The limit theorems to be obtained for these processes will be in the sup
and in the Lp norms, 1 â‰¤p < âˆ, uniformly in Î» âˆˆ[a,b] (precise deï¬nitions in
the next section). The reason these results will be true will be essentially the
same as in Frees [15], namely: (1) the process (1.4) is equivalent to its linear
part, that is, all the terms in its Hoeï¬€ding decomposition of order higher

4
E. GINÂ´E AND D. M. MASON
than one tend to zero in the appropriate way; (2) that this linearization,
which is a smoothed empirical process, is equivalent to the empirical process
without smoothing, hence independent of Î» and hn; (3) that this empirical
process, under appropriate and quite weak conditions, satisï¬es the central
limit theorem in the sup norm or in the Lp norms.
The devil is in the details, and extending the Frees result from one point
t âˆˆR, to uniformity in t âˆˆRd and in Î» âˆˆ[a,b], makes for very diï¬€erent
proofs and requires a substantial amount of technique, some of it new.
The statements of the central limit theorems, along with examples, are
collected in Section 2 and all the proofs are postponed to Section 3. In the
process of establishing our results we shall develop some tools that should
be of separate interest. Among them include tight bounds for the absolute
moment of the supremum of the U-statistic process under a uniform cover-
ing number bound generalizing a similar bound obtained by Einmahl and
Mason [13] and GinÂ´e and Koltchinskii [17] (see also GinÂ´e and Guillou [16])
for the usual empirical process. All of these results were motivated by Propo-
sition 6.2 of Talagrand [35], which is an expectation bound for VC classes of
sets, where VC stands for Vapnik and Ë‡Cervonenkis. We also obtain moment
and exponential inequalities for Banach space valued U-statistics which, al-
though not necessarily optimal, are very easy to apply and are well adapted
to the problems treated in this article. In a sequel to this paper (GinÂ´e and
Mason [20]), we derive the corresponding functional laws of the logarithm
for un,Î».
2. Main results and examples.
As is usual when dealing with empirical
processes, we take ((S Ã— T)N,(S âŠ—T )N,Pr) as the underlying probability
space, where (S,S) is a measurable space, T = {âˆ’1,1}, T is the family of
all subsets of T, and Pr = P N Ã— (P â€²)N, P a probability measure on (S,S)
and P â€² the uniform distribution on T. Then the random variables Xi are
the projections (S Ã— T)N 7â†’S, Xi(s1,t1,s2,t2,...) = si, which are i.i.d. with
law P. We will occasionally use the random variables Îµi(s1,t1,s2,t2,...) =
ti, which obviously satisfy Pr{Îµi = 1} = Pr{Îµi = âˆ’1} = 1/2. Note that the
random variables {Xi,Îµj :i,j âˆˆN} are independent. The variables Îµi are
often called Rademacher variables. Sometimes we will write X for X1.
All the asymptotic results on the process un,Î» in this article require the
following key assumption.
For each i = 1,...,m, the random variable g(X1,...,Xm), con-
ditionally on Xi = x, x âˆˆS, has a density fi(t,x), t âˆˆRd, which
is jointly measurable in t and x.
(CD)
Note that, setting
f =
m
X
i=1
f i,
(2.1)

LOCAL U-STATISTIC PROCESS
5
the function
fg(t) := E[f(t,X)]/m,
t âˆˆRd,
(2.2)
deï¬nes a density for the random variable g(X1,...,Xm). Another condition
that we will require for diï¬€erent values of p âˆˆ[1,âˆ] is
âˆ¥f(Â·,x)âˆ¥p < âˆ
for all x âˆˆS and âˆ¥fgâˆ¥p < âˆ.
(CDp)
Here and elsewhere, âˆ¥Â· âˆ¥p denotes the Lp(Rd) norm for 1 â‰¤p < âˆand
the sup norm on Rd for p = âˆ.
The asymptotics of the processes un,Î» will turn out to be equivalent to
that of the processes
Î½n(t) = 1
âˆšn
n
X
i=1
(f(t,Xi) âˆ’E[f(t,Xi)]),
t âˆˆRd,
(2.3)
which are empirical processes. With some abuse of notation, we say that
Î½n converges in law in Lâˆ(Rd)
(2.4)
if condition (CDâˆ) holds and the class of functions {f(t,Â·):tâˆˆRd} is P-Donsker.
We refer to Dudley [10] or van der Vaart and Wellner [37] for the deï¬nition of
Donsker classes of functions. The condition (CDâˆ) is equivalent to the maps
t 7â†’f(t,x) and t 7â†’Ef(t,X) being in â„“âˆ(Rd), the abuse of notation consists
in replacing this last space by Lâˆ(Rd), which usually means something else,
and the precise meaning of (2.4) is that limnâ†’âˆEH(Î½n)âˆ—= EH(G) for ev-
ery H :â„“âˆ(Rd) 7â†’R bounded and continuous, where G = {G(t):t âˆˆRd} is
the centered Gaussian process with the covariance of f(Â·,X), more precisely
a sample continuous version, and H(Î½n)âˆ—is the (a.s.) smallest measurable
function larger than or equal to H(Î½n). Likewise, for 1 â‰¤p < âˆ, we say that
Î½n converges in law in Lp(Rd)
(2.5)
if the condition (CDp) holds and the Lp(Rd)-valued random variable f(Â·,X)
satisï¬es the central limit theorem in this space, that is, there is a centered
Gaussian process G with the same covariance as f(Â·,X) and with sample
paths in Lp(Rd), such that for every H :Lp(Rd) 7â†’R bounded and contin-
uous,
lim
nâ†’âˆEH(Î½n) = EH(G).
Note that in each case, Î½n(Â·) is a random variable that takes values in
Lp(Rd), 1 â‰¤p â‰¤âˆ, although in the case p = âˆ, with abuse of notation:
Î½n(Â·) is really in â„“âˆ(Rd), the space of bounded functions on Rd, and Î½n is
not necessarily measurable.
The following deï¬nition describes the type of central limit theorem we
will prove for the process un,Î».

6
E. GINÂ´E AND D. M. MASON
Definition 1.
Let 1 â‰¤p â‰¤âˆand assume (CD) and (CDp). The pro-
cesses un,Î» converge weakly in Lp(Rd), uniformly in a â‰¤Î» â‰¤b, to the cen-
tered Gaussian process G with the same covariance as f(Â·,X) if
sup
Î»âˆˆ[a,b]
âˆ¥un,Î» âˆ’Î½nâˆ¥p â†’0
in prâˆ—
and Î½n converges weakly in Lp(Rd) in the sense of (2.4) for p = âˆand (2.5)
for p < âˆ.
Convergence in prâˆ—means convergence in probability of the measurable
envelopes (the smallest dominating measurable functions).
Note that in the case p = âˆ, convergence of un,Î» to G in the sense of
this deï¬nition implies that the processes (t,Î») 7â†’un,Î»(t) converge in law
in â„“âˆ(Rd Ã— [a,b]) to the Gaussian process G (de la PeËœna and GinÂ´e [7],
Dudley [10], or van der Vaart and Wellner [37] for this type of convergence).
However, our notion gives more. In fact if, for l = 1,...,N, we have functions
gl :Sml 7â†’Rdl such that the processes u(l)
n,Î» corresponding to g = gl converge
weakly in Lâˆ(Rdl), uniformly in al â‰¤Î» â‰¤bl, to a centered Gaussian process
Gl with the same covariance as Fl(Â·,X), where Fl is the f corresponding to
g = gl, then it is easy to conclude, using the obvious multivariate extension
of Deï¬nition 1, that the vector-valued processes âˆ’â†’un,Î»1,...,Î»N deï¬ned by
âˆ’â†’un,Î»1,...,Î»N (t1,...,tN) = (u(1)
n,Î»1(t1),...,u(N)
n,Î»N(tN)),
(2.6)
t1 âˆˆRd1,...,tN âˆˆRdN ,
converge weakly in Lâˆ(Rd1) Ã— Â·Â·Â· Ã— Lâˆ(RdN ) uniformly in al â‰¤Î»l â‰¤bl,
l = 1,...,N, to the centered vector-valued Gaussian process deï¬ned on Rd1 Ã—
Â·Â·Â· Ã— RdN ,
G(t1,...,tN) = (G1(t1),...,GN(tN)),
(2.7)
with the same covariance/cross covariance matrix as F(Â·,X), where
F(t1,...,tN,X) = (F1(t1,X),...,FN(tN,X)),
(2.8)
t1 âˆˆRd1,...,tN âˆˆRdN .
2.1. Central limit theorems.
We still require another deï¬nition. We say
that a class of measurable functions F deï¬ned on a measurable space (S,S)
is VC-type (VC for Vapnik and Ë‡Cervonenkis) with respect to an envelope
F (meaning a measurable function F such that |f| â‰¤F for all f âˆˆF) if the
covering number N(F,L2(Q),Îµ), deï¬ned as the smallest number of L2(Q)
open balls of radius Îµ required to cover F, satisï¬es
N(F,L2(Q),Îµ) â‰¤
Aâˆ¥Fâˆ¥L2(Q)
Îµ
v
,
0 < Îµ â‰¤2âˆ¥Fâˆ¥L2(Q),
(2.9)

LOCAL U-STATISTIC PROCESS
7
for some A â‰¥3 and v â‰¥1, for every probability measure Q on S for which
Q(F 2) < âˆ. If (2.9) holds for F, then we say that the VC class F admits
the characteristics A and v.
Theorem 1.
Let p = âˆ, let (CD) and (CDâˆ) hold, and let K be
bounded. Assume:
(a) each of the classes
Kn := {K(hâˆ’1/d(y âˆ’Â·)):y âˆˆRd,ahn â‰¤h â‰¤bhn}
(2.10)
is VC-type for a bounded envelope Fn and all the classes Kn admit the same
characteristics A and v;
(b) the density fg of g(X1,...,Xm) is bounded and the class of functions
F := {f(t,Â·):t âˆˆRd} is P-Donsker and the identity map
(Rd,| Â· |) 7â†’(Rd,Ï)
is uniformly continuous, where Ï2(u,v) = Var(f(u,X) âˆ’f(v,X));
(c) hn â†’0 and nhn/(1 âˆ¨log(Aâˆ¥Fnâˆ¥L2(fg)/âˆšhn))2 â†’âˆ. The processes
un,Î» then converge weakly in Lâˆ(Rd), uniformly in a â‰¤Î» â‰¤b, to the centered
Gaussian process with the same covariance as f(Â·,X).
Remark 1.
Theorem 1 has obvious applications to the construction
of conï¬dence bands for fg. It is formulated uniformly in a â‰¤Î» â‰¤b so as
to allow the possibility for Î» to be replaced by an estimator bÎ»n. Suppose
that bÎ»n = Î»n(X1,...,Xn) is an adaptive bandwidth selector such that for
all 0 < Îµ < 1 there exist 0 < c < d < âˆfor which for all large enough n
Pr{c < bÎ»n < d} â‰¥1 âˆ’Îµ.
(2.11)
Then if assumption (a) of Theorem 1 holds for any choice of 0 < a < b < âˆ
we can immediately conclude from (2.11) that the processes un,bÎ»n converge
weakly in Lâˆ(Rd) to the centered Gaussian process with the same covari-
ance as f(Â·,X). The analogous remark holds for Theorems 2 and 3 below.
For a thorough discussion of bandwidth estimators that satisfy (2.11) refer
to Deheuvels and Mason [5].
Remark 2.
We note that if the classes of functions Fi = {fi(t,Â·):t âˆˆ
Rd}, i = 1,...,m, are P-Donsker, then so is F given in (b) (e.g., The-
orem 2.10.6 in van der Vaart and Wellner [37] applied to the function
Ï†(t1,...,tm) = Pm
i=1 ti/âˆšm). A suï¬ƒcient condition for the class of functions
F being P-Donsker is that it be of VC-type, since the function f being
jointly measurable already ensures that this class of functions is measurable
(e.g., Deï¬nition 2.3.3, Example 2.3.5 and Theorem 2.5.2 (Pollardâ€™s CLT)

8
E. GINÂ´E AND D. M. MASON
in van der Vaart and Wellner [37], or Dudley [10], Theorem 6.3.1). These
two references contain many examples of classes of functions which are of
VC-type. We single out one of them which is particularly convenient for
condition (a) above. Let Î¨:R 7â†’R be a function of bounded variation on
R (Î¨ is the diï¬€erence of two bounded nondecreasing functions). The proof
of Lemma 22 in Nolan and Pollard [26] shows that if
K(x) = Î¨(p(x)),
x âˆˆRd,
(2.12)
where p is either a real polynomial on Rd or the Î±th power of the absolute
value of a real polynomial on Rd, Î± > 0, then the class of functions
K = {K(Î³âˆ’1(t âˆ’Â·)):t âˆˆRd,Î³ > 0}
is VC-type. Moreover, since the function K(Î³âˆ’1(tâˆ’x)) is jointly measurable,
this class is also measurable. Most kernels of interest satisfy condition (2.12),
and therefore, condition (a) in Theorem 1.
Sometimes one is interested only in weak convergence in Lâˆ(D) uniformly
in a â‰¤Î» â‰¤b, where D is a subset of Rd that may even consist of a single
point. For instance, this is the case for the interpoint distance process, where
K(x) = I{|x| â‰¤1}, S = Rd and g(x,y) = x âˆ’y. The following, which is
related to a result of Eastwood and HorvÂ´ath (year?), will be a corollary
to the proof of the above theorem. We say that a subset D of Rd is star-
shaped about 0 if x âˆˆD implies Î»x âˆˆD for all 0 â‰¤Î» â‰¤1.
Corollary 1.
Let D be a measurable bounded subset of Rd star-shaped
about 0 and with Vol(D) Ì¸= 0, and set K = ID/Vol(D). Assume that g(X1,...,
Xm) has a bounded density fg, that E[f(0,X)]2 < âˆand that for all Îµ > 0,
lim
Î´â†’0limsup
nâ†’âˆPrâˆ—

sup
|u|â‰¤Î´
|Î½n(u) âˆ’Î½n(0)| > Îµ

= 0.
(2.13)
Let hn â†’0 be such that nhn â†’âˆ. Then, the processes Î»un,Î»(0) converge
weakly in â„“âˆ((0,1]) to the process Î»ÏƒZ, 0 â‰¤Î» â‰¤1, where Z is standard
normal and Ïƒ2 = Var(f(0,X)).
It makes sense to deï¬ne Î»un,Î»(0) as zero for Î» = 0. With this convention,
in force from here on, we have weak convergence in â„“âˆ([0,1]) in this corollary.
Condition (2.13) is satisï¬ed, for instance, if the class FÎ´ := {f(t,Â·):|t| â‰¤Î´}
is P-Donsker for some Î´ > 0, a condition weaker than the class F being P-
Donsker.
Next we state the central limit theorems in the Lp norm, uniform on
a â‰¤Î» â‰¤b. We need to recall the deï¬nition of Young moduli of exponential
type. As in de la PeËœna and GinÂ´e [7], page 188, Î¨1(x) := ex âˆ’1, but if Î± < 1,

LOCAL U-STATISTIC PROCESS
9
since exÎ± is only convex for x â‰¥xÎ± := ((1 âˆ’Î±)/Î±)1/Î±, we take as a function
Î¨Î± that is 0 at 0, convex and increasing, and of the order of exÎ± for x large
the following:
Î¨Î±(x) := Ï„Î±(x) âˆ’Î±exp((1 âˆ’Î±)/Î±),
(2.14)
where Ï„Î±(x) equals exp(xÎ±) if x â‰¥xÎ±, and equals the tangent line to the
function y = exp(xÎ±) at x = xÎ± for 0 â‰¤x â‰¤xÎ±. We also recall that then, for
any nonnegative random variable Î¾ for which Ee(Î¾/a)Î± < âˆfor some a > 0,
âˆ¥Î¾âˆ¥Î¨Î± := inf{c:EÎ¨Î±(Î¾/c) â‰¤1}.
(2.15)
This is a (pseudo)norm and it dominates, up to constants that depend only
on Î± and p, all the Lp (pseudo)norms. Simple standard computations show
that
Pr{Î¾ > x} â‰¤bexp{âˆ’(x/a)Î±}
for all x > 0
=â‡’
âˆ¥Î¾âˆ¥Î¨Î± â‰¤Ca
(2.16)
for a constant C that depends only on Î± and b. Note also that Î¨âˆ’1
Î± (u) is
a constant times u for 0 â‰¤u â‰¤Î¨Î±(xÎ±) and it is the 1/Î±-th power of the
logarithm of u + Î±exp((1 âˆ’Î±)/Î±) for u â‰¥Î¨Î±(xÎ±).
Given a kernel K and 0 < a â‰¤b < âˆ, deï¬ne
K[a,b] := {Kh :h âˆˆ[a,b]} âˆª{0}.
(2.17)
For any two functions f and g in Lp, set
dp
p(f,g) =
Z
Rd |f(t) âˆ’g(t)|p dt.
(2.18)
Theorem 2.
Let 2 â‰¤p < âˆand let (CD) and (CDp) hold. Assume:
(a) the kernel K is in Lp(Rd) and
Z 1
0
Î¨âˆ’1
2/m(N(K[a,b],dp,Îµ))dÎµ < âˆ;
(2.19)
(b) the sum of conditional densities f deï¬ned in (2.1) satisï¬es
lim
tâ†’âˆt2 Pr{âˆ¥f(Â·,X) âˆ’Ef(Â·,X)âˆ¥p > t} = 0
(2.20)
and
Z
Rd[E(f(u,X) âˆ’Ef(u,X))2]p/2 du < âˆ;
(c) hn â†’0 and nh2(pâˆ’1)/p
n
â†’âˆ.
Then, the processes un,Î» converge weakly in Lp(Rd), uniformly in a â‰¤Î» â‰¤b,
to the centered Gaussian process with the same covariance as f(Â·,X).

10
E. GINÂ´E AND D. M. MASON
The two conditions in (2.20) are implied by the stronger but sometimes
more convenient conditions Eâˆ¥f i(Â·,X) âˆ’Efi(Â·,X)âˆ¥2
p < âˆfor i = 1,...,m.
This follows immediately from Minkowskiâ€™s inequality for integrals (e.g.,
Folland [14], page 194). Also, note that for p = 2 the ï¬rst condition in (2.20)
is superï¬‚uous.
We should remark here that the conditions (2.20) are precisely the neces-
sary and suï¬ƒcient conditions for the Lp(Rd)-valued random variable f(Â·,X)
to satisfy the central limit theorem, that is, for the processes Î½n to converge
in law to G in Lp(Rd), p â‰¥2 (Pisier and Zinn [29]; see also Araujo and GinÂ´e
[2], pages 206â€“207).
For 1 â‰¤p < 2 we need K2 and fg to satisfy certain moment assumptions,
and for this it will be convenient to have the following notation: for s > 0,
p â‰¥1, we deï¬ne the Borel measure Âµs on Rd, Lp(Âµs) and Ëœdp,s as
dÂµs(t) = (1 + |t|)s dt,
Lp(Âµs) = Lp(Rd,B,Âµs),
(2.21)
Ëœdp,s(f,g) = âˆ¥f âˆ’gâˆ¥Lp(Âµs),
the latter for functions f,g âˆˆLp(Âµs).
Theorem 3.
Let 1 â‰¤p < 2 and let (CD) and (CDp) hold. Assume K2
and fg are in L1(Âµs) for some s > d(2 âˆ’p)/p. Assume also:
(a) K is in Lp(Rd) and
Z 1
0
Î¨âˆ’1
1/m(N(K[a,b],dp âˆ¨Ëœd2,s,Îµ))dÎµ < âˆ;
(2.22)
(b) the sum f of conditional densities satisï¬es
Z
Rd[E(f(t,X) âˆ’Ef(t,X))2]p/2 dt < âˆ;
(2.23)
(c) hn â†’0 and nhn â†’âˆ.
Then, the processes un,Î» converge weakly in Lp(Rd), uniformly in a â‰¤Î» â‰¤b,
to the centered Gaussian process with the same covariance as f(Â·,X).
For p = 1, condition (2.23) is equivalent to
R [Ef
2(t,X)]1/2 dt < âˆ.
As above, we should also mention that condition (2.23) is precisely the
necessary and suï¬ƒcient condition for the Lp(Rd)-valued random variable
f(Â·,X) to satisfy the central limit theorem, that is, for the processes Î½n to
converge in law to G in Lp(Rd), 1 â‰¤p â‰¤2 (Vakhania [36] and Jain [22]; see
also Araujo and GinÂ´e [2], pages 206â€“207).
Remark 3.
All garden variety kernels satisfy the entropy assumptions of
Theorems 2 and 3. In fact, many such kernels are of the form K(x) = Î¨(|x|),

LOCAL U-STATISTIC PROCESS
11
where Î¨ is a function of bounded variation deï¬ned on [0,âˆ). To see this,
assume that for bounded nondecreasing functions M and N we can write
Î¨ = P âˆ’N. Further, assume that
Z âˆ
0
rdâˆ’1|M(r)|dr = M0 < âˆ
and
Z âˆ
0
rdâˆ’1|N(r)|dr = N0 < âˆ.
Deï¬ne the class of functions P = {r 7â†’rdâˆ’1Î¨(rÎ»1/d):Î» â‰¥1}. We claim that
this class satisï¬es for some A1 > 0,
N(P,d1,Îµ) â‰¤A1Îµâˆ’1,
0 < Îµ â‰¤1.
(2.24)
To verify this choose 1 â‰¤Î» â‰¤Âµ. We see that
Z âˆ
0
|rdâˆ’1Î¨(rÎ»1/d) âˆ’rdâˆ’1Î¨(rÂµ1/d)|dr
â‰¤
Z âˆ
0
rdâˆ’1[M(rÂµ1/d) âˆ’M(rÎ»1/d)]dr
+
Z âˆ
0
rdâˆ’1[N(rÂµ1/d) âˆ’N(rÎ»1/d)]dr
= (M0 + N0)(Î»âˆ’1 âˆ’Âµâˆ’1) =: C(Î»âˆ’1 âˆ’Âµâˆ’1).
Now as in the proof in Example 1.2 of GinÂ´e, Mason and Zaitsev [21] choose
open balls with centers at Î»k = C/(C âˆ’kÎµ) for k = 0,...,k0 where k0 is the
largest integer strictly less than C/Îµ. This shows (2.24).
Now consider the class of functions on Rd given by K = {x 7â†’K(Î»1/dx):
Î» â‰¥1}, where K(Î»1/dx) = Î¨(Î»1/d|x|). Since by changing to polar coordinates
Z
Rd |K(Î»1/dx) âˆ’K(Âµ1/dx)|dx = Cd
Z âˆ
0
rdâˆ’1|Î¨(rÎ»1/d) âˆ’Î¨(rÂµ1/d)|dr,
where Cd = dÏ€d/2/Î“(1 + d/2), we see from (2.24) that for some B1 > 0
N(KÎ»,d1,Îµ) â‰¤B1Îµâˆ’1,
0 < Îµ â‰¤1.
(2.25)
From this result along with boundedness of K we readily get that for all
p â‰¥1 there is a Bp > 0 such that
N(KÎ»,dp,Îµ) â‰¤BpÎµâˆ’p,
0 < Îµ â‰¤1.
(2.26)
It then follows easily that the class of functions K[a,b] formed from a kernel
of the form K(x) = Î¨(|x|) obeying the above conditions satisï¬es the en-
tropy condition of Theorems 2 and, if K has bounded support or decreases
exponentially in a positive power of |x|, that of Theorem 3 as well. Some
commonly used kernels deï¬ned on R of this form are (1) K(u) = 1{u âˆˆ
[âˆ’1/2,1/2]}, (2) K(u) = 1
2 exp(âˆ’|u|), (3) K(u) =
1
âˆš
2Ï€ exp(âˆ’u2/2), and (4)
K(u) = 3
4(1 âˆ’x2)+. See, for instance, Devroye [8].

12
E. GINÂ´E AND D. M. MASON
2.2. Examples.
In this subsection we show how the previous theorems
apply to a few instances of estimation of the density of a function of several
variables considered in the literature, as well as to the interpoint distance.
Example 1 (Linear combinations). (Frees [15], Schick and Wefelmeyer [32])
Suppose that
g(x1,...,xm) =
m
X
i=1
ui(xi),
xi âˆˆS,
(2.27)
for measurable functions u1,...,um from S to Rd such that the random
variable ui(X) has a density fi for each i = 1,...,m. Then (CD) holds with
f i(t,x) = Ëœfi(t âˆ’ui(x)) and Ëœfi = f1 âˆ—Â·Â·Â· âˆ—fiâˆ’1 âˆ—fi+1 âˆ—Â·Â·Â· âˆ—fm. Thus,
f(t,x) =
m
X
i=1
Ëœfi(t âˆ’ui(x)),
t âˆˆRd,x âˆˆS.
The process un,Î» is then given by
un,Î»(t) = âˆšn(n âˆ’m)!
n!
X
iâˆˆIm
n
"
KÎ»hn
 
t âˆ’
m
X
râˆ’1
ur(Xir)
!
(2.28)
âˆ’EKÎ»hn
 
t âˆ’
m
X
râˆ’1
ur(Xr)
!#
.
We will discuss some conditions under which the central limit theorems in
Lp(Rd), p âˆˆ[1,âˆ], uniform in Î», given above apply in this situation.
Let d = 1. If f is of bounded variation on R then so is the convolution of
f with any density, as is easy to check (in fact, more is true; see, e.g., Schick
and Wefelemeyer [33], Lemma 1). Hence Ëœfj is of bounded variation for each
j if at least two of the densities fi are. So, assuming the densities fi are of
bounded variation, then the classes Fi = { Ëœfi(tâˆ’Â·):t âˆˆRd} are of VC type by
Lemma 22 of Nolan and Pollard [26], as mentioned in connection with (2.12).
Also, since the map (t,x) 7â†’Ëœfi(t âˆ’x) is jointly measurable, these classes
are Q-Donsker for every Q (e.g., Dudley [10], Theorem 6.3.1, page 208).
Hence, Fi is P-Donsker for each i = 1,...,m. As observed, for example, in
the proof of Lemma 8, Schick and Wefelmeyer [34], if f is a function of
bounded variation on R, with f(âˆ’âˆ+) = 0 and Tf is the total variation of
its right continuous modiï¬cation f(Â·+), then by Fubiniâ€™s theorem applied
to the product of Lebesgue measure with the measure whose cumulative

LOCAL U-STATISTIC PROCESS
13
distribution function is f(Â·+),
R |f(x + s) âˆ’f(x)|dx â‰¤C|s| for all s âˆˆR.
With f = Ëœfi this gives
E(f i(t,X) âˆ’fi(s,X))2 =
Z
( Ëœfi(t âˆ’u) âˆ’Ëœfi(s âˆ’u))2fi(u)du
â‰¤2Tfiâˆ¥Ëœfiâˆ¥âˆâˆ¥Ëœfiâˆ¥1|t âˆ’s|.
Hence, since this holds for every i = 1,...,m, the identity map (R,| Â· |) 7â†’
(R,Ï) is uniformly continuous. So, if the densities fi are of bounded variation
on R, then condition (b) in Theorem 1 is satisï¬ed (note that fg is of bounded
variation, hence bounded).
Let d > 1. Finding interesting conditions on the densities fi in order for
condition (b) in Theorem 1 in the CLT to be satisï¬ed is a little more cum-
bersome in this case. Here are some conditions:
(1) fi is Î±-HÂ¨older continuous for some 0 < Î± â‰¤1 and of bounded support,
for each 1 â‰¤i â‰¤m. In this case one can easily check the VC property.
(2) fi is of bounded variation on Rd in the sense that it is the diï¬€erence
of the (d-dimensional) distribution functions of two positive measures (nec-
essarily of the same mass). In this case the Donsker property follows from
Dudley [10], Corollary 10.2.8, page 327.
(3) The functions Ëœfi satisfy condition (2.12). This condition is directly
imposed on convolutions because (2.12) may not be inherited by convolu-
tion, except in particular cases. Some important examples, like full d-variate
normal densities, satisfy it.
As a consequence of the above discussion, we have proved the following
theorem that improves on Theorem 1 in Schick and Wefelmeyer [32] in that
the convergence is uniform in Î» âˆˆ[a,b], the kernel is not necessarily a con-
volution and the window sizes hn are allowed to decrease at a smaller rate.
Their result includes the bias part whereas ours does not, and we discuss
this immediately below.
Theorem 4.
Let g be deï¬ned by (2.27) and let K satisfy condition
(2.12). If d = 1 assume that the densities fi of ui(X) are of bounded variation
and if d > 1 assume that fi satisfy (1) or (2) or that Ëœfi satisfy (3) in the
previous paragraph. Let hn â†’0 and nhn/(log hâˆ’1
n )2 â†’âˆ. Then the processes
un,Î» deï¬ned by (2.28) converge weakly in Lâˆ(Rd) uniformly in a â‰¤Î» â‰¤
b to the centered Gaussian process with the same covariance as f(Â·,x) =
Pm
i=1 Ëœfi(Â· âˆ’ui(x)).
Next we comment on the bias part in this theorem. What we do is stan-
dard and can also be done for the rest of the results in this article, but we
will refrain from doing so. Suppose that the densities fi are in Ck(Rd) and

14
E. GINÂ´E AND D. M. MASON
that their partial derivatives of order k or smaller are all bounded. Then the
same is true for fg = f1 âˆ—Â·Â·Â· âˆ—fm (this follows, e.g., from Proposition 8.10
in Folland [14] and Youngâ€™s inequalities) and therefore fg admits a Taylor
development of the form
fg(t + Î´) âˆ’fg(t)
=
k
X
r=1
1
r!
X
s1+Â·Â·Â·+sd=r
0â‰¤siâ‰¤r
âˆ‚rfg
âˆ‚s1x1 Â·Â·Â·âˆ‚sdxd
(t)Î´s1
1 Â·Â·Â·Î´sd
d + H(t,k,Î´)|Î´|k,
where H is uniformly bounded by a constant times the common bound for
the kth partial derivatives of fg (actually, by continuity, H â†’0 as Î´ â†’0).
Suppose moreover that the kernel K satisï¬es the conditions
Z
|t|k|K(t)|dt < âˆ
and
Z
ts1
1 Â·Â·Â·tsd
d K(t)dt = 0
for si â‰¥0,
d
X
i=1
si â‰¤k.
Then, integration after change of variables and use of Taylorâ€™s formula for
fg(t + (Î»hn)1/du) âˆ’fg(t) give
sup
Î»âˆˆ[a,b]
âˆšn|EKÎ»hn(t âˆ’g(X1,...,Xm)) âˆ’fg(t)| = O(âˆšnhk/d
n ).
Therefore, under these extra conditions on fi and K, if nh2k/d
n
â†’0, the
conclusion of the previous theorem can be modiï¬ed to convergence in law
in â„“âˆ(Rd Ã— [a,b]) of
âˆšn
(
1
|Im
n |
X
Im
n
KÎ»hn
 
t âˆ’
m
X
r=1
ur(Xir)
!
âˆ’fg(t)
)
to the same centered Gaussian process. If the partial derivatives up to order
k of fi are bounded and in L1, then fg âˆˆCmk(Rd) (e.g., by iteration in
Proposition 8.10, Folland [14]), and the previous discussion applies with k
replaced by mk.
Simultaneous estimation of convolutions. Here is an immediate applica-
tion of Theorem 4 to the simultaneous estimation of the densities of convolu-
tions. Let f be a density of bounded variation on R. We are interested in es-
timating the convolutions f âˆ—2 = f âˆ—f,...,f âˆ—N, for N â‰¥2. For m = 2,...,N,
tm âˆˆR and am â‰¤Î»m â‰¤bm introduce the estimators
d
f âˆ—m
n (tm,Î»m) =
1
|Im
n |Î»mhn
X
Im
n
K
tm âˆ’Pm
r=1 Xir
Î»mhn

and set
u(m)
n,Î»m(tm) = âˆšn{ d
f âˆ—m
n (tm,Î»m) âˆ’E d
f âˆ—m
n (tm,Î»m)}

LOCAL U-STATISTIC PROCESS
15
or, under extra conditions as in the previous remark, replace E d
f âˆ—m
n (tm,Î»m)
by f âˆ—m(tm,Î»m). [These estimators correspond to the functions g = gm de-
ï¬ned by gm(x1,...,xm) = x1 + Â·Â·Â· + xm.] A direct application of Theorem 4
in combination with the observations (2.6)â€“(2.8) gives that the vector-valued
processes (u(2)
n,Î»2(t2),...,u(N)
n,Î»N(tN)) converge weakly in Lâˆ(R)Ã—Â·Â·Â·Ã—Lâˆ(R)
uniformly in am â‰¤Î»m â‰¤bm, m = 2,...,N, to the centered vector-valued
Gaussian process deï¬ned on R Ã— Â·Â·Â· Ã— R, with the same covariance/cross
covariance matrix as
(2f(t2 âˆ’X),...,Nf âˆ—(Nâˆ’1)(tN âˆ’X)).
We note here that Schick and Wefelmeyer [32] use a variation of the Frees
[15] local U-statistic estimator of convolutions of densities. Their estimator
is based on convolving kernel density estimators. Here is how their approach
works in the case of estimating the density of X1 + X2, where X1 and X2
are i.i.d. real valued with density f. Consider the kernel density estimator
bfn(x) = (nhn)âˆ’1
n
X
i=1
k(hâˆ’1
n (x âˆ’Xi)),
where k is of bounded variation on R. Their estimator is bfn âˆ—bfn and can be
expressed, with K = k âˆ—k, as
bfn âˆ—bfn(x) =
1
n2hn
n
X
i=1
n
X
j=1
K
x âˆ’Xi âˆ’Xj
hn

= n âˆ’1
n
U n,hn(x) +
1
n2hn
n
X
i=1
K
x âˆ’2Xi
hn

,
where U n,hn(x) is the Frees type local U-statistic estimator of f âˆ—f(x) de-
ï¬ned by
U n,hn(x) = (hnn(n âˆ’1))âˆ’1
X
1â‰¤iÌ¸=jâ‰¤n
K(hâˆ’1
n (x âˆ’Xi âˆ’Xj)).
The second term in the above expression for bfn âˆ—bfn(x) is asymptotically
negligible and Theorem 4 applies to U nhn. This remark applies as well to
simultaneous estimation of convolutions of densities.
We can complement the above results for Lâˆ(Rd) with limit theorems
for the Lp distance. We now do this for the cases p = 1 and p = 2.
Theorem 5.
Assume K satisï¬es condition (a) in Theorem 2 and let
g(x1,...,xm) = Pm
i=1 ui(xi), ui :S 7â†’Rd be measurable, where ui(X) has

16
E. GINÂ´E AND D. M. MASON
density fi. Assume fi is in L2(Rd). Assume also hn â†’0 and nhn â†’âˆ.
Then
âˆšn
|Im
n |
X
Im
n
(
KÎ»hn
 
t âˆ’
m
X
r=1
ur(Xir)
!
âˆ’EKÎ»hn
 
t âˆ’
m
X
r=1
ur(Xr)
!)
converges in law in L2(Rd) uniformly in Î» âˆˆ[a,b] to the centered Gaussian
process with the same covariance as Pm
i=1 Ëœfi(Â· âˆ’ui(Xi)).
This theorem follows because by Youngâ€™s inequality (e.g., Folland [14],
page 240), fi âˆˆL2 for i = 1,...,m implies E
R f(t,X)2 dt < âˆ. As in the
previous theorem, a little more smoothness on fi and higher-order kernels
allow for elimination of the bias.
We can also recover the Schick and Wefelmeyer [32], Theorem 2 on the
CLT for the L1 norm, with weaker assumptions (note that condition (2.22)
is vacuous if [a,b] reduces to a single point).
If two densities belong to L1(Âµs) for some s > 0, then so does their con-
volution as can be seen by direct computation using the trivial observation
that (1 + |u + v|) â‰¤(1 + |u|)(1 + |v|), and it is also routine to check that if
any ï¬nite number of densities and their squares belong to L1(Âµs), so does
the square of their convolution. Moreover, by Lemma 1 to be proved below,
if f and k are two nonnegative functions in L1(Âµs) for some s > d, then
R (f âˆ—k)1/2(t)dt < âˆ. Hence Theorem 3 gives:
Theorem 6.
Let g(x1,...,xm) = Pm
i=1 ui(xi), ui :S 7â†’Rd be measur-
able, with ui(X) having density fi, for i = 1,...,m, and let K be a kernel on
Rd. Assume that for some s > d, K2, fi and f 2
i are in L1(Âµs), i = 1,...,m,
and that K satisï¬es condition (a) in Theorem 3 for this s. Assume also
hn â†’0 and nhn â†’âˆ. Then
âˆšn
|Im
n |
X
Im
n
(
KÎ»hn
 
t âˆ’
m
X
r=1
ur(Xir)
!
âˆ’EKÎ»hn
 
t âˆ’
m
X
r=1
ur(Xr)
!)
converges in law in L1(Rd) uniformly in Î» âˆˆ[a,b]) to the centered Gaussian
process with the same covariance as Pm
i=1 Ëœfi(Â· âˆ’ui(Xi)).
In R, if the densities fi are bounded (they do not need to be) then the
condition imposed on fi is simply that
R |x|1+Î´f(x)dx < âˆfor some Î´ > 0.
Example 2 (Distribution of sample distances).
Frees [15] considers es-
timating the density of the interpoint functional g(X1,X2) = |X1 âˆ’X2| in
two dimensions, where Xi are i.i.d. with a density f which is bounded and
of bounded support. We further assume that f is Î±-HÂ¨older continuous for

LOCAL U-STATISTIC PROCESS
17
some 0 < Î± â‰¤1, that is, |f(u) âˆ’f(v)| â‰¤C|u âˆ’v|Î± for all u,v âˆˆR2. Then, it
is easy to see that fg, the density of g,
fg(t) =
Z 2Ï€
0
Z
R2 f(x1 + tcosÎ¸,x2 + tsinÎ¸)f(x1,x2)tdx1 dx2 dÎ¸,
is bounded and has bounded support. Moreover, for x = (x1,x2) and with
R the radius of a ball around zero containing the support of f, we have, for
the conditional densities fi of |X1 âˆ’X2|,
f 1(t,x) = f2(t,x) =
Z 2Ï€
0
f(x1 + tcosÎ¸,x2 + tsinÎ¸)tdÎ¸,
0 â‰¤t â‰¤2R,
and fi(t,x) = 0 for larger values of t. Then f = f1 + f 2 satisï¬es
|f(t,Â·) âˆ’fi(s,Â·)| â‰¤8Ï€RC|t âˆ’s|Î± + 4Ï€âˆ¥fâˆ¥âˆ|t âˆ’s|,
and therefore, with F = {f(t,Â·):|t| â‰¤2R} and any probability measure Q,
N(F,L2(Q),Îµ) â‰¤C/Îµ1/Î± which, since the class F is image admissible Suslin
by joint measurability of f, implies that the class F is P-Donsker. So, if we
take a kernel K satisfying (2.12), and hn â†’0 with nhn/(log hâˆ’1
n )2 â†’âˆ, we
get that the processes deï¬ned for |t| â‰¤R, Î» âˆˆ[a,b],
n1/2
n(n âˆ’1)
X
1â‰¤iÌ¸=jâ‰¤n
{KÎ»hn(t âˆ’|Xi âˆ’Xj|) âˆ’EKÎ»hn(t âˆ’|Xi âˆ’Xj|)},
converge in law uniformly in t and Î» to the centered Gaussian process with
the same covariance as 2f1(t,X). Moreover, the comments following Theo-
rem 4 regarding replacement of (Î»hn)âˆ’1EK((Î»hn)âˆ’1(tâˆ’|Xi âˆ’Xj|)) by fg(t)
apply here as well.
In dimension 1,
f1(t,x) = f2(t,x) = f(t + x) + f(âˆ’t + x),
t â‰¥0,
and a suï¬ƒcient condition for F to be P-Donsker is that f be of bounded
variation on R. Then, K of bounded variation on R and nhn/(log hâˆ’1
n )2 â†’âˆ
ensure the same CLT as above. Since
fg(x) =
Z
f(y + x)f(y)dy +
Z
f(y âˆ’x)f(y)dy
and
fg(0) = 2
Z
f 2(y)dy,
as observed by Frees [15], we get a âˆšn consistent estimator of
R f 2(x)dx
when the extra smoothness conditions to make the bias tend to zero hold.
See also Bickel and Ritov [4] or GinÂ´e and Mason [19] and references therein
for other âˆšn consistent estimators of
R f 2(x)dx.

18
E. GINÂ´E AND D. M. MASON
Example 3 (Local interpoint distance processes).
(Jammalamadaka and
Janson [23], Eastwood and HorvÂ´ath [12].) In Corollary 1 we consider the
processes
âˆšn
hn Vol(D)
X
Im
n
[I{g(Xi1,...,Xim) âˆˆ(Î»hn)1/dD}
âˆ’Pr{g(X1,...,Xm) âˆˆ(Î»hn)1/dD}]
for D star shaped about 0. Of particular interest in the literature is the case
corresponding to m = 2, S = Rd, g(X1,X2) = X2 âˆ’X1 and D the (open or
closed) unit ball about zero for some norm in Rd. In this case the densities
f i(t,x), i = 1,2, are, respectively, f(xâˆ’t) and f(x+t), where f is the density
of X. So, for the local asymptotic equicontinuity condition (2.13) to hold
we only need that the class F = {f(Â· + t):|t| < Î´} be P-Donsker for some
Î´ > 0. If f is HÂ¨older continuous of order Î± âˆˆ(0,1], and Q is any probability
measure on Rd, then
Z
(f(x + t) âˆ’f(x + s))2 dQ(x) â‰¤C|t âˆ’s|2Î±,
s,t âˆˆRd.
It follows as in the previous example that F is VC and measurable, hence
Q-Donsker for every probability measure Q. Thus, Corollary 1 implies the
following slight strengthening and generalization of Theorem 1.1 in East-
wood and HorvÂ´ath [12].
Theorem 7.
If D is a bounded measurable subset of Rd star-shaped
about zero and with Vol(D) Ì¸= 0, Xi are i.i.d. random vectors in Rd with
a density f which is Î±-HÂ¨older continuous for some Î± âˆˆ(0,1], and hn â†’0,
nhn â†’âˆ, then the processes
1
n3/2hn Vol(D)
X
(i1,i2)âˆˆI2n

I
Xi1 âˆ’Xi2
(Î»hn)1/d âˆˆD

âˆ’Pr
X1 âˆ’X2
(Î»hn)1/d âˆˆD

,
0 â‰¤Î» â‰¤1,
converge in law in â„“âˆ[0,1] to the process Î»ÏƒZ, 0 â‰¤Î» â‰¤1, where Z is N(0,1)
and Ïƒ2 = 4[
R f 3(x)dx âˆ’(
R f 2(x)dx)2].
3. Proofs.
In the sequel it will be helpful to introduce the following no-
tation and facts. For a kernel L of k â‰¥1 variables we set
U (k)
n (L) = (n âˆ’k)!
n!
X
iâˆˆIkn
L(Xi1,...,Xik)
(3.1)
[so, Un(t,Î») = U (m)
n
(KÎ»hn(t âˆ’g(Â·,...,Â·))) even if g is not symmetric in its
entries]. [When L is a constant function we deï¬ne U (0)
n (L) = L.] Assume now

LOCAL U-STATISTIC PROCESS
19
that L is a function of m â‰¥1 variables, symmetric in its entries. Then, for
1 â‰¤k â‰¤m, the Hoeï¬€ding projections with respect to P are deï¬ned as
Ï€kL(x1,...,xk) = (Î´x1 âˆ’P) Ã— Â·Â·Â· Ã— (Î´xk âˆ’P) Ã— P mâˆ’k(L)
(3.2)
and Ï€0L = EL(X1,...,Xm). Then, the Hoeï¬€ding decomposition states the
following, which is easy to check:
U (m)
n
(L) âˆ’EL =
m
X
k=1
m
k

U (k)
n (Ï€kL).
(3.3)
For L âˆˆL2(P m) this is an orthogonal decomposition and E(Ï€kL|X2,...,Xk.) =
0 for k â‰¥1; that is, the kernels Ï€kL are canonical for P (or completely de-
generate, or completely centered). Also, Ï€k, k â‰¥1, are nested projections,
that is, Ï€k â—¦Ï€â„“= Ï€k if k â‰¤â„“, and E(Ï€kL)2 â‰¤E(L âˆ’EL)2 â‰¤EL2.
The function Kh(t âˆ’g(X1,...,Xm)) is not necessarily symmetric in its
entries, but we can symmetrize it as
Kh(t,x1,...,xm) := 1
m!
X
ÏƒâˆˆIm
m
Kh(t âˆ’g(xÏƒ1,...,xÏƒm)).
(3.4)
Then, clearly, for each t âˆˆRd,
Un(t,Î») âˆ’EKÎ»hn(t âˆ’g(X1,...,Xm))
= U (m)
n
(KÎ»hn(t,Â·,...,Â·)) âˆ’EKÎ»hn(t,X1,...,Xm).
Moreover, by applying (3.3) to un,Î»(t) we get
un,Î»(t) = âˆšn
m
X
k=1
m
k

U (k)
n (Ï€kKÎ»hn(t,Â·,...,Â·)).
(3.5)
3.1. A general proposition for the CLT.
Let us consider the ï¬rst term in
the expansion (3.5). Note that, by deï¬nition of f and fg,
mÏ€1KÎ»hn(t,x) =
m
X
i=1
EKÎ»hn(t âˆ’g(X1,...,Xiâˆ’1,x,Xi+1,...,Xm))
âˆ’mEKÎ»hn(t âˆ’g(X1,...,Xm))
=
Z
KÎ»hn(t âˆ’u)(f(u,x) âˆ’Ef(u,X)) du
=
Z
(f(t âˆ’u,x) âˆ’Ef(t âˆ’u,X))KÎ»hn(u)du.
Hence,
âˆšnmU (1)
n (Ï€1KÎ»hn(t,Â·))

20
E. GINÂ´E AND D. M. MASON
= 1
âˆšn
n
X
i=1
Z
(f(t âˆ’u,Xi) âˆ’Ef(t âˆ’u,X))KÎ»hn(u)du
(3.6)
=
Z
Î½n(t âˆ’u)KÎ»hn(u)du = (Î½n âˆ—KÎ»hn)(t),
which is a generalized version of the smoothed empirical process that has
been recently investigated by several authors (e.g., Rost [31] and references
therein). We shall see that it controls the asymptotic behavior of the process
un,Î». In the next proposition we show it has the same asymptotic behavior
as the empirical process over the class of functions {f(t,Â·),t âˆˆRd}.
Proposition 1.
Let 1 â‰¤p â‰¤âˆ. Assume:
(i) condition (CDp) holds;
(ii) limÎ´â†’0 limsupnâ†’âˆPrâˆ—{sup|u|â‰¤Î´ âˆ¥Î½n(Â· âˆ’u) âˆ’Î½n(Â·)âˆ¥p > Îµ} = 0 for all
Îµ > 0;
(iii) the sequence âˆ¥Î½nâˆ¥âˆ—
p, n âˆˆN, is stochastically bounded.
Then, whenever hn â†’0 we have
lim
nâ†’âˆsup
aâ‰¤Î»â‰¤b
âˆ¥âˆšnmU (1)
n (Ï€1KÎ»hn(Â·,Â·)) âˆ’Î½n(Â·)âˆ¥p = 0
in prâˆ—.
(3.7)
Proof.
Let wÎ´(Î½n) = sup|u|<Î´ âˆ¥Î½n(Â·âˆ’u)âˆ’Î½(Â·)âˆ¥p, Î´ > 0, denote the Lp(Rd)
modulus of â€œcontinuityâ€ of Î½n, which is deï¬ned because of (i). Then it fol-
lows by Fubini in the case p = âˆand by Minkowskiâ€™s inequality for integrals
(e.g., Folland [14], page 194) in the case 1 â‰¤p < âˆthat
âˆ¥Î½n âˆ—KÎ»hn âˆ’Î½nâˆ¥p â‰¤wÎ´(Î½n)âˆ¥KÎ»hnâˆ¥1 + 2âˆ¥Î½nâˆ¥p
Z
|u|>Î´
|KÎ»hn(u)|du
â‰¤wÎ´(Î½n)âˆ¥Kâˆ¥1 + 2âˆ¥Î½nâˆ¥p
Z
|u|>Î´/(Î»hn)1/d |K(u)|du.
Now, the result follows from this, K âˆˆL1(Rd) and (ii) and (iii), in view of
(3.6).
â–¡
Corollary 2.
Let 1 â‰¤p â‰¤âˆ. Assume (CDp) and hypothesis (b) in
Theorem 1 for p = âˆ, in Theorem 2 for 2 â‰¤p < âˆand in Theorem 3 for
1 â‰¤p < 2. Then the processes Î½n converge weakly in Lp(Rd) to the centered
Gaussian process G with the covariance of f(Â·,X). If moreover hn â†’0, then
the limit (3.7) holds.
Proof.
(a) Case p = âˆ. In this case, the hypothesis of the class F being
P-Donsker is just another way of saying that Î½n converges in law to G in
Lâˆ(Rd), and this obviously implies (iii); ï¬nally, (ii) holds by the uniform

LOCAL U-STATISTIC PROCESS
21
continuity of the identity map (Rd,| Â· |) 7â†’(Rd,Ï) together with the usual
asymptotic equicontinuity condition (e.g., Dudley [10], pages 117â€“118).
(b) Case 1 â‰¤p < âˆ. As mentioned in Section 2, the hypotheses (b) in
Theorems 2 and 3 are precisely the necessary and suï¬ƒcient conditions for the
process f(Â·,X) to satisfy the CLT in Lp, that is, for Î½n to converge in law to
G in Lp. Moreover, (iii) is a direct consequence of this convergence. Finally,
condition (ii) holds by the uniform tightness implied by weak convergence
together with the FrÂ´echetâ€“Kolmogorov characterization of compact sets of
Lp(Rd) (see, e.g., Dunford and Schwartz [11], Theorem IV.8.21, page 301).
â–¡
In view of (3.5) and Corollary 2, to complete our CLT program for un,Î»,
that is, the proofs of Theorems 1, 2 and 3, it only remains to show that the
hypotheses in the statements of these theorems also imply
sup
aâ‰¤Î»â‰¤b
âˆ¥âˆšnU (k)
n (Ï€kKÎ»hn)âˆ¥p â†’0
in pr,
k = 2,...,m.
(3.8)
Proving this constitutes the main part of our proofs, and requires new in-
equalities for U-processes that we develop in the next subsections.
3.2. Inequalities for U-processes.
In the next two subsections we collect
the inequalities we need to prove the limits (3.8). First we consider the case
of U-processes indexed by VC classes of functions and obtain a moment
inequality that generalizes the scope of that of Einmahl and Mason [13]
and GinÂ´e and Koltchinskii [17] for empirical processes. Next, we consider U-
statistics taking values on separable type 2 Banach spaces such as Lp, p â‰¥2,
and derive exponential inequalities for them. The inequality that we get in
this situation is particularly neat. Then, based on the method recently used
by GinÂ´e, Lata la and Zinn [18] to prove inequalities for U-statistics, we derive
both moment and exponential inequalities for other Banach spaces, such as
Lp, 1 â‰¤p < 2. These are less clean than in the type 2 case, but are still
usable. Neither of our exponential inequalities captures the Gaussian tail
behavior that the statistic should have for small values of x; nevertheless,
their application yields very strong results in the situations encountered in
this article.
3.3. U-processes indexed by VC classes.
In this subsection we consider
classes of measurable functions F deï¬ned on (Sm,Sm) taking values in
[âˆ’1,1], and we assume that 0 âˆˆF. The object is to obtain a bound for
Eâˆ¥U (k)
n (Ï€kf)âˆ¥F where F is of VC-type, and where we use the notation
âˆ¥Î¨(f)âˆ¥F = supfâˆˆF|Î¨(f)| for any functional Î¨ deï¬ned on the class F. This
bound will require measurability on the class F described in de la PeËœna
and GinÂ´e [7], page 138: the class F should be measurable in the sense that

22
E. GINÂ´E AND D. M. MASON
for every k = 1,...,m and every choice of ai1,...,ik âˆˆ{âˆ’1,1}, the mapping
f 7â†’P
Ikn ai1,...,ikP mâˆ’kf(Xi1,...,Xik) is measurable for the completion of
Sn. This holds, for instance, if (a) if there exists F0 countable such that this
sup equals the sup over F0, or (b) if the Ïƒ-algebra S is countably gener-
ated and contains the singletons, and the class F is image admissible Suslin,
for instance, if it is parametrized by a complete separable metric space T in
such a way that the evaluation map (t,x1,...,xm) 7â†’ft(x1,...,xm) is jointly
measurable (Dudley [10], Section 5.3; van der Vaart and Wellner [37], Sec-
tion 2.3.1; Pollard [30], page 196). These conditions allow us to randomize by
independent random signs and use Fubini. If either of these two conditions
is satisï¬ed, we say that the class F is measurable.
The following moment inequality will be instrumental in ï¬nishing the
proof of Theorem 1. The proof of this inequality has several points in com-
mon with the proofs of similar inequalities for m = 1 in Einmahl and Mason
[13] and in GinÂ´e and Koltchinskii [17]; however the present proof does not
rely on the square root trick or on the contraction principle for Rademacher
processes.
Theorem 8.
Let F be a measurable collection of functions Sm 7â†’R
symmetric in their entries with an envelope function F and let P be any
probability measure on (S,S) (with Xi i.i.d. P). Assume F is bounded by
M > 0 and F is VC with respect to F with characteristics A and v, as in
(2.9). Then for every m âˆˆN, A â‰¥em, v â‰¥1, there exist constants C1 :=
C1(m,A,v,M) and C2 = C2(m,A,v,M) such that
nk/2Eâˆ¥U (k)
n (Ï€kf)âˆ¥F â‰¤C1Ïƒ

log Aâˆ¥Fâˆ¥L2(P m)
Ïƒ
k/2
,
(3.9)
k = 0,1,...,m,
assuming
nÏƒ2 â‰¥C2 log
2âˆ¥Fâˆ¥L2(P m)
Ïƒ

,
(3.10)
where Ïƒ2 is any number satisfying
âˆ¥P mf 2âˆ¥F â‰¤Ïƒ2 â‰¤P mF 2.
(3.11)
Proof.
Without loss of generality we assume F â‰¤M = 1. The theorem
is true for all m and k = 0 by HÂ¨olderâ€™s inequality, since U (0)
n (Ï€0f) = Pf, so
we assume the statement to be true for all m âˆˆN and k âˆ’1, for some k â‰¥1,
and prove it for k (and for all m âˆˆN ). We shall omit symbols when no
confusion is possible, so, for instance, we write âˆ¥Â· âˆ¥for âˆ¥Â· âˆ¥F. We shall not
keep track of constants; in particular, constants that depend on a subset of

LOCAL U-STATISTIC PROCESS
23
m,A,v,M, will generically be denoted by C (so, the value of C may change
from line to line). By Theorem 3.5.3 in de la PeËœna and GinÂ´e [7], the deï¬nition
of Ï€k and Jensenâ€™s inequality,
E

X
Ikn
(Ï€kf)(Xi1,...,Xik)
 â‰¤CE

X
Ikn
Îµi1 Â·Â·Â·Îµik(Ï€kf)(Xi1,...,Xik)

â‰¤CE

X
Ikn
Îµi1 Â·Â·Â·Îµik(P mâˆ’kf)(Xi1,...,Xik)
.
Here Xi,Îµj are all independent, the Xâ€™s have law P and the Îµâ€™s are random
signs (Rademacher variables). Since for any probability measure Q on Sk,
Q(P mâˆ’k(f âˆ’g))2 â‰¤Q Ã— P mâˆ’k(f âˆ’g)2,
it follows from the VC property of F that
N(P mâˆ’kF,L2(Q),Ï„) â‰¤
Aâˆ¥
âˆš
P mâˆ’kF 2âˆ¥L2(Q)
Ï„
v
,
0 < Ï„ â‰¤2âˆ¥
âˆš
P mâˆ’kF 2âˆ¥L2(Q),
that is, P mâˆ’kF is VC-type with characteristics A and v and envelope
âˆš
P mâˆ’kF 2. This gives, by the entropy integral for Rademacher chaos of or-
der k (de la PeËœna and GinÂ´e [7], Corollary 5.1.8, upon noting that exponential
Orlicz norms dominate Lp norms up to constants),
|Ik
n|âˆ’1/2EÎµ

X
Ikn
Îµi1 Â·Â·Â·Îµik(P mâˆ’kf)(Xi1,...,Xik)

â‰¤C
Z p
âˆ¥U(k)
n
((P mâˆ’kf)2)âˆ¥
0

log A
q
U (k)
n (P mâˆ’kF 2)
Ï„
k/2
dÏ„,
where EÎµ denotes expectation with respect to the Rademacher variables only.
[To apply Corollary 5.1.8 exactly to our process we need that, for X1,...,Xn
ï¬xed, the Rademacher chaos process
f 7â†’
X
Ikn
Îµi1 Â·Â·Â·Îµik(P mâˆ’kf)(Xi1,...,Xik),
f âˆˆF,
be separable, and this follows by separability of the unit cube of R|Ik
n| for
the Euclidean norm.] Then, by Fubini,
|Ik
n|1/2Eâˆ¥U (k)
n (Ï€kf)âˆ¥â‰¤CB,
(3.12)
where
B = E
Z p
âˆ¥U(k)
n
((P mâˆ’kf)2)âˆ¥
0

log A
q
U (k)
n (P mâˆ’kF 2)
Ï„
k/2
dÏ„.
(3.13)

24
E. GINÂ´E AND D. M. MASON
Decompose the integral B into two parts,
(I) := E
Z p
âˆ¥U(k)
n
((P mâˆ’kf)2)âˆ¥
0

log A
q
U (k)
n (P mâˆ’kF 2)
Ï„
k/2
dÏ„ In

,
where
In = I{U (k)
n (P mâˆ’kF 2) > 4P mF 2}
and
(II ) := E
Z p
âˆ¥U(k)
n
((P mâˆ’kf)2)âˆ¥
0

log A
q
U (k)
n (P mâˆ’kF 2)
Ï„
k/2
dÏ„ Ic
n

,
so that B = (I)+(II ). The (I) term is handled by the Arcones [3] exponential
inequality (de la PeËœna and GinÂ´e [7], Theorem 4.1.13), which gives
Pr{U (k)
n (P mâˆ’kF 2) > 4P mF 2}
(3.14)
â‰¤4exp

âˆ’
9n(P mF 2)2
2k2P mF 4 + cP mF 2

â‰¤4exp

âˆ’9nP mF 2
2k2 + c

for a constant c that depends only on k. In the last inequality we have used
F â‰¤1. Since, by change of variables,
Z p
âˆ¥U(k)
n
((P mâˆ’kf)2)âˆ¥
0

log A
q
U (k)
n (P mâˆ’kF 2)
Ï„
k/2
dÏ„
â‰¤A
Z 1
0
(log uâˆ’1)k/2 du
q
U (k)
n (P mâˆ’kF 2),
and P k(U (k)
n (P mâˆ’kF 2)) â‰¤P mF 2, it follows by HÂ¨olderâ€™s inequality and (3.14)
that
(I) â‰¤Câˆ¥Fâˆ¥L2(P m) exp

âˆ’
9nâˆ¥Fâˆ¥2
L2(P m)
2(2k2 + c1)

â‰¤D
âˆšn.
(3.15)
As for (II ), we note
(II ) â‰¤E
Z p
âˆ¥U(k)
n
((P mâˆ’kf)2)âˆ¥
0

log 2Aâˆ¥Fâˆ¥L2(P m)
Ï„
k/2
dÏ„ Ic
n

.
(3.16)
Now by integration we see that for any 0 < c < C
Z c
0
(log(C/x))k/2

1 âˆ’k
2(log(C/x))âˆ’1

dx = c(log(C/c))k/2,
which when (log(C/c))âˆ’1 â‰¤kâˆ’1 gives the inequality
Z c
0
(log(C/x))k/2 dx â‰¤2c(log(C/c))k/2.
(3.17)

LOCAL U-STATISTIC PROCESS
25
Thus since on Ic
n
2Aâˆ¥Fâˆ¥L2(P m)/
q
âˆ¥U (k)
n ((P mâˆ’kf)2)âˆ¥â‰¥A â‰¥em > ek,
(3.18)
we get from (3.17), (3.18) and (3.16) that
(II ) â‰¤2E
q
âˆ¥U (k)
n ((P mâˆ’kf)2)âˆ¥

log
2Aâˆ¥Fâˆ¥L2(P m)
q
âˆ¥U (k)
n ((P mâˆ’kf)2)âˆ¥
k/2
.
Since the function âˆšx(âˆ’logx)k/2, 0 < x < 1, is concave on (0,eâˆ’k] and
A â‰¥em > ek, this last bound is by Jensenâ€™s inequality
â‰¤2
q
Eâˆ¥U (k)
n ((P mâˆ’kf)2)âˆ¥

log
2Aâˆ¥Fâˆ¥L2(P m)
q
Eâˆ¥U (k)
n ((P mâˆ’kf)2)âˆ¥
k/2
.
(3.19)
We are going to show that there exists a C > 0 such that
B â‰¤C
 1
âˆšn +
s
B
nk/2 + Ïƒ2

log Aâˆ¥Fâˆ¥L2(P m)
Ïƒ
k/2
.
(3.20)
We shall consider two cases. In case 1, Eâˆ¥U (k)
n ((P mâˆ’kf)2)âˆ¥â‰¤Ïƒ2. In this
case, since the function âˆšx(âˆ’log x)k/2, 0 < x < 1, is increasing on (0,eâˆ’k],
we get the trivial bound from (3.15) and (3.19) that
B â‰¤D
âˆšn + 2Ïƒ

log 2Aâˆ¥Fâˆ¥L2(P m)
Ïƒ
k/2
,
which of course implies the bound (3.20) (note that Aâˆ¥Fâˆ¥L2(P m)/Ïƒ â‰¥em).
Next consider case 2, Eâˆ¥U (k)
n ((P mâˆ’kf)2)âˆ¥> Ïƒ2. To handle this case we
must bound Eâˆ¥U (k)
n ((P mâˆ’kf)2)âˆ¥. It is here that we will use the induction
hypothesis. By Hoeï¬€dingâ€™s decomposition (3.3) we have
Eâˆ¥U (k)
n ((P mâˆ’kf)2)âˆ¥â‰¤
k
X
r=0
k
r

Eâˆ¥U (r)
n (Ï€r(P mâˆ’kf)2)âˆ¥.
(3.21)
The term corresponding to r = 0 is simply âˆ¥P k(P mâˆ’kf)2âˆ¥â‰¤Ïƒ2. Consider
now the new class
G := {(P mâˆ’kf)2 :f âˆˆF}
of functions of k variables. For any probability measure Q on Sk,
Q((P mâˆ’kf)2 âˆ’(P mâˆ’kg)2)2 â‰¤4Q Ã— P mâˆ’k(f âˆ’g)2,
and thus the class G is VC-type with constants A and v and envelope
2
âˆš
P mâˆ’kF 2 as in (2.9). Also observe that since
âˆ¥P k(P mâˆ’kf)4âˆ¥â‰¤âˆ¥P mf 2âˆ¥â‰¤4Ïƒ2 â‰¤4âˆ¥
âˆš
P mâˆ’kF 2âˆ¥2
L2(P k) = 4âˆ¥Fâˆ¥2
L2(P m),

26
E. GINÂ´E AND D. M. MASON
we verify that (3.11) holds. Also we trivially see that (3.10) is satisï¬ed, that
is,
4nÏƒ2 > nÏƒ2 â‰¥C2 log
2âˆ¥Fâˆ¥L2(P m)
Ïƒ

= C2 log
4âˆ¥Fâˆ¥L2(P m)
2Ïƒ

.
Finally noting that A â‰¥em > ek and 2
âˆš
P mâˆ’kF 2 â‰¤2, we are permitted to
apply the induction hypothesis for 1 â‰¤r < k (r = 0 has already been dealt
with) to get with M = 2,
Eâˆ¥U (r)
n (Ï€r(P mâˆ’kf)2)âˆ¥â‰¤C1(k,A,v,2)nâˆ’r/22Ïƒ

log Aâˆ¥Fâˆ¥L2(P m)
Ïƒ
r/2
.
(3.22)
Since by the hypotheses (3.10) and (3.11) on Ïƒ [note (3.11) and F â‰¤1 imply
Ïƒ2 â‰¤1] we have
1
nr/2 Ïƒ

log Aâˆ¥Fâˆ¥L2(P m)
Ïƒ
r/2
â‰¤Cr/2Ïƒ1+r â‰¤Cr/2Ïƒ2,
(3.23)
it follows from the bounds (3.22) and (3.23) that
k
r

Eâˆ¥U (r)
n (Ï€r(P mâˆ’kf)2)âˆ¥â‰¤CÏƒ2,
1 â‰¤r < k.
(3.24)
As for r = k, we randomize and use the entropy bound for Rademacher
chaos, just as we did at the beginning of the proof, using the fact that G is
VC-type. This gives
Eâˆ¥U (k)
n (Ï€k(P mâˆ’kf)2)âˆ¥
â‰¤C|Ik
n|âˆ’1/2E
|Ik
n|âˆ’1/2 X
Ikn
Îµi1 Â·Â·Â·Îµik(P mâˆ’kf)2

(3.25)
â‰¤
C
|Ikn|1/2 E
Z p
âˆ¥U(k)
n
((P mâˆ’kf)4)âˆ¥
0

log A
q
U (k)
n (P mâˆ’kF 2)
Ï„
k/2
dÏ„
â‰¤C B
nk/2 ,
where B is as deï¬ned in (3.13) and we use
âˆ¥U (k)
n ((P mâˆ’kf)4)âˆ¥â‰¤âˆ¥U (k)
n ((P mâˆ’kf)2)âˆ¥.
From (3.15), (3.19), (3.21)â€“(3.25) and Eâˆ¥U (k)
n ((P mâˆ’kf)2)âˆ¥> Ïƒ2 we get (3.20).
Since log[Aâˆ¥Fâˆ¥L2(P m)/Ïƒ] > 1, hypothesis (3.10) on Ïƒ gives
1
âˆšn â‰¤C
Ïƒ
(log Aâˆ¥Fâˆ¥L2(P m)/Ïƒ)1/2 â‰¤CÏƒ

log Aâˆ¥Fâˆ¥L2(P m)
Ïƒ
k/2
,

LOCAL U-STATISTIC PROCESS
27
and therefore it follows from inequality (3.20) that with perhaps a diï¬€erent
value of C,
B â‰¤C
s
B
nk/2 + Ïƒ2

log Aâˆ¥Fâˆ¥L2(P m)
Ïƒ
k/2
.
Taking squares and solving this inequality, we get that there exists a constant
C (easy to evaluate) such that
B â‰¤C
(log Aâˆ¥Fâˆ¥L2(P m)/Ïƒ)k
nk/2
+ Ïƒ

log Aâˆ¥Fâˆ¥L2(P m)
Ïƒ
k/2
.
But, again by condition (3.10) on Ïƒ as in (3.23),
(log Aâˆ¥Fâˆ¥L2(P m)/Ïƒ)k/2
nk/2
â‰¤CÏƒk â‰¤Ïƒ,
and therefore
B â‰¤CÏƒ

log Aâˆ¥Fâˆ¥L2(P m)
Ïƒ
k/2
,
which, by inequality (3.12), proves the theorem.
â–¡
Remark 4.
An analogue of the previous theorem holds if we replace the
function (log(Aâˆ¥Fâˆ¥L2(Q)/Ï„) by H(âˆ¥Fâˆ¥L2(Q)/Ï„) with H an increasing regu-
larly varying function of exponent 0 â‰¤Î± < 2/m, very much as in Theorem
3.1 in GinÂ´e and Koltchinskii [17].
3.4. U-statistics taking values in separable Banach spaces.
3.4.1. The Lp case, 2 â‰¤p < âˆ.
We shall begin by establishing an ex-
ponential bound for the tail of the norm of a U-statistic taking values in
a separable type 2 Banach space B. Let us recall that a separable Ba-
nach space B is of type 2 if for any ï¬nite number of points xi âˆˆB and
independent Rademacher variables Îµi (independent random signs), we have
Eâˆ¥Pn
i=1 Îµixiâˆ¥2 â‰¤C Pn
i=1 âˆ¥xiâˆ¥2, and the smallest such constant C is the type
2 constant of B. It is well known that the Lp spaces are of type 2 if (and
only if) p â‰¥2. If Zi are independent, centered B-valued random vectors with
a square integrable norm and B is of type 2, then
E

n
X
i=1
Zi

2
â‰¤C
n
X
i=1
Eâˆ¥Ziâˆ¥2
(3.26)
(Araujo and GinÂ´e [2] or Ledoux and Talagrand [24]).

28
E. GINÂ´E AND D. M. MASON
Theorem 9.
Let H be a function of k variables, P-canonical, symmet-
ric, with values in a type 2 Banach space. We have, for all x â‰¥0,
Pr
(
X
iâˆˆIkn
H(Xi1,...,Xik)
 â‰¥x
)
â‰¤D exp

âˆ’

x
Î»0nk/2Îº
2/k
,
(3.27)
where Îº is a number satisfying
Îº â‰¥
sup
x1,...,xkâˆˆS
âˆ¥H(x1,...,xk)âˆ¥
(3.28)
and Î»0 and D are constants that depend only on k and the type 2 constant
C of B.
Proof.
(This inequality was mentioned on page 252 of de la PeËœna and
GinÂ´e [7] and its precise statement and proof were left to the reader.) Here
is the proof.
Let
Sn =
1
Îº
 n
k
1/2
X
1â‰¤i1<Â·Â·Â·<ikâ‰¤n
H(Xi1,...,Xik),
and let
Sâ€²
n =
1
Îº
 n
k
1/2
X
1â‰¤i1<Â·Â·Â·<ikâ‰¤n
Îµ1
i1 Â·Â·Â·Îµk
ikH(X(1)
i1 ,...,X(k)
ik ),
where Îº is as in (3.28), X(j)
i
are i.i.d. with law P, and Îµj
i are i.i.d. Rademacher
variables independent of the collection of variables {X(j)
i
}.
By decoupling (Theorem 3.1.1 of de la PeËœna and GinÂ´e [7]) and convexity
(e.g., Theorem 3.5.3 on page 140 of de la PeËœna and GinÂ´e [7], as it applies
to a nonnegative, nondecreasing convex function Î¨), there is a constant Ck
such that
âˆ¥âˆ¥Snâˆ¥âˆ¥Î¨2/k â‰¤Ckâˆ¥âˆ¥Sâ€²
nâˆ¥âˆ¥Î¨2/k.
(3.29)
By hypercontractivity of Rademacher chaos (Khinchinâ€™s inequality for Rade-
macher chaos), for example, Theorem 3.2.2 on page 113 of de la PeËœna and
GinÂ´e (year?), for all r â‰¥2,
EÎµâˆ¥Sâ€²
nâˆ¥r â‰¤rkr/2(EÎµâˆ¥Sâ€²
nâˆ¥2)r/2,
and by the type 2 inequality applied one sequence {Îµj
i }, j = 1,...,k, at a
time, we get
(EÎµâˆ¥Sâ€²
nâˆ¥2)r/2 â‰¤Ckr/2,
where C is the type 2 constant of the Banach space, and therefore,
EÎµâˆ¥Sâ€²
nâˆ¥r â‰¤Ckr/2rkr/2.

LOCAL U-STATISTIC PROCESS
29
This inequality yields, by Taylor expansion of the exponential, that for some
c > 0,
EÎµÎ¨2/k(câˆ¥Sâ€²
nâˆ¥) < âˆ
and therefore that there exists a constant Î»1 = Î»1(C,k) depending only on
C and k, such that
EÎµÎ¨2/k(âˆ¥Sâ€²
nâˆ¥/Î»1) â‰¤1.
Integrating with respect to the Xâ€™s,
EÎ¨2/k(âˆ¥Sâ€²
nâˆ¥/Î»1) â‰¤1,
that is, âˆ¥âˆ¥Sâ€²
nâˆ¥âˆ¥Î¨2/k â‰¤Î»1,
which, combined with (3.29), gives
âˆ¥âˆ¥Snâˆ¥âˆ¥Î¨2/k â‰¤CkÎ»1 := Î»0,
a constant. Of course this implies, by the deï¬nition of the Orlicz norm Î¨2/k,
that there is a constant D(k,C) such that
Pr{âˆ¥Snâˆ¥> x} â‰¤Deâˆ’(x/Î»0)2/k.
â–¡
3.4.2. The Lp case, 1 â‰¤p < 2.
Our aim now is to obtain a useful expo-
nential inequality for B-valued U-statistics, when B is not necessarily a type
2 Banach space. We will generalize to B-valued U-statistics (via decoupling
followed by iteration) the following sharp inequality for sums of independent
random vectors: there is a constant L < âˆsuch that if B is a separable Ba-
nach space, Zi, i âˆˆN, are independent mean zero random vectors taking
values in B and r â‰¥2, then, setting Sn = Pn
i=1 Zi,
Eâˆ¥Snâˆ¥r â‰¤Lr

rr/2(Eâˆ¥Snâˆ¥2)r/2 + rrE max
1â‰¤iâ‰¤nâˆ¥Ziâˆ¥r

.
(3.30)
This inequality was obtained by Pinelis [28], and it also follows easily from
the sharper inequality in GinÂ´e, Lata la and Zinn [18], Proposition 3.1. Next
we extend inequality (3.30) to B-valued U-statistics.
Theorem 10.
Let B be a separable Banach space, let H :Sk 7â†’B be a
bounded P-canonical random vector symmetric in its entries and let Xi,X(j)
i
be i.i.d. S-valued random variables, 1 â‰¤i â‰¤n and j = 1,...,k. Deï¬ne Îº and
Ï‡n to be any pair of numbers such that
Îº â‰¥
sup
x1,...,xkâˆˆS
âˆ¥H(x1,...,xk)âˆ¥
(3.31)
and
Ï‡n â‰¥
 
E

X
iâˆˆIkn
H(X(1)
i1 ,...,X(k)
ik )

2!1/2
.

30
E. GINÂ´E AND D. M. MASON
Then there exists a constant C depending only on k such that, for all n âˆˆN
and r â‰¥2,
E

X
iâˆˆIkn
H(X(1)
i1 ,...,X(k)
ik )

r
(3.32)
â‰¤Cr[rkr/2Ï‡r
n + r(k+1)r/2n(kâˆ’1)rÎºr + rkrÎºr].
Moreover, there exists a constant D0 depending only on k such that, for all
n âˆˆN and r â‰¥2,
E

X
iâˆˆIkn
H(Xi1,...,Xik)

r
â‰¤Dr
0[rkr/2Ï‡r
n + r(k+1)r/2n(kâˆ’1)rÎºr + rkrÎºr],
(3.33)
where Îº and Ï‡n are deï¬ned as in (3.31).
Proof.
Inequality (3.30) gives the result for k = 1. Assume the re-
sult is true for k and for every Banach space, and let H be a function
of k + 1 variables satisfying the conditions in the statement of the the-
orem. Before starting the induction, we describe some simplifying nota-
tion. We will denote by â‰¤â€² inequality up to a multiplicative constant Cr
with C depending only on k. Also, we will write Hi = H if the coordi-
nates of the multi-index i âˆˆ{1,...,k + 1}n are all diï¬€erent, and Hi = 0
otherwise, and we will drop the arguments of H or Hi, so P
i Hi will mean
P
iâˆˆ{1,...,k+1}n Hi(X(1)
i1 ,...,X(k+1)
ik+1 ). Finally, for A âŠ‚{1,...,k + 1}, EA will
mean integration with respect to the variables X(r)
i
only, for r âˆˆA and i â‰¤n.
Applying (3.30) conditionally on the variables X(j)
i
, j = 1,...,k, we obtain
E

X
i
Hi
 â‰¤â€² E1,...,k
"
rr/2
 
Ek+1

X
ik+1
 X
i1,...,ik
Hi
!
2!r/2#
(3.34)
+ E1,...,k
"
rrEk+1 max
ik+1

X
i1,...,ik
Hi

r#
.
In order to deal with the ï¬rst term in (3.34), for each x1,...,xk âˆˆS ï¬xed
we consider the random variable P
ik+1 Hi(x1,...,xk,X(k+1)
ik+1 ) as a function
from Sk into the Banach space L2(â„¦,Î£,P;B) of B-valued random variables
whose B norms are square integrable, with norm
|F(x1,...,xk,X(k+1)
ik+1 )|âˆ—:= (Ek+1âˆ¥F(x1,...,xk,X(k+1)
ik+1 )âˆ¥2)1/2.
To apply the induction hypothesis to the statistic P
i1,...,ik(P
ik+1 Hi) in this
Banach space with the norm | Â· |âˆ—, we ï¬rst note that, if we denote by ËœÎº and

LOCAL U-STATISTIC PROCESS
31
ËœÏ‡ the corresponding quantities associated with this statistic, then
ËœÎº =
max
x1,...,xkâˆˆS

X
ik+1
H(x1,...,xk,X(k+1)
ik+1 )

âˆ—
â‰¤nÎº
and
ËœÏ‡n =
 
E1,...,k

X
i1,...,ik
 X
ik+1
Hi
!
2
âˆ—
!1/2
=
 
E

X
i
Hi

2!1/2
= Ï‡n.
Hence, the induction hypothesis gives
rr/2E1,...,k
 
Ek+1

X
ik+1
 X
i1,...,ik
Hi
!
2!r/2
= rr/2E1,...,k

X
i1,...,ik
 X
ik+1
Hi
!
r
â‰¤â€² rr/2[rkr/2 ËœÏ‡r
n + r(k+1)r/2n(kâˆ’1)rËœÎºr + rkrËœÎºr]
â‰¤r(k+1)r/2Ï‡r
n + r(k+2)r/2nkrÎºr + r(k+1/2)rnrÎºr.
Now, if n â‰¤r1/2, then r(k+1/2)rnr â‰¤r(k+1)r and if n > r1/2, then r(k+1/2)rnr â‰¤
r(k+2)r/2nkr, so that
rr/2E1,...,k
 
Ek+1

X
ik+1
 X
i1,...,ik
Hi
!2
!r/2
(3.35)
â‰¤â€² r(k+1)r/2Ï‡r
n + r(k+2)r/2nkrÎºr + r(k+1)rÎºr.
Finally, we apply the induction hypothesis conditionally on the variables
X(k+1)
i
to the second term of (3.34) by considering that term to be a U-
statistic with values in the Banach space â„“âˆ
n (B) := {(v1,...,vn):vi âˆˆB},
with norm |(v1,...,vn)| := max1â‰¤iâ‰¤n âˆ¥viâˆ¥. In fact, with this deï¬nition,
max
ik+1

X
i1,...,ik
Hi

=

X
i1,...,ik
(Hi(X(1)
i1 ,...,X(k)
ik ,X(k+1)
1
),...,Hi(X(1)
i1 ,...,X(k)
ik ,X(k+1)
n
))
,
and if we denote by Îº and Ï‡n the corresponding parameters, we have, for
each value of X(k+1)
i
, j = 1,...,n,
Îº =
max
x1,...,xkâˆˆSâˆ¥(H(x1,...,xk,X(k+1)
1
),...,H(x1,...,xk,X(k+1)
n
))âˆ¥â‰¤Îº

32
E. GINÂ´E AND D. M. MASON
and
Ï‡n =
 
E1,...,k max
ik+1

X
i1,...,ik
Hi

2!1/2
â‰¤nkÎº.
So, induction gives
rrE1,...,k max
ik+1

X
i1,...,ik
Hi

r
â‰¤â€² rr[rkr/2Ï‡r
n + r(k+1)r/2n(kâˆ’1)rÎºr + rkrÎºr]
â‰¤Îºr[r(k+2)r/2nkr + r(k+3)r/2n(kâˆ’1)r + r(k+1)r].
By considering the cases n â‰¤r1/2 and n > r1/2 we see that
r(k+3)r/2n(kâˆ’1)r â‰¤max(r(k+2)r/2nkr,r(k+1)r),
from which it follows that
rrE1,...,k max
ik+1

X
i1,...,ik
Hi

r
â‰¤â€² Îºr[r(k+2)r/2nkr + r(k+1)r].
(3.36)
Now, the ï¬rst part of the theorem follows by substituting the estimates (3.35)
and (3.36) into inequality (3.34). The proof of the theorem is completed
by noting that (3.33) follows from (3.32) via de la PeËœnaâ€™s [6] decoupling
inequality (see Theorem 3.1.1 in de la PeËœna and GinÂ´e [7]).
â–¡
We note that this theorem could have been proved, with only formal
changes, for Hi depending on the subindices i. GinÂ´e, Lata la and Zinn, un-
published, have a moment inequality for B-valued canonical U-statistics of
order 2 without boundedness assumptions that contains (3.32) for k = 2.
Our proof is inspired by theirs.
We shall apply (3.33) to the special case when B = Lp(Rd), 1 â‰¤p < 2,
and H(x1,...,xk) = Ï€kKh(Â·,x1,...,xk), to obtain the following. Recall the
deï¬nition (2.21) of Âµs.
Corollary 3.
Let K, fg and s > 0 satisfy the conditions of Theorem
3 for 1 â‰¤p < 2. Then there exist Î³ > 0 and D > 0 such for all n â‰¥1 and
x > 0,
Pr
âˆ¥P
Ikn Ï€kKh(Â·,Xi1,...,Xik)âˆ¥p
Dnkâˆ’1/
âˆš
h
> x

â‰¤Î³ exp

âˆ’

x
âˆ¥Kâˆ¥p,2,s
1/k
,
(3.37)
where âˆ¥Kâˆ¥p,2,s = âˆ¥Kâˆ¥p âˆ¨âˆ¥Kâˆ¥L2(Âµs).
For the proof, ï¬rst, note the following easy bound for âˆ¥âˆ¥Ï€kKhâˆ¥pâˆ¥âˆ,
namely, we can choose some A1 > 0, so that
Îº := A1âˆ¥Kâˆ¥p/h1âˆ’1/p â‰¥
sup
x1,...,xkâˆˆS
âˆ¥Ï€kKh(Â·,x1,...,xk)âˆ¥p.
(3.38)

LOCAL U-STATISTIC PROCESS
33
To see this, just observe that Ï€kKh(t,x1,...,xk) is a linear combination of
terms of the form hâ„“(t,xi1,...,xiâ„“) with (i1,...,iâ„“) âˆˆIâ„“
n and 0 â‰¤â„“â‰¤k, where
h0(t) = P mKh and, for â„“â‰¥1,
hâ„“(t,xi1,...,xiâ„“) = P mâˆ’â„“Kh(t,x1,...,xâ„“,Xâ„“+1,...,Xm)
= P mâˆ’â„“1
m!
X
ÏƒâˆˆIm
m
Kh(t âˆ’gÏƒ(x1,...,xâ„“,Xâ„“+1,...,Xm))
and gÏƒ(y1,...,ym) = g(yÏƒ1,...,yÏƒm). Then Jensenâ€™s inequality for expecta-
tions and averages and a substitution yield
Z
|hâ„“(t,x1,...,xl)|p dt â‰¤
Z
|Kh(t)|p dt = h1âˆ’p
Z
|K(t)|p dt.
We shall also need a good bound for Eâˆ¥P
Ikn Ï€kKh(Â·,Xi1,...,Xik)âˆ¥p in
order to estimate Ï‡n in (3.31). Such a bound will be based on the following
lemma, which is an extension of ideas and results in Chapter 7 in Devroye
[8] and Section 3 of Devroye [9].
Lemma 1.
Let 1 â‰¤p < 2. If f and k are two nonnegative functions on
Rd such that f,k âˆˆL1(Âµs) for some s > d(2âˆ’p)/p, then, for any 0 < b < âˆ,
sup
hâˆˆ(0,b]
Z
(kh âˆ—f)p/2(y)dy â‰¤C(âˆ¥fâˆ¥L1(Âµs)âˆ¥kâˆ¥L1(Âµs))p/2
for some constant C that depends only on d, p and s.
Proof.
Let q = sp/(2âˆ’p) and note that v(y) := (1+|y|)âˆ’q is integrable.
Then, by Jensen with respect to the probability measure v(y)dy/âˆ¥vâˆ¥1, we
have
Z
(kh âˆ—f)p/2(y)dy =
Z
v(y)âˆ’1(kh âˆ—f)p/2(y)v(y)dy
â‰¤âˆ¥vâˆ¥1âˆ’p/2
1
Z
(1 + |y|)s(kh âˆ—f)(y)dy
p/2
.
Since (1+|u+v|) â‰¤(1+|u|)(1+|v|) and 1+|hu| â‰¤(1âˆ¨h)(1+|u|) for h > 0,
we also haveZ
(1 + |y|)s(kh âˆ—f)(y)dy
â‰¤
Z Z
(1 + |y âˆ’x|)s(1 + |x|)skh(y âˆ’x)f(x)dxdy
â‰¤(1 âˆ¨bs/d)âˆ¥fâˆ¥L1(Âµs)âˆ¥kâˆ¥L1(Âµs).
The lemma follows from these inequalities.
â–¡

34
E. GINÂ´E AND D. M. MASON
Lemma 2.
If K âˆˆL2(Rd) and h > 0, then, for 1 â‰¤k â‰¤m and t âˆˆRd,
E(Ï€kKh(t,X1,...,Xk))2 â‰¤((K2)h âˆ—fg)(t)
h
.
(3.39)
Let now K, fg and s > 0 satisfy the conditions of Theorem 3 for 1 â‰¤p < 2,
and let 0 < b < âˆ. Then there exists C < âˆ, such that, for 1 â‰¤k â‰¤m and
all 0 < h â‰¤b,
 
E

X
Ikn
Ï€kKh(Â·,Xi1,...,Xik)

2
p
!1/2
â‰¤Câˆ¥Kâˆ¥L2(Âµs)nk/2
h1/2
.
(3.40)
Proof.
Using the fact that Ï€k is a projection in L2(Pr), and applying
convexity of the square function to the symmetrization of Kh, we have
E(Ï€kKh(t,X1,...,Xk))2 â‰¤1
h2 EK2
t âˆ’g(X1,...,Xm)
h1/d

= 1
h((K2)h âˆ—fg)(t),
that is, (3.39). Next, by orthogonality,
E
 X
Ikn
Ï€kKh(Â·,Xi1,...,Xik)
!2
=
k!n!
(n âˆ’k)!E(Ï€kKh(t,X1,...,Xk))2.
Then the Minkowski inequality for integrals (e.g., Folland [14], page 194)
and the above results yield
 
E

X
Ikn
Ï€kKh(Â·,Xi1,...,Xik)

2
p
!1/2
â‰¤

 
E
 X
Ikn
Ï€kKh(Â·,Xi1,...,Xik)
!2!1/2
p
â‰¤
m!nk
h
1/2Z
((K2)h âˆ—fg)p/2(t)dt
1/p
.
The result (3.40) follows now from Lemma 1.
â–¡
Proof of Corollary 3.
It follows from Lemma 2 and from (3.38)
that we can take, for some A2 > 0,
Ï‡n := A2nk/2âˆ¥Kâˆ¥p,2,s/
âˆš
h
and
Îº := A1âˆ¥Kâˆ¥p,2,s/h1âˆ’1/p.

LOCAL U-STATISTIC PROCESS
35
Assume that 0 < h â‰¤1 and r â‰¥2. Then we have the bounds
rk/2Ï‡n = A2âˆ¥Kâˆ¥p,2,srk/2nk/2/
âˆš
h â‰¤A2âˆ¥Kâˆ¥p,2,srknkâˆ’1/
âˆš
h,
r(k+1)/2nkâˆ’1Îº = A1âˆ¥Kâˆ¥p,2,sr(k+1)/2nkâˆ’1/h1âˆ’1/p â‰¤A1âˆ¥Kâˆ¥p,2,srknkâˆ’1/
âˆš
h
and
rkÎº = rkA1âˆ¥Kâˆ¥p,2,s/h1âˆ’1/p â‰¤A1âˆ¥Kâˆ¥p,2,srknkâˆ’1/
âˆš
h.
By (3.33), this says that for some D > 0, for all r â‰¥2,
E

X
Ikn
Ï€kKh(Â·,Xi1,...,Xik)

r
p
â‰¤(Dâˆ¥Kâˆ¥p,2,srknkâˆ’1/
âˆš
h)r
and thus
E

X
Ikn
Ï€kKh(Â·,Xi1,...,Xik)

r/k
p
â‰¤
 
E

X
Ikn
Ï€kKh(Â·,Xi1,...,Xik)

r
p
!1/k
â‰¤(Dâˆ¥Kâˆ¥p,2,srknkâˆ’1/
âˆš
h)r/k
= (3kDâˆ¥Kâˆ¥p,2,snkâˆ’1/
âˆš
h)r/krr/3r.
The same bound holds for r = 1. From this moment bound we easily get
that for all k â‰¥2,
E exp
âˆ¥P
Ikn Ï€kKh(Â·,Xi1,...,Xik)âˆ¥p
3kDâˆ¥Kâˆ¥p,2,snkâˆ’1/
âˆš
h
1/k
<
âˆ
X
r=0
rr
3rr! =: Î³ < âˆ.
The desired result (3.37) follows now from Markovâ€™s inequality and a re-
naming of D.
â–¡
Notice for future use that by (3.37) we get via (2.16) that for some C > 0,

âˆšnâˆ¥P
Ikn Ï€kKh(Â·,Xi1,...,Xik)âˆ¥p
nk

Î¨1/k
â‰¤CDâˆ¥Kâˆ¥p,2,s
âˆš
nh
.
(3.41)
3.5. Completion of the proofs of the CLT.
We are now ready to prove
(3.8) for 1 â‰¤p â‰¤âˆ, which will complete the proofs of Theorems 1, 2 and 3
(Section 3.1). We begin with the case p = âˆ.
Proof of Theorem 1.
Let
Kg,n := {K((y âˆ’g(Â·))/h1/d):y âˆˆRd,ahn â‰¤h â‰¤bhn}.
Since N(Kg,n,L2( ËœQ),Îµ) = N(Kn,L2( ËœQ â—¦gâˆ’1),Îµ) for every probability mea-
sure ËœQ on Rm, it follows from condition (a) in Theorem 1 that the classes

36
E. GINÂ´E AND D. M. MASON
Kg,n are VC-type with the same A and v and with envelopes Fn(g). More-
over, since the map
(y,h,x1,...,xm) 7â†’K((y âˆ’g(x1,...,xm))/h1/d)
is jointly measurable, these classes are image admissible Suslin, hence mea-
surable. So, we can apply Theorem 8 to them. Since by Minkowskiâ€™s inequal-
ity
(Î»hn)2EK2
Î»hn(y,X1,...,Xm) â‰¤EK2
y âˆ’g(X1,...,Xm)
(Î»hn)1/d

=
Z
K2
 y âˆ’w
(Î»hn)1/d

fg(w)dw â‰¤âˆ¥fgâˆ¥âˆâˆ¥Kâˆ¥2
2bhn,
we can take Ïƒ2 = Chn with C = bâˆ¥fgâˆ¥âˆâˆ¥Kâˆ¥2
2/âˆ¥Ï€kKâˆ¥2
âˆ. Hence, Theorem 8
gives that there is a constant Ck such that, for all n and k,
E
(
sup

1
nk/2 Î»hn
X
Ikn
Ï€kKÎ»hn(t,Xi1,...,Xik)
:t âˆˆRd,a â‰¤Î» â‰¤b
)
â‰¤Ck
p
hn[1 âˆ¨log(Aâˆ¥Fnâˆ¥L2(fg)/
p
hn )].
Hence, if nhn/[1 âˆ¨log(Aâˆ¥Fnâˆ¥L2(fg)/âˆšhn )]2 â†’âˆ, then for all k = 2,...,m,
E sup
aâ‰¤Î»â‰¤b
âˆ¥âˆšnU (k)
n (Ï€kKÎ»hn)âˆ¥âˆâ‰¤C[1 âˆ¨log(Aâˆ¥Fnâˆ¥L2(fg)/âˆšhn )]
n(kâˆ’1)/2h1/2
n
â†’0,
(3.42)
proving (3.8) in the Lâˆcase.
â–¡
Proof of Corollary 1.
By the Hoeï¬€ding decomposition (3.5), it
suï¬ƒces to show [in analogy with Proposition 1 and (3.8)] that
sup
0<Î»â‰¤1
|Î»(âˆšnmU (1)
n (Ï€1KÎ»hn(0,Â·,...,Â·)) âˆ’Î½n(0))| â†’0
in pr
(3.43)
and
sup
0<Î»â‰¤1
Î»âˆšn|U (k)
n (Ï€kKÎ»hn(0,Â·,...,Â·))| â†’0,
k = 2,...,m.
(3.44)
As in the proof of Proposition 1, (3.43) reduces to proving
sup
0<Î»â‰¤1
Î»
Z
|Î½n(âˆ’u) âˆ’Î½n(0)||KÎ»hn(u)|du â†’0
for i = 1,...,m. Let M be such that D is contained in the ball of radius M
about the origin in Rd. Since KÎ»hn(u) = I{u âˆˆ(Î»hn)1/dD/(Î»hn Vol(D))} is
zero for |u| > (Î»hn)1/dM, we have
sup
0<Î»â‰¤1
Î»
Z
|Î½n(âˆ’u) âˆ’Î½n(0)||KÎ»hn(u)|du â‰¤
sup
|u|â‰¤h1/d
n
M
|Î½n(âˆ’u) âˆ’Î½n(0)|,

LOCAL U-STATISTIC PROCESS
37
which tends to zero in probability by condition (2.13), proving (3.43).
For each n, the class of functions {IÎ»hnD :0 â‰¤Î» â‰¤1} is VC because it is
linearly ordered (these are the simplest VC classes), and its envelope is
contained in the class. The same is true for the class {Î»hnKÎ»hn(0,Â·,...,Â·)/
âˆ¥Ï€kK(0,Â·,...,Â·)âˆ¥âˆ:0 < Î» â‰¤1}. Then the logarithm in the bound (3.9) in
Theorem 8 is simply a constant, and that theorem gives
nk/2
hn
âˆ¥Ï€kK(0,Â·,... ,Â·)âˆ¥âˆ
E sup
0<Î»â‰¤1
|Î»U (k)
n (Ï€kKÎ»hn(0,Â·,...,Â·))| â‰¤CÏƒ
as long as nÏƒ2 > Câ€², for ï¬xed constants C and Câ€² and for k = 2,...,m, where
we can take
Ïƒ2 =
hnâˆ¥fgâˆ¥âˆ
Vol(D)âˆ¥Ï€kK(0,Â·,...,Â·)âˆ¥2âˆ
because, by change of variables,
sup
0<Î»â‰¤1
E[Î»2h2
nK2
Î»hn(âˆ’g(X1,...,Xm)/(Î»hn)1/d)] â‰¤hnâˆ¥fgâˆ¥âˆ/Vol(D).
Since nhn â†’âˆby hypothesis, the condition nÏƒ2 > Câ€² is satisï¬ed, and there-
fore, we can apply Theorem 8 and obtain
sup
0<Î»â‰¤1
Î»âˆšn|U (k)
n (Ï€kKÎ»hn(0,Â·,...,Â·))| â‰¤
Ck
n(kâˆ’1)/2h1/2
n
â†’0
for all 2 â‰¤k â‰¤m, proving (3.44).
â–¡
To ï¬nish the proof of Theorems 2 and 3 is more complicated because we
must deal with a mixed norm, the sup over Î» of an Lp norm. The proof
will consist in showing that the exponential inequalities from the above
subsections lead to an entropy bound of the random variables in (3.8).
Given a kernel L in Lp(Rd), 1 â‰¤p < âˆ, and h > 0, let Lh(t,x1,...,xm)
be the symmetrization of Lh(tâˆ’g(x1,...,xm)), as in (3.4). We observe that,
just as in (3.38), there is a constant c < âˆthat depends only on k such that
âˆ¥âˆ¥Ï€kLhâˆ¥pâˆ¥âˆâ‰¤câˆ¥Lâˆ¥p
h(pâˆ’1)/p ,
k = 1,...,m.
(3.45)
Because of (3.45), it makes sense to deï¬ne
XL,n :=

h(pâˆ’1)/p
n
nk/2
X
iâˆˆIkn
Ï€kLhn(Â·,Xi1,...,Xim)

p
.
(3.46)
Proof of (3.8) for 2 â‰¤p < âˆ.
For p â‰¥2, Lp is of type 2 and Theorem
9 then gives that, for a constant C that depends only on k and p, for all
x â‰¥0,
Pr{XL,n â‰¥x} â‰¤D exp

âˆ’

x
Câˆ¥Lâˆ¥p
2/k
,
(3.47)

38
E. GINÂ´E AND D. M. MASON
and then, by (2.16), we have for another constant C that depends on k and
p,
âˆ¥XL,nâˆ¥Î¨2/k â‰¤Câˆ¥Lâˆ¥p,
(3.48)
where Î¨2/k is the Young modulus of exponential type deï¬ned in (2.14) [but
with Î¨1(x) = ex âˆ’1] and âˆ¥Â· âˆ¥Î¨2/k is the associated (pseudo)norm (2.15).
Applying (3.48) to L = KÎ» âˆ’KÎ»â€², we obtain
âˆ¥XKÎ»,n âˆ’XKÎ»â€²,nâˆ¥Î¨2/k â‰¤âˆ¥XKÎ»âˆ’KÎ»â€²,nâˆ¥Î¨2/k â‰¤Câˆ¥KÎ» âˆ’KÎ»â€²âˆ¥p.
(3.49)
Then this bound and (3.45) allow us to apply the usual entropy integral
bound, for example, in the version given in de la PeËœna and GinÂ´e [7], Corollary
5.1.5, and conclude that for some constant D, keeping in mind that 0 âˆˆK[a,b],
 sup
aâ‰¤Î»â‰¤b
XKÎ»,n

Î¨2/k
â‰¤D
Z Câˆ¥Kâˆ¥p
0
Î¨âˆ’1
2/k(N(K[a,b],dp,Îµ))dÎµ,
(3.50)
where K[a,b] is deï¬ned by (2.17) and dp is the Lp(Rd) distance deï¬ned in
(2.18) (technically, this only holds for any separable version of the process
XKÎ»,n, but we see in a remark below that this process itself is separable).
Now, since up to constants Î¨Î± is increasing in Î±, hypothesis (a) in Theorem
2 implies that this integral is ï¬nite for all 2 â‰¤k â‰¤m. Taking into account
that the Orlicz distances of exponential type dominate (up to constants) the
Lr(Pr) distances, inequality (3.50) implies that for all 2 â‰¤k â‰¤m,
E sup
aâ‰¤Î»â‰¤b
âˆ¥âˆšnU (k)
n (Ï€kKÎ»hn)âˆ¥p â‰¤
C
n(kâˆ’1)/2h(pâˆ’1)/p
n
,
for some constant C that depends on k,p,a and b. The condition nh2(pâˆ’1)/p
n
â†’
âˆimplies that this expectation tends to zero for 2 â‰¤k â‰¤m, proving (3.8)
for p â‰¥2.
â–¡
Proof of (3.8) for 1 â‰¤p < 2.
Since fg and K2 are in L1(Âµs) for some
s > d(2 âˆ’p)/p, Lemma 1 applies and therefore Corollary 3 and inequality
(3.41) hold. Now, the proof of (3.8) and subsequently Theorem 3 follow
exactly as the proof of Theorem 2, but using Corollary 3 and its consequence
(3.41) instead of Theorem 9 and its consequence for XL,n. These give
âˆ¥XL,nâˆ¥Î¨1/k â‰¤Cnk/2âˆ’1h1/2âˆ’1/p
n
âˆ¥Lâˆ¥p,2,s
instead of (3.48), which yields, as in the previous proof, for some constant
D,
 sup
aâ‰¤Î»â‰¤b
XKÎ»,n

Î¨1/k
â‰¤Dnk/2âˆ’1h1/2âˆ’1/p
n
Z Câˆ¥Kâˆ¥p,2,s
0
Î¨âˆ’1
1/k(N(K[a,b],dp âˆ¨Ëœd2,s,Îµ))dÎµ

LOCAL U-STATISTIC PROCESS
39
instead of (3.50). Hence, for some constant C,
E sup
aâ‰¤Î»â‰¤b
âˆ¥âˆšnU (k)
n (Ï€kKÎ»hn)âˆ¥Lp â‰¤â€²
1
nk/2âˆ’1/2h1âˆ’1/p
n
E sup
aâ‰¤Î»â‰¤b
XKÎ»,n
â‰¤Câˆ¥Kâˆ¥p,2,s
(nhn)1/2 â†’0
if nhn â†’âˆ.
â–¡
Remark 5 (Separability of the process XKÎ»,n).
In the previous subsec-
tion technically we must make sure that
 sup
Î»âˆˆ[a,b]
XKÎ»,n

Î¨Î±
= sup
max
Î»âˆˆC XKÎ»,n

Î¨Î±
:C ï¬nite, C âŠ‚[a,b]

in order to ensure that the entropy bound applies exactly to the process
XKÎ»,n and not to a modiï¬cation thereof. For this, by standard arguments
(basically the monotone convergence theorem), it suï¬ƒces that there exist
D âŠ‚[a,b] countable such that
sup
Î»âˆˆ[a,b]
XKÎ»,n = sup
Î»âˆˆD
XKÎ»,n
a.s.
(3.51)
Let D denote the rationals in [a,b]. To show (3.51) it suï¬ƒces to prove that,
with probability 1, for each Î» âˆˆ[a,b] and any sequence Î»m in D such that
Î»m â†’Î» we have limmâ†’âˆXKÎ»mâˆ’KÎ»,n = 0. In turn to verify this it is enough
to check that
lim
mâ†’âˆ
 Z
Rd

X
Ikn
Ï€kKÎ»mhn âˆ’KÎ»hn(t,Xi1,...,Xik)

p
dt
!1/p
= 0.
(3.52)
Now, each of these Lp norms is bounded by a ï¬nite number of terms of the
form
Z
Rd |E(KÎ»mhn âˆ’KÎ»hn)(t âˆ’V )|p dt
1/p
,
where V is a random variable. Observe that
Z
Rd |E(KÎ»mhn âˆ’KÎ»hn)(t âˆ’V )|p dt
1/p
â‰¤

E
Z
Rd |(KÎ»mhn âˆ’KÎ»hn)(t âˆ’V )|p dt
1/p
=

E
Z
Rd

1
Î»mhn
K

t âˆ’V
(Î»mhn)1/d

âˆ’
1
Î»hn
K
 t âˆ’V
(Î»hn)1/d

p
dt
1/p
,

40
E. GINÂ´E AND D. M. MASON
which by the change of variables inside the integral u = (t âˆ’V )/(Î»mhn)1/d
is equal to

Î»mhn
Z
Rd

1
Î»mhn
K(u) âˆ’
1
Î»hn
K
Î»m
Î»
1/d
u

p
du
1/p
=
Z
Rd
K(u) âˆ’Î»m
Î» K
Î»m
Î»
1/d
u

p
du
1/p
(Î»mhn)1/pâˆ’1.
Now since K âˆˆLp(Rd) we have limÎ³â†’1
R
Rd |K(u)âˆ’K(Î³u)|p du = 0, and this,
in turn, implies that
lim
mâ†’âˆ
Z
Rd
K(u) âˆ’Î»m
Î» K
Î»m
Î»
1/d
u

p
du = 0,
which gives (3.51).
Acknowledgments.
We would like to thank Anton Schick and Wolfgang
Wefelmeyer for introducing us to this area via the second named author.
We are also grateful to an anonymous referee whose excellent detailed com-
ments were very helpful for improving and streamlining the presentation; in
particular the present proof of Lemma 1 belongs to him. Finally we thank
Julia Dony for pointing out a number of misprints as well as for a helpful
suggestion.
REFERENCES
[1] Ahmad, I. A. and Fan, Y. (2001). Optimal bandwidths for kernel density estimators
of functions of observations. Statist. Probab. Lett. 51 245â€“251. MR1822731
[2] Araujo, A. and GinÂ´e, E. (1980). The Central Limit Theorem for Real and Banach
Valued Random Variables. Wiley, New York. MR0576407
[3] Arcones, M. A. (1995). A Bernstein-type inequality for U-statistics and U-
processes. Statist. Probab. Lett. 22 239â€“247. MR1323145
[4] Bickel, P. and Ritov, Y. (1988). Estimating integrated squared density deriva-
tives: Sharp best order of convergence estimates. SankhyÂ¯a Ser. A 50 381â€“393.
MR1065550
[5] Deheuvels, P. and Mason, D. M. (2004). General asymptotic conï¬dence bands
based on kernel-type function estimators. Stat. Inference Stoch. Process. 7 225â€“
277. MR2111291
[6] de la PeËœna, V. H. (1992). Decoupling and Khintchineâ€™s inequalities for U-statistics.
Ann. Probab. 20 1877â€“1892. MR1188046
[7] de la PeËœna, V. H. and GinÂ´e, E. (1999). Decoupling. From Dependence to Indepen-
dence. Springer, New York. MR1666908
[8] Devroye,
L. (1987). A Course in Density Estimation. BirkhÂ¨auser, Boston.
MR0891874
[9] Devroye, L. (1992). A note on the usefulness of superkernels in density estimation.
Ann. Statist. 20 2037â€“2056. MR1193324
[10] Dudley, R. M. (1999). Uniform Central Limit Theorems. Cambridge Univ. Press.
MR1720712

LOCAL U-STATISTIC PROCESS
41
[11] Dunford, N. and Schwartz, J. T. (1988). Linear Operators. Part I. General The-
ory. Wiley, New York. MR1009162
[12] Eastwood, V. R. and HorvÂ´ath, L. (1999). Limit theorems for short distances in
Rm. Statist. Probab. Lett. 45 261â€“268. MR1718038
[13] Einmahl, U. and Mason, D. M. (2000). An empirical process approach to the
uniform consistency of kernel-type function estimators. J. Theoret. Probab. 13
1â€“37. MR1744994
[14] Folland, G. B. (1999). Real Analysis: Modern Techniques and Their Applications,
2nd ed. Wiley, New York. MR1681462
[15] Frees, E. W. (1994). Estimating densities of functions of observations. J. Amer.
Statist. Assoc. 89 517â€“525. MR1294078
[16] GinÂ´e, E. and Guillou, A. (2001). On consistency of kernel density estimators for
randomly censored data: Rates holding uniformly over adaptive intervals. Ann.
Inst. H. PoincarÂ´e Probab. Statist. 37 503â€“522. MR1876841
[17] GinÂ´e, E. and Koltchinskii, V. (2006). Concentration inequalities and asymp-
totic results for ratio type empirical processes. Ann. Probab. 34 1143â€“1216.
MR2243881
[18] GinÂ´e, E., Lata la, R. and Zinn, J. (2000). Exponential and moment inequalities for
U-statistics. In High Dimensional Probability, II (E. GinÂ´e, D. M. Mason and J.
A. Wellner, eds.) 13â€“38. BirkhÂ¨auser, Boston. MR1857312
[19] GinÂ´e, E. and Mason, D. M. (2006). Uniform in bandwidth estimation of integral
functionals of the density function. Preprint.
[20] GinÂ´e, E. and Mason, D. M. (2007). Laws of the iterated logarithm for the local
U-statistic process. J. Theoret. Probab. To appear.
[21] GinÂ´e, E., Mason, D. M. and Zaitsev, A. Yu. (2003). The L1-norm density esti-
mator process. Ann. Probab. 31 719â€“768. MR1964947
[22] Jain, N. (1977). Central limit theorem and related questions in Banach space.
In Probability (J. L. Doob, ed.) 55â€“65. Amer. Math. Soc., Providence, RI.
MR0451328
[23] Jammalamadaka, S. R. and Janson, S. (1986). Limit theorems for a triangular
scheme of U-statistics with applications to inter-point distances. Ann. Probab.
14 1347â€“1358. MR0866355
[24] Ledoux, M. and Talagrand, M. (1991). Probability in Banach Spaces. Springer,
Berlin. MR1102015
[25] Mason, D. M. (2004). A uniform functional law of the logarithm for the local em-
pirical process. Ann. Probab. 32 1391â€“1418. MR2060302
[26] Nolan, D. and Pollard, D. (1987). U-processes: Rates of convergence. Ann.
Statist. 15 780â€“799. MR0888439
[27] Parzen, E. (1962). On estimation of a probability density function and mode. Ann.
Math. Statist. 33 1065â€“1076. MR0143282
[28] Pinelis, I. F. (1995). Optimum bounds on moments of sums of independent random
vectors. Siberian Adv. Math. 5 141â€“150. MR1387858
[29] Pisier, G. and Zinn, J. (1978). On the limit theorems for random variables with
values in the spaces Lp, 2 â‰¤p < âˆ. Z. Wahrsch. Verw. Gebiete 41 289â€“304.
MR0471010
[30] Pollard, D. (1984). Convergence of Stochastic Processes. Springer, New York.
MR0762984
[31] Rost, D. (2000). Limit theorems for smoothed empirical processes. In High Dimen-
sional Probability, II (E. GinÂ´e, D. M. Mason and J. A. Wellner, eds.) 107â€“113.
BirkhÂ¨auser, Boston. MR1857318

42
E. GINÂ´E AND D. M. MASON
[32] Schick, A. and Wefelmeyer, W. (2004). Root n consistent density estimators
for sums of independent random variables. J. Nonparametr. Stat. 16 925â€“935.
MR2094747
[33] Schick, A. and Wefelmeyer, W. (2006). Pointwise convergence rates and central
limit theorems for kernel density estimators in linear processes. Statist. Probab.
Lett. 76 1756â€“1760. MR2274137
[34] Schick, A. and Wefelmeyer, W. (2007). Root-n consistent density estimators of
convolutions in weighted L1-norms. J. Statist. Plann. Inference 137 1765â€“1774.
[35] Talagrand, M. (1994). Sharper bounds for Gaussian and empirical processes. Ann.
Probab. 22 28â€“76. MR1258865
[36] Vakhania, N. (1981). Probability Distributions on Linear Spaces. North-Holland,
Amsterdam. MR0626346
[37] van der Vaart, A. W. and Wellner, J. A. (1996). Weak Convergence and Empir-
ical Processes. With Applications to Statistics. Springer, New York. MR1385671
Department of Mathematics
University of Connecticut
196 Auditorium Road
Storrs, Connecticut 06269-3009
USA
E-mail: gine@math.uconn.edu
Department of Food and Resource Economics
University of Delaware
206 Townsend Hall
Newark, Delaware 19717
USA
E-mail: davidm@udel.edu
