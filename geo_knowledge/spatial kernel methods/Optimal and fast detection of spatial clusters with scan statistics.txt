arXiv:1002.4770v1  [math.ST]  25 Feb 2010
The Annals of Statistics
2010, Vol. 38, No. 2, 1010â€“1033
DOI: 10.1214/09-AOS732
c
âƒInstitute of Mathematical Statistics, 2010
OPTIMAL AND FAST DETECTION OF SPATIAL CLUSTERS
WITH SCAN STATISTICS1
By Guenther Walther
Stanford University
We consider the detection of multivariate spatial clusters in the
Bernoulli model with N locations, where the design distribution has
weakly dependent marginals. The locations are scanned with a rect-
angular window with sides parallel to the axes and with varying sizes
and aspect ratios. Multivariate scan statistics pose a statistical prob-
lem due to the multiple testing over many scan windows, as well
as a computational problem because statistics have to be evaluated
on many windows. This paper introduces methodology that leads to
both statistically optimal inference and computationally eï¬ƒcient al-
gorithms. The main diï¬€erence to the traditional calibration of scan
statistics is the concept of grouping scan windows according to their
sizes, and then applying diï¬€erent critical values to diï¬€erent groups. It
is shown that this calibration of the scan statistic results in optimal
inference for spatial clusters on both small scales and on large scales,
as well as in the case where the cluster lives on one of the marginals.
Methodology is introduced that allows for an eï¬ƒcient approximation
of the set of all rectangles while still guaranteeing the statistical op-
timality results described above. It is shown that the resulting scan
statistic has a computational complexity that is almost linear in N.
1. Introduction and overview of results.
Spatial scan statistics are used
to detect clusters in spatial data and are widely used, for example, in epi-
demiology, biosurveillance and astronomy. In this paper, we consider the
Bernoulli model in R2, which is important in many of the above applica-
tions, see, for example, Kulldorï¬€(1999). All of the results in this paper can
easily be extended to higher dimensions, but focusing on the important two-
dimensional case simpliï¬es the exposition and the notation. The Bernoulli
model states that there are N locations in R2, and that each location has a
Received October 2008; revised June 2009.
1Supported by NSF Grant DMS-05-05682 and NIH Grant 1R21AI069980.
AMS 2000 subject classiï¬cations. Primary 62G10; secondary 62H30.
Key words and phrases. Scan statistic, Bernoulli model, optimal detection, multiscale
inference, fast algorithm, concentration inequality.
This is an electronic reprint of the original article published by the
Institute of Mathematical Statistics in The Annals of Statistics,
2010, Vol. 38, No. 2, 1010â€“1033. This reprint diï¬€ers from the original in
pagination and typographic detail.
1

2
G. WALTHER
label associated with it that takes on one of two possible outcomes, say 0 and
1. Conditional on the locations, the values of these labels are realizations of
independent Bernoulli random variables with parameter p at all locations in
a certain set R and parameter q at all locations in Rc.
The null hypothesis is
H0 :p = q
and the alternative hypothesis is H1 :q < p for some unknown set R out of a
certain class of sets, which in this paper is taken to be the class of rectangles
with sides parallel to the axes and with arbitrary sizes and aspect ratios.
Example 1.
Each location represents the spatial location of a person
which is either healthy (label 0) or diseased (label 1). If q < p, then R
represents the local area of a disease outbreak. The task is to detect such
disease clusters R where the disease density is signiï¬cantly higher than the
population density; see, for example, Kulldorï¬€(1999) and the references
given there.
Example 2.
A ï¬‚ow cytometer measures various numerical character-
istics of each of a large number of cells. Thus, each cell can be identiï¬ed
with a point in Euclidean space. One task in the analysis ï¬‚ow cytometry
data is to describe local regions where two cell distributions are diï¬€erent.
Roederer and Hardy (2001) and Roederer et al. (2001) model such regions
as rectangles with sides parallel to the axes. The reason for this is that such
sets are easy to interpret and easy to implement on instruments for further
processing. Also, sometimes the diï¬€erence eï¬€ect lives on a lower-dimensional
subspace, which is a special case of axis-parallel rectangles. Suppose one has
a sample drawn i.i.d. from a distribution G, and a second sample drawn
i.i.d. from a distribution H. Label each observation in the ï¬rst sample with
a 0 and each observation in the second sample with a 1. If G = H, then the
problem is left invariant under permutations of the labels. It will be seen
shortly that thus the inference for Example 2 can proceed identically to that
for Example 1.
Further examples are given, for example, in Kulldorï¬€(1999). There is a
large body of work on univariate scan statistics; see, for example, the refer-
ences in Glaz and Balakrishnan (1999) and in Glaz, Naus and Wallenstein
(2001), but the multivariate case is much less well developed. One reason
is that computational issues play a prominent role when multivariate scan
windows need to be evaluated at possibly many locations. Some references
for the multivariate case that are relevant for the problem studied here are
Naus (1965), Loader (1991), Chen and Glaz (1996), Alm (1997), Anderson
and Titterington (1997), Kulldorï¬€(1997, 1999), Naiman and Priebe (2001),

OPTIMAL AND FAST SCAN STATISTICS
3
and on the computational aspect, Neill and Moore (2004a, 2004b). A recent
reference for the multivariate two-sample problem is Rohde (2009), who con-
structs regions of signiï¬cant diï¬€erence based on nearest-neighbor statistics.
To simplify the exposition, we will assume that the distribution F of the
locations is continuous and has independent marginals. All of the main re-
sults continue to hold if the marginals are weakly dependent, for example,
if they are Ïˆ-mixing. But a completely general design of the N locations re-
quires some modiï¬cations, which will be reported elsewhere. It is also conve-
nient to only consider rectangles R with F(R) â‰¤1/8, which is an innocuous
restriction for most problems.
In our analysis, we will condition on the sample size N and on the N
locations. Under the null hypothesis, the problem is then left invariant under
permutations of the labels, and exact ï¬nite sample signiï¬cance statements
for rectangles R can be obtained by a permutation test. There are two
major problems associated with such an inference: as the class of rectangles
is large, a statistical problem arises in the form of multiple testing, and
a computational problem arises due to the need to evaluate test statistics
on many rectangles. This paper introduces methodology that leads to both
statistically optimal inference and computationally eï¬ƒcient algorithms.
The conventional deï¬nition of a scan statistic is
max
RâˆˆRT(R),
(1)
where R is a set of scan windows such as the set of rectangles described
above, and T is a standardized test statistic that is evaluated locally for
each scan window. Critical values are then derived for this overall maximum.
In this paper, we propose to use size-dependent critical values obtained by
grouping windows according to their size: all windows that contain between
2âˆ’â„“âˆ’1N and 2âˆ’â„“N locations are grouped into one block, â„“â‰¥3. Then we
use diï¬€erent critical values for diï¬€erent blocks as proposed by Ruï¬bach and
Walther (2009) in a certain univariate context. The heuristic motivation for
this approach is the following: there are of the order N disjoint windows
containing a small number of locations each. As the corresponding local
statistics T will be roughly independent, the maximum over the small win-
dows will behave like the maximum of N i.i.d. random variables. This will
tend to be stochastically much larger than the maximum over windows of
size N/8 (say), which will roughly behave like the maximum of 8 of these
i.i.d. random variables. Thus, the distribution of the conventional scan statis-
tic (1) will be dominated by the small windows, with a corresponding loss
of power for larger windows. Grouping windows according to their size and
employing size-dependent critical values allows to remedy this eï¬€ect. Indeed,
it will be shown below that this methodology allows for the following large
sample results:

4
G. WALTHER
â€¢ If the eï¬€ect q < p lives on a small rectangle, then the blocked scan statistic
is essentially as powerful as any test can possibly be.
â€¢ If the eï¬€ect q < p lives on a large rectangle, then the blocked scan statistic
is again optimal, even in comparison to tests that are allowed to use
a priori knowledge of the correct window size. That is, scanning with
diï¬€erent window sizes does not result in a signiï¬cant penalty.
â€¢ If the eï¬€ect q < p lives on one of the two marginals, then the above
optimality results still hold in the one-dimensional framework. That is,
scanning with two-dimensional rectangles does not result in a signiï¬cant
penalty even if it is known a priori that the eï¬€ect lives on a univariate
marginal.
We will give heuristic explanations of these results as well as rigorous
mathematical statements. These results use a concentration inequality for
the hypergeometric distribution which may be of independent interest. The
optimality results require the use of size-dependent critical values, and it
appears that such methodology has not been used before for scan statistics.
In the setting of univariate function estimation in the Gaussian White Noise
model, DÂ¨umbgen and Spokoiny (2001) employed a scale-dependent penalty
term. It is not clear how a useful penalty term can be derived for the prob-
lem under consideration here. Also, the univariate results in Ruï¬bach and
Walther (2009) suggest that the block procedure yields a better ï¬nite sample
performance for relevant sample sizes.
The construction of eï¬ƒcient algorithms, and also the particular proof
of the above optimality results, requires an economical approximation of
the set of all rectangles. We prove an approximation theorem that allows
for an adequate approximation of the set of all rectangles by O(N log2 N)
rectangles. By comparison, there are O(N 4) rectangles that contain diï¬€erent
subsets of the N locations. As a consequence, it will be shown that the
blocked scan statistic can be implemented with a computational complexity
that is almost linear in N.
It will be seen that there is a close connection between the computational
approximation scheme and the statistical inference, with the grouping of
rectangles according to their size being a central theme in each case.
2. The blocked scan statistic.
Kulldorï¬€(1997) derives the log-likelihood
ratio statistic for a given scan window R as
T(R) = n

Ë†plog Ë†p
p + (1 âˆ’Ë†p)log 1 âˆ’Ë†p
1 âˆ’p

+ (N âˆ’n)

Ë†q log Ë†q
p + (1 âˆ’Ë†q)log 1 âˆ’Ë†q
1 âˆ’p

,

OPTIMAL AND FAST SCAN STATISTICS
5
Fig. 1.
Constructing an approximating set of rectangles. Units on the axes are with
respect to the marginal distributions FX and FY .
if Ë†q â‰¤Ë†p, and T(R) = 0, otherwise. Here, n := #R is the number of locations in
R, p is the overall proportion of 1â€™s, and Ë†p and Ë†q are the proportion of 1â€™s in R
and in Rc, respectively. Despite its cumbersome form, this statistic has been
widely adapted in the computer science literature; see, for example, Neill
and Moore (2004a, 2004b). The concentration inequality given in Theorem
4 shows that this transformation of Ë†q and Ë†p has the beneï¬t of a clean tail
behavior.
T(R) is zero if Ë†p = Ë†q and positive if Ë†q < Ë†p. We restrict ourselves to the
alternative hypothesis q < p for notational simplicity and because this case
is most relevant for applications, but all the following results continue to
hold for the alternative p Ì¸= q after a simple modiï¬cation of the deï¬nition of
T(R).
We will evaluate T on a set of rectangles that is a good approximation to
the set R := {axis-parallel rectangles in R2}. The following theorem has a
constructive proof that shows how to construct an economical set of rectan-
gles that approximate all rectangles in R whose size (as measured in terms
of F) is about s, namely R(s) := {R âˆˆR:s/2 < F(R) â‰¤s}.
Theorem 1.
For every s,Îµ âˆˆ(0,1), there exists Rapp(s,Îµ) âŠ‚R such
that:
1. For every R âˆˆR(s), there exists Râ€² âˆˆRapp(s,Îµ) with F(Râ–³Râ€²) â‰¤ÎµF(R).
2. #Rapp(s,Îµ) â‰¤Csâˆ’1Îµâˆ’4 log(2/s) for a universal constant C.
The idea for the approximation scheme is depicted in Figure 1 and ex-
plained in Section 3. To construct an approximation for all of R we proceed
as follows. First, note that R = Sâˆ
â„“=0 R(2âˆ’â„“). Second, the construction of
Rapp(s,Îµ) depends on F, which is typically unknown. To obtain an approx-
imation that depends on the observations only, we replace F by the empir-
ical measure FN in the construction of Rapp(s,Îµ) and call the resulting set

6
G. WALTHER
Rapp,N(s,Îµ). Then we deï¬ne our approximating set as
Rapp,N :=
âŒŠlog2(N/(2log N))âŒ‹
[
â„“=3
Rapp,N(2âˆ’â„“,â„“âˆ’1/2).
(2)
The particular choice Îµ = â„“âˆ’1/2 yields the optimality results given in Theo-
rem 2 below. Thus, the smaller the rectangle, the ï¬ner the approximation
relative to the size of the rectangle. Section 4 gives an algorithm that con-
structs Rapp,N. The precise result about this approximation is as follows.
Corollary 1.
There exists Rapp,N âŠ‚R depending only on FN such
that:
1. For every R âˆˆR with F(R) âˆˆ[2log N
N
, 1
8], there exists Râ€² âˆˆRapp,N with
Râ€² âŠ‚R and F(R â–³Râ€²) â‰¤9
8
F (R)
âˆš
âŒŠlog2(1/F (R))âŒ‹with probability converging to
1 uniformly in R âˆˆR and F.
2. #Rapp,N â‰¤Câ€²N log2 N for a universal constant Câ€².
By comparison, a naive enumeration of all rectangles that contain diï¬€er-
ent subsets of the N locations results in O(N 4) rectangles and therefore is
generally computationally infeasible. The algorithm in Section 4 computes
the scan statistic T over Rapp,N in O(N log4 N) steps, i.e., with a compu-
tation time that is almost linear in N.
We will call Rapp,N(2âˆ’â„“,...) the â„“th block of rectangles. The idea for the
statistical methodology is closely connected to this approximation scheme:
as all the rectangles in the â„“th block have about the same size, we will
assign to those rectangles the same critical value. Following the criterion
given in Ruï¬bach and Walther (2009), we set these critical values such that
the signiï¬cance level of the â„“th block decreases as âˆ¼â„“âˆ’2.
In more detail, let Î± âˆˆ(0,1) and deï¬ne qâ„“(Î±) to be the (1âˆ’Î±)-quantile of
maxRâˆˆâ„“th block T(R) when the labels are permuted randomly. For notational
convenience, we suppress the dependence of qâ„“(Î±) on the sample size N and
on p. Let ËœÎ± be the largest number such that
P
 âŒŠlog2(N/(2log N))âŒ‹
[
â„“=3

max
Râˆˆâ„“th blockT(R) > qâ„“
 ËœÎ±
â„“2
!
â‰¤Î±.
(3)
By construction, one can then claim with guaranteed simultaneous ï¬nite
sample conï¬dence 1 âˆ’Î± that H0 is violated on every rectangle R on which
T(R) > qâ„“(ËœÎ±/â„“2), where â„“is the block index of R. As explained in Ruï¬bach
and Walther (2009), it is advantageous in practice to replace â„“2 by, for

OPTIMAL AND FAST SCAN STATISTICS
7
example, (10 + â„“)2, and all of the following results also apply for such a
modiï¬cation.
The qâ„“can be readily simulated with a simple extension of the usual
Monte Carlo technique for a permutation test: for each block, one records in
a list the maximum for each Monte Carlo permutation of the labels. Then
one can use a bisection method on the lists of sorted maxima to ï¬nd ËœÎ±.
3. Optimality.
In the following, we consider a growing sample size N.
The result below allows for a quite general situation where the rectangle RN
may vary with N, likewise the probabilities of success pN in RN and qN in
Rc
N, and the design distribution F N. For simplicity, we denote probabilities
under this model by PN. The key quantity for detecting q < p on some
rectangle R turns out to be
D(F(R),p,q) := F(R)(1 âˆ’F(R))(p âˆ’q)2
p(1 âˆ’q).
D(F(R),p,q) increases, and hence the detection of R becomes easier, if for
ï¬xed F(R) and q the diï¬€erence pâˆ’q increases, as one would expect. If F(R)
and p âˆ’q are ï¬xed, then D(F(R),p,q) increases as (p + q)/2 moves away
from 1/2, i.e., detection is easier if the background probability q is closer to
0 or if p is closer to 1. Theorem 2 below quantiï¬es when detection is possible
and shows that the blocked scan statistic is optimal for detecting both small
rectangles, that is, when F N(RN) â†’0, and large rectangles, that is, when
liminf F N(RN) > 0. An appropriate way to formulate these optimality re-
sults is via the asymptotic minimax framework, see, e.g., the investigation
of univariate shape properties on small scales in the Gaussian white noise
model in DÂ¨umbgen and Spokoiny (2001) and the results for small and large
scales in the context of a univariate density in DÂ¨umbgen and Walther (2008).
Theorem 2.
(a) Let {(F N,RN,pN,qN)} be an arbitrary sequence of
parameters with
D(F N(RN),pN,qN) â‰¥(2 + ÎµN)log(1/F N(RN))
N
where ÎµN
r
log
1
F N(RN) â†’âˆ.
Then
PN(the blocked scan statistic ï¬nds a signiï¬cant rectangle R âŠ‚RN) â†’1.
(b1) Let Ï†N be any sequence of tests with asymptotic level Î± âˆˆ(0,1) un-
der H0. For any prescribed sequence of continuous distributions {F N}, there

8
G. WALTHER
exists a sequence of parameters {(RN,pN,qN)} such that
D(F N(RN),pN,qN) â‰¥(2 âˆ’ÎµN)log(1/F N(RN))
N
with ÎµN â†“0,ÎµN
q
log
1
F N(RN) â†’âˆ, and limNPN(Ï†N rejects) â‰¤Î±.
This result continues to hold if one also prescribes the values {F N(RN)}
and {ÎµN}, provided that (log N)2/N â‰¤F N(RN) â†’0 and ÎµN
q
log
1
F N(RN) â†’
âˆ.
(b2) Let {F N} be any sequence of continuous distributions and {RN} any
sequence of rectangles with F N(RN)(1âˆ’F N(RN)) > 0, let bN âˆˆ[0,NF N(RN)(1âˆ’
F N(RN))), and let Ï†N be any test with asymptotic level Î± âˆˆ(0,1) under the
null hypothesis that the probability of success on RN equals that on Rc
N. If
PN(Ï†N rejects) â†’1
for every sequence of parameters {(pN,qN)} that satisï¬es D(F N(RN),pN,qN) â‰¥
bN
N , then necessarily bN â†’âˆ.
Parts (a) and (b1) show that in the case of small rectangles there is a
cutoï¬€at D = 2log
1
F N(RN)/N: if D â‰¥(2 + ÎµN)log
1
F N(RN)/N with ÎµN â†’0
suï¬ƒciently slowly, then the blocked scan statistic will detect the rectangle
RN with asymptotic power one. One the other hand, if D is of the size
(2 âˆ’ÎµN)log
1
F N(RN )/N, then no test can exist that detects the rectangle
with nontrivial asymptotic power. These two statements leave essentially no
room for any other test to beat the blocked scan statistic for detecting small
rectangles.
In the case of large rectangles, part (b2) states that any test Ï†N can
have asymptotic power 1 only if ND â†’âˆ. But under the latter condition,
the blocked scan statistic also has asymptotic power 1 [because ND â†’âˆ
arbitrarily slowly is suï¬ƒcient for the claim in (a) if
1
F N(RN) stays bounded].
Note that (b2) even allows the competing test Ï†N to possess prior knowledge
of the rectangle R.
These results clarify the tradeoï¬€when using a scan statistic with varying
window size. On the one hand, one can evidently gain substantial power by
matching the window size with the extent of the eï¬€ect. On the other hand,
varying the window size incurs a multiple testing penalty. The above results
show that this multiple testing penalty becomes negligible for large samples,
provided one employs an appropriate calibration of the various window sizes
such as the blocked scan statistic introduced here. An illustration will be
given in Section 4.
Furthermore, there is no substantial multiple testing penalty for searching
over multivariate rectangles when the eï¬€ect lives on one of the marginals.

OPTIMAL AND FAST SCAN STATISTICS
9
Theorem 3.
Suppose that the {RN} are in fact intervals on one of the
two axes. Then the conclusions of Theorem 2 continue to hold, even if the
tests Ï†N in (b1) and (b2) are allowed to use the prior knowledge about which
axis the {RN} live on.
A heuristic explanation of this result is as follows: Figure 1(a) depicts
1
s disjoint rectangles with content s. The rectangles of Figure 1(b) are ob-
tained by doubling the width of certain rectangles in Figure 1(a) and then
dividing the rectangle into two with a horizontal split. After log 1
s iterations
one obtains the rectangles of Figure 1(c). The idea of Theorem 1 is that in
the case of independent or weakly dependent marginals the totality of these
rectangles (after a reï¬nement allowing, e.g., certain translations) constitutes
an economical set of rectangles that approximates well the set of all rectan-
gles with content s. The diï¬ƒculty of the multiple testing problem depends
essentially on the cardinality of this approximating set, as local statistics
that pertain to rectangles with large overlap will be highly correlated and
thus will not aï¬€ect the multiple testing problem much. But the construction
depicted in Figure 1 results in 1
s log 1
s rectangles, which up to the log term is
of the same order as the 1
s rectangles in the univariate case of Figure 1(a).
Thus, one expects that the multiple testing problem in this multivariate
situation will not be signiï¬cantly more diï¬ƒcult than in the univariate case.
The proof of Theorem 2 makes use of the following concentration inequal-
ity for the hypergeometric distribution.
Theorem 4.
Let X denote the number of red items among n items
drawn without replacement out of N items of which R are red. Then
P(X â‰¥x) â‰¤C(L(x) + 2)exp(âˆ’L(x))
for x > m := nR/N,
P(X â‰¤x) â‰¤C(L(x) + 2)exp(âˆ’L(x))
for x < m
and
P(L(X) â‰¥x) â‰¤2C(x + 2)exp(âˆ’x)
for x > 0,
where L(x) := n(Ë†plog Ë†p
p + (1 âˆ’Ë†p)log 1âˆ’Ë†p
1âˆ’p) + (N âˆ’n)(Ë†q log Ë†q
p + (1 âˆ’Ë†q)log 1âˆ’Ë†q
1âˆ’p),
p := R
N , Ë†p := x
n, Ë†q := Râˆ’x
Nâˆ’n, and C := 2exp{
13
12p(1âˆ’p)( 1
n +
1
Nâˆ’n)}.
This inequality compares to the classical concentration bound obtained
from the Chernoï¬€â€“Hoeï¬€ding theorem as follows. Hoeï¬€ding [(1963), Theo-
rem 1 and Section 6] gives P(X â‰¥x) â‰¤exp(âˆ’n(Ë†plog Ë†p
p + (1 âˆ’Ë†p)log 1âˆ’Ë†p
1âˆ’p)). A
Taylor series expansion shows that for Ë†p near p the exponent behaves like
âˆ’n (Ë†pâˆ’p)2
2p(1âˆ’p), whereas âˆ’L(x) â‰ˆâˆ’n
(Ë†pâˆ’p)2
(1âˆ’n/N)2p(1âˆ’p). Thus, Theorem 4 accounts
for the variance correction factor Nâˆ’n
Nâˆ’1 for sampling without replacement.

10
G. WALTHER
Derbeko, El-Yaniv and Meir (2004) give an improvement to the Chernoï¬€â€“
Hoeï¬€ding bound that is weaker than that of Theorem 4. Rohde (2009) gives
a Bernstein-type inequality for the hypergeometric distribution.
Scanning on a grid and comparison with the algorithm of Neill and Moore.
Neill and Moore (2004a, 2004b) give an algorithm that runs in O(N log2 N)
steps for data that are binned on a
âˆš
N Ã—
âˆš
N grid. That algorithm produces
a rectangle R that attains maxR T(R) by partitioning the grid into overlap-
ping regions, bounding maxT over subregions, and pruning regions which
cannot contain the maximum. Thus, both the algorithm of Neill and Moore
and the algorithm introduced here run in almost linear time; see Proposi-
tion 1 below. Both algorithms achieve this by using an approximation. The
algorithm of Neill and Moore approximates the data by binning them on a
grid, and then ï¬nds the exact maximum over all rectangles on the grid. In
contrast, the methodology introduced here evaluates rectangles on the exact
data, but approximates the set of all rectangles. The results of this section
show that this algorithm results in a solution that is statistically optimal.
It is an open problem whether the algorithm of Neill and Moore results in a
solution that is statistically optimal, and how the grid has to be constructed
to achieve this.
Consider now the related problem where one observes a Bernoulli random
variable on each grid point of a
âˆš
N Ã—
âˆš
N grid. Then the design distribution
F has independent marginals, but it is not continuous any more. Still, the
methodology introduced in this paper can be readily adapted to this set-up
and shown to be statistically optimal. The conclusions of Theorems 2 and
3 continue to hold. However, the condition on the size of F(R) in Theorem
2(b1) now has to be set diï¬€erently for the marginal eï¬€ects considered in
Theorem 3. In the multivariate case, (b1) allows rectangles R as small as
F(R) â‰¥log2 N/N [and (a) even allows detection if F(R) â‰¥2log N/N], which
results in a detection threshold of about 2log N/N for rectangles with these
sizes. But any nonempty marginal interval R necessarily satisï¬es F(R) â‰¥
âˆš
N/N due to the nature of the grid, which results in a detection threshold
of about log N/N for the smallest detectable marginal intervals.
Controlling maxR T(R).
The cardinality of the approximating set of
rectangles is small enough so that the tail behavior of maxRâˆˆâ„“th block T(R)
can be controlled quite precisely by simply using Booleâ€™s inequality; see (10)
below. This is in contrast to the approximating set of intervals introduced
by Ruï¬bach and Walther (2009) for certain multiple testing problems on
the line. While that set leads to computationally eï¬ƒcient algorithms, its
cardinality is still so large that the control of maxIâˆˆâ„“th block T(I) requires in
addition the diï¬ƒcult stochastic control of the increments of T(I) as a pro-
cess in I. In light of the above results, one may surmise that for these and

OPTIMAL AND FAST SCAN STATISTICS
11
related problems, there typically exists an approximating set that not only
allows for statistical optimality and computationally eï¬ƒcient algorithms,
but which also obviates the need for the stochastic control of the increments
of T when used in conjunction with the block procedure. In particular, it
may be possible to recover the optimality results for the inference problems
treated in Ruï¬bach and Walther (2009) with the univariate version of the
algorithm introduced here.
4. Algorithm.
It is helpful to use the following notation in this section.
The coordinates of the N locations are (X1,Y1),...,(XN,YN), and we write
X(r) := X(round(r)âˆ§N) for real r, where X(1) â‰¤Â·Â·Â· â‰¤X(N) are the order statis-
tics of X1,...,XN. Each location has a label that is either 0 or 1. Here, is
the pseudo-code to enumerate the set of approximating rectangles and to
compute the corresponding local test statistics:
Sort the locations (X1,Y1),...,(XN,YN) according to the X-value.
for â„“= 3,...,âŒŠlog2
N
2log N âŒ‹do:
Set s := 2âˆ’â„“, Îµ := â„“âˆ’1/2/6.
for i = 0,...,â„“do:
for j = 0,...,âŒŠ(Îµs2i)âˆ’1âŒ‹do:
for k = j + 1,...,j + âŒŠ1
ÎµâŒ‹do:
Extract all locations (Xp,Yp) for which Xp falls in the interval
Xjk := [X(jÎµs2iN+1),X(kÎµs2iN)] and denote by
Njk the number of these locations.
Sort these extracted Yp and compute the vector of cumulative
sums of the labels of the (Xp,Yp) corresponding to the sorted Yp.
for m = 0,...,âŒŠ2i/ÎµâŒ‹do:
for n = m + 1,...,m + âŒŠ2/ÎµâŒ‹do:
Compute the test statistic on the rectangle
Xjk Ã— [Y(mÎµ2âˆ’iNjk+1),Y(nÎµ2âˆ’iNjk)], where the order
statistics Y(Â·) are with respect to the extracted Yp.
The running time of the algorithm is almost linear in N.
Proposition 1.
The above algorithm runs in O(N log4 N) time.
We illustrate the methodology with an example where 1000 locations are
drawn from a mixture of four bivariate normals. The labels are Bernoulli
with p = 0.4, except in the strip [x â‰¥5], where p = 0.6, and in the box
[1,2]Ã—[3,5], where p = 0.75. Critical values for the conventional scan statistic
(1) and the blocked scan statistic (3) were computed with 50000 random
permutations of the labels. Figure 2 (left) shows all minimal (with respect
to inclusion) boxes that are signiï¬cant at the 5% level using the calibration

12
G. WALTHER
Fig. 2.
Minimal signiï¬cant rectangles obtained with the conventional calibration for the
scan statistic (left) and the blocked scan statistic (right). Locations having label 1 are
plotted in red, locations with label 0 are black.
for the traditional scan statistic. Thus, we are 95% conï¬dent that each of
the depicted boxes contains a so-called overdensity, that is, somewhere inside
the box the probability of success p is larger than outside the box. Figure
2 (right) shows the resulting signiï¬cant boxes when the calibration for the
blocked scan statistic is used. In addition to detecting the small box at
[1,2] Ã— [3,5], the blocked scan statistic also detects the large box [x â‰¥5]. It
was found that this result was a frequent outcome for realizations of this
example.
5. Proofs.
Proof of Theorem 1.
We parametrize rectangles as follows: R =
(x,xâ€²,y,yâ€²) denotes the rectangle with the vertices (x,y),(xâ€²,y),(xâ€²,yâ€²) and
(x,yâ€²), where x,xâ€²,y,yâ€² âˆˆ[âˆ’âˆ,âˆ] and x < xâ€², y < yâ€². We will approximate
R(s) by the ï¬nite set Rapp(s,Îµ), which for notational simplicity we deï¬ne for
Îµ âˆˆ(0, 1
6) by Rapp(s,6Îµ) := {R:R = (xj,xk,ym,yn) := (F âˆ’1
X (jÎµs2i),F âˆ’1
X (kÎµs2i),
F âˆ’1
Y (mÎµ2âˆ’i), F âˆ’1
Y (nÎµ2âˆ’i)), where i,j,k,m and n are integers with 0 â‰¤i â‰¤
âŒˆlog2
1
sâŒ‰, 0 â‰¤j â‰¤âŒŠ(Îµs2i)âˆ’1âŒ‹, j + 1 â‰¤k â‰¤j + âŒŠ1/ÎµâŒ‹, 0 â‰¤m â‰¤âŒŠ2i/ÎµâŒ‹and
m + 1 â‰¤n â‰¤m + âŒŠ2/ÎµâŒ‹}. Here, F âˆ’1
X
and F âˆ’1
Y
denote the quantile functions
of the ï¬rst and second marginals of F, respectively, with F âˆ’1
X (p) = âˆ’âˆfor
p < 0 and F âˆ’1
X (p) = âˆfor p > 1.
Thus,
#Rapp(s,6Îµ) â‰¤Îµâˆ’12Îµâˆ’1
âŒˆlog2(1/s)âŒ‰
X
i=0
((Îµs)âˆ’12âˆ’i + 1)(Îµâˆ’12i + 1)

OPTIMAL AND FAST SCAN STATISTICS
13
â‰¤2Îµâˆ’2
âŒˆlog2(1/s)âŒ‰
X
i=0
4
3(Îµs)âˆ’12âˆ’i 7
6Îµâˆ’12i
â‰¤4sâˆ’1Îµâˆ’4 log2(4/s).
Now, let R = (x,xâ€²y,yâ€²) âˆˆR(s). We will show that there exists a Râ€² âˆˆ
Rapp(s,6Îµ) with F(R â–³Râ€²) â‰¤6Îµs and that one can even arrange that Râ€² âŠ‚
R. To this end set i := âŒˆlog2
FX([x,xâ€²])
s
âŒ‰. Thus,
s2iâˆ’1 < FX([x,xâ€²]) â‰¤s2i
(4)
so the index i is assigned to rectangles whose â€œlength,â€ as measured by FX,
lies between s
22i and s2i. Let j be the smallest integer such that xj > x,
let k be the largest integer so that xk < xâ€², let m be the smallest integer
with ym > y, and let n be the largest integer such that yn < yâ€². It will be
shown below that these indices fall in the ranges given in the deï¬nition
of Rapp(s,6Îµ), hence Râ€² := (xj,xk,ym,yn) âˆˆRapp(s,6Îµ), and by deï¬nition
Râ€² âŠ‚R. Further,
F(R â–³Râ€²) = F([x,xâ€²] Ã— ([y,ym] âˆª[yn,yâ€²]))
(5)
+ F(([x,xj] âˆª[xk,xâ€²]) Ã— [ym,yn]).
Now, FY ([y,ym]) â‰¤Îµ2âˆ’i by the deï¬nition of m, and the same bound applies
to FY ([yn,yâ€²]). Likewise, both FX([x,xj]) and FX([xk,xâ€²]) are not larger
than Îµs2i. Hence, (5) is not larger than
2FX([x,xâ€²])Îµ2âˆ’i + 2Îµs2iFY ([y,yâ€²])
= 2Îµ(z + sF(R)/z)
where z := FX([x,xâ€²])2âˆ’i âˆˆ(s/2,s] by (4)
â‰¤2Îµ(s/2 + 2F(R))
since s/2 < F(R)
< 6ÎµF(R).
It remains to show that i,j,k,m and n fall in the ranges given in the def-
inition of Rapp(s,6Îµ): 1 â‰¥FX([x,xâ€²]) â‰¥F(R) > s/2 implies 0 â‰¤i â‰¤âŒˆlog2
1
sâŒ‰.
Clearly, j â‰¥0. For Ëœj := âŒŠ(Îµs2i)âˆ’1âŒ‹, we have xËœj â‰¥F âˆ’1
X (1 âˆ’Îµs2i) â‰¥F âˆ’1
X (1 âˆ’
2ÎµFX([x,xâ€²])) â‰¥x by (4) and as Îµ â‰¤1/6. Hence, j â‰¤Ëœj. Next,
(k âˆ’j)Îµs2i = FX([xj,xk])

â‰¤FX([x,xâ€²]) â‰¤s2i,
â‰¥FX([x,xâ€²]) âˆ’2Îµs2i > 0,
by (4) and since Îµ â‰¤1/6. Hence, 1 â‰¤k âˆ’j â‰¤1/Îµ. Clearly, m â‰¥0. Fur-
ther, s/2 < F(R) â‰¤(FX([xj,xk]) + 2Îµs2i) Ã— (FY ([ym,âˆ)) + Îµ2âˆ’i) = (k âˆ’j +
2)Îµs2i(1 âˆ’(m âˆ’1)Îµ2âˆ’i). Together with (k âˆ’j + 2)Îµ â‰¤3 (see above), this
inequality yields 6(mâˆ’1)Îµ < 6Ã—2i âˆ’1, whence m < 2i/Îµâˆ’1/(6Îµ)+1 â‰¤2i/Îµ
since Îµ â‰¤1/6. Finally, s/2 < F(R) â‰¤(FX([xj,xk]) + 2Îµs2i) Ã— (FY ([ym,yn]) +

14
G. WALTHER
2Îµ2âˆ’i). With (4) this yields FY ([ym,yn]) â‰¥2âˆ’iâˆ’1/(1+2Îµ)âˆ’Îµ2âˆ’i+1 > 0 since
Îµ â‰¤1/6, hence n > m. Likewise, s â‰¥F(R) â‰¥FX([xj,xk]) Ã— FY ([ym,yn]) to-
gether with (4) gives s > s2iâˆ’1(n âˆ’m)Îµ2âˆ’i, hence n âˆ’m < 2/Îµ.
â–¡
Proof of Corollary 1.
Deï¬ne the random collection of rectangles as
in (2), where Rapp,N(s,Îµ) is deï¬ned as Rapp(s,Îµ) in the proof of Theorem 1
but with F âˆ’1
X and F âˆ’1
Y
replaced by the empirical quantile functions F âˆ’1
N,X and
F âˆ’1
N,Y , respectively. That is, we consider rectangles R = (xj,xk,ym,yn) such
that (xj,xj+1] has empirical measure FN,X about equal to Îµ
6s2i, likewise for
(xk,xk+1]; further (ym,ym+1] and (yn,yn+1] have empirical measure FN,Y
about equal to Îµ
62âˆ’i, where 0 â‰¤i â‰¤âŒˆlog2
1
sâŒ‰. Then result 2 of Theorem 1
yields
#Rapp,N â‰¤C
âŒŠlog2(N/(2log N))âŒ‹
X
â„“=1
2â„“â„“2 log 2â„“+1
â‰¤2C
N
log N

log2
N
2log N
3
log 2
â‰¤2CN log2
2 N.
Now, let R = (x,xâ€²,y,yâ€²) be a rectangle parametrized as in the proof of The-
orem 1. Set â„“:= âŒŠlog2
1
F (R)âŒ‹. Then 3 â‰¤â„“â‰¤âŒŠlog2
N
2log N âŒ‹by the assumptions
on R. We will construct another deterministic rectangle ËœR = (Ëœx, Ëœxâ€², Ëœy, Ëœyâ€²) such
that for Î³ = 1/8:
(A) F(R \ ËœR) â‰¤(1 + Î³)
F (R)
âˆš
âŒŠlog2(1/F (R))âŒ‹;
(B) P(there exists Râ€² âˆˆRapp,N(2âˆ’â„“,â„“âˆ’1/2): ËœR âŠ‚Râ€² âŠ‚R) â‰¥1 âˆ’16
1+Î³
Î³2âˆšlog N .
The claim of the corollary then follows.
To keep familiar notation set s := 2âˆ’â„“and Îµ := â„“âˆ’1/2. Deï¬ne
i :=

log2
FX([x,xâ€²])
s

,
so
2iâˆ’1 < FX([x,xâ€²])
s
â‰¤2i.
(6)
Then 0 â‰¤i â‰¤âŒˆlog2
1
sâŒ‰as required in the deï¬nition of Rapp,N(s,Îµ).
To construct ËœR, deï¬ne Ëœx, Ëœxâ€², Ëœy, Ëœyâ€² such that FX([x, Ëœx]) = FX([Ëœxâ€²,xâ€²]) = (1+
Î³)Îµs2i/6, FY ([y, Ëœy]) = FY ([Ëœyâ€²,yâ€²]) = (1 + Î³)Îµ2âˆ’i/6. Then x < Ëœx < Ëœxâ€² < xâ€² and
y < Ëœy < Ëœyâ€² < yâ€²: by (6), (1+Î³)Îµs2i/6 < FX([x,xâ€²])/2. Likewise, the deï¬nition

OPTIMAL AND FAST SCAN STATISTICS
15
of â„“implies s = 2âˆ’â„“< 2F(R), hence (1+Î³)Îµ2âˆ’i/6 â‰¤
s
4FX([x,xâ€²]) = sFY ([y,yâ€²])
4F (R)
<
FY ([y,yâ€²])
2
, which yields y < Ëœy < Ëœyâ€² < yâ€². Thus, ËœR âŠ‚R and
F(R \ ËœR) = F([x,xâ€²] Ã— ([y, Ëœy] âˆª[Ëœyâ€²,yâ€²]))
+ F(([x, Ëœx] âˆª[Ëœxâ€²,xâ€²]) Ã— [Ëœy, Ëœyâ€²])
< (1 + Î³)ÎµF(R)
as in the proof of Theorem 1,
using s/2 < F(R) by the deï¬nition of â„“. This establishes (A). Next,
P

at most Îµ
6s2iN observations in [x, Ëœx]

= P(FN,X([x, Ëœx]) â‰¤Îµs2i)
= P(FN,X([x, Ëœx]) âˆ’FX([x, Ëœx]) â‰¤âˆ’Î³Îµs2i/6)
â‰¤
1 + Î³
NÎ³2Îµs2i/6
by Chebyshev
â‰¤3
1 + Î³
Î³2p
(log 2)(log N)
since s2i â‰¥FX([x,xâ€²]) â‰¥F(R) â‰¥2log N
N
by (6) and â„“â‰¤log2 N. Hence, with
probability at least 1 âˆ’4
1+Î³
Î³2âˆšlog N an endpoint xj of one the rectangles in
Rapp,N(2âˆ’â„“,â„“âˆ’1/2) falls into [x, Ëœx]. Analogously, one can show that some xk,
ym and yn fall into [Ëœxâ€²,xâ€²], [y, Ëœy] and [Ëœyâ€²,yâ€²], respectively. Hence, there exists
a rectangle Râ€² âˆˆRapp,N(2âˆ’â„“,â„“âˆ’1/2) that satisï¬es ËœR âŠ‚Râ€² âŠ‚R. (B) follows.
â–¡
Proof of Theorem 2(a).
To simplify notation we write (F,R,p,q) for
(F N,RN, pN,qN). It will become clear that these parameters may vary with
N due to the uniformity of the following results. As usual, FN will denote
the empirical measure pertaining to F.
Set bN := ÎµN
q
log
1
F (R) â†’âˆ. (a) follows after showing:
(A)
PN
 
there exists a rectangle Râ€² âˆˆRapp,N with Râ€² âŠ‚R and
T(Râ€²) > log
1
F(R) +
s
bN log
1
F(R)
!
â†’1.
(B) Râ€² belongs to a block â„“whose critical value satisï¬es
qâ„“
 ËœÎ±
â„“2

â‰¤log
1
F(R) + 6log log
1
F(R) + Î³

16
G. WALTHER
with Î³ depending on Î± only.
For the proof of (A), one veriï¬es that the condition D(F(R),p,q) â‰¥(2 +
ÎµN)log
1
F (R)/N together with the inequality
(pâˆ’q)2
p(1âˆ’q) â‰¤1 for q < p implies
F(R) â‰¥2log N
N . So the block index â„“:= âŒŠlog2
1
F (R)âŒ‹of R satisï¬es 3 â‰¤â„“â‰¤
âŒŠlog2
N
2log N âŒ‹. Thus, by Corollary 1, with probability converging to 1 there
exists Râ€² âˆˆRapp,N such that Râ€² âŠ‚R and
F(Râ€²) â‰¥F(R)

1 âˆ’
9
8
p
âŒŠlog2(1/F(R))âŒ‹

â‰¥F(R)(1 âˆ’Î»N),
where Î»N := 2
3
q
bN
bN+âŒŠlog2(1/F (R))âŒ‹, and the last inequality follows from 3(1 +
âŒŠlog2
1
F (R)âŒ‹/bN) â‰¤(1+3/bN)âŒŠlog2
1
F (R)âŒ‹â‰¤28
35 âŒŠlog2
1
F (R)âŒ‹for N large enough,
using âŒŠlog2
1
F (R)âŒ‹â‰¥3.
Denote by Ë†p and Ë†q the proportion of 1â€™s in Râ€² and Râ€²c, respectively. On the
event AN := {FN(Râ€²)(1âˆ’FN(Râ€²))
F (R)(1âˆ’F (R))
â‰¥1 âˆ’25
24Î»N, Ë†pâˆ’Ë†q
pâˆ’q â‰¥1 âˆ’Î»N
6 , p
Ë†p â‰¥1 âˆ’Î»N
24 , 1âˆ’q
1âˆ’Ë†q â‰¥
1 âˆ’Î»N
24 } we have Ë†q < Ë†p as q < p. The function l(Ë†p) := Ë†plog Ë†p
p + (1 âˆ’Ë†p)log 1âˆ’Ë†p
1âˆ’p
satisï¬es l(p) = 0, lâ€²(p) = 0, and lâ€²â€²(Î¾) = Î¾âˆ’1(1 âˆ’Î¾)âˆ’1 â‰¥Ë†pâˆ’1(1 âˆ’Ë†q)âˆ’1 for Î¾ âˆˆ
[Ë†q, Ë†p]. Thus, Taylorâ€™s theorem gives on AN
T(Râ€²) = (#Râ€²)l(Ë†p) + (N âˆ’#Râ€²)l(Ë†q)
â‰¥(#Râ€²) (Ë†p âˆ’p)2
2Ë†p(1 âˆ’Ë†q) + (N âˆ’#Râ€²) (Ë†q âˆ’p)2
2Ë†p(1 âˆ’Ë†q)
= (#Râ€²)(N âˆ’#Râ€²)
N
(Ë†p âˆ’Ë†q)2
2Ë†p(1 âˆ’Ë†q)
â‰¥NF(R)(1 âˆ’F(R)) (p âˆ’q)2
2p(1 âˆ’q)

1 âˆ’25
24Î»N

1 âˆ’Î»N
6
2
1 âˆ’Î»N
24
2
â‰¥

1 âˆ’35
24Î»N

ND(F(R),p,q)/2
â‰¥log
1
F(R) + 1
2
 
1 âˆ’35
24Î»N

bN âˆ’35
12Î»N
s
log
1
F(R)
!s
log
1
F(R)
â‰¥log
1
F(R) + 1
72(bN âˆ’140
p
bN)
s
log
1
F(R)
since Î»N â‰¤2/3.
(A) follows once we show that PN(AN) â†’1. As for the ï¬rst event in
AN, the proof of Corollary 1 provided a deterministic rectangle ËœR with

OPTIMAL AND FAST SCAN STATISTICS
17
F( ËœR) â‰¥(1 âˆ’Î»N)F(R) â‰¥2
3 log N/N and PN( ËœR âŠ‚Râ€² âŠ‚R) â†’1. Chebyshevâ€™s
inequality gives for c = 1/24:
PN

FN( ËœR)
F( ËœR)
âˆ’1
 > cÎ»N

â‰¤
F( ËœR)
N(F( ËœR))2c2Î»2
N
â‰¤
3
2(log N)Î»2
Nc2
â‰¤
27
4c2 min(bN log 2,log N)
by (8)
and the same bound holds for |FN(R)
F (R) âˆ’1|. But ËœR âŠ‚Râ€² âŠ‚R, FN( ËœR)/F( ËœR) â‰¥
1 âˆ’Î»N/24 and FN(R)/F(R) â‰¤1 + Î»N/24 imply
FN(Râ€²)
F(R)
ï£±
ï£´
ï£´
ï£´
ï£²
ï£´
ï£´
ï£´
ï£³
â‰¥FN( ËœR)
F( ËœR)
F( ËœR)
F(R) â‰¥

1 âˆ’Î»N
24

(1 âˆ’Î»N) â‰¥1 âˆ’25
24Î»N,
â‰¤FN(R)
F(R) â‰¤1 + Î»N
24 .
(7)
This entails the ï¬rst event in AN due to the inequality y(1âˆ’y)
x(1âˆ’x) â‰¥min( y
x,2âˆ’y
x)
for x,y âˆˆ(0,1/2).
For the other events in AN, note that given the locations X = (X1,...,XN),
Ë†p and Ë†q are independent with Ë†p âˆ¼bin(#Râ€²,p)/#Râ€², while Ë†q is an average
of N âˆ’#Râ€² independent Bernoulli random variables that have probability
of success equal to p for the #R âˆ’#Râ€² locations in R \ Râ€² and q for the
N âˆ’#R locations in Rc. Hence,
EN(Ë†q|X) = (#R âˆ’#Râ€²)p + (N âˆ’#R)q
N âˆ’#Râ€²
= q + FN(R) âˆ’FN(Râ€²)
1 âˆ’FN(Râ€²)
(p âˆ’q)
â‰¤q + 13/(12 Â· 8)Î»N
1 âˆ’37/(8 Â· 36)(p âˆ’q)
on (7) as Î»N â‰¤2
3,F(R) â‰¤1
8
< q + 3
19Î»N(p âˆ’q).
Thus, on (7)
PN
 Ë†p âˆ’Ë†q
p âˆ’q < 1 âˆ’Î»N
6
X

â‰¤PN

Ë†p âˆ’Ë†q âˆ’EN(Ë†p âˆ’Ë†q) <
 3
19 âˆ’1
6

Î»N(p âˆ’q)
X


18
G. WALTHER
â‰¤p(1 âˆ’q)/#Râ€² + p(1 âˆ’q)/(N âˆ’#Râ€²)
114âˆ’2Î»2
N(p âˆ’q)2
as q < p
=
1142
Î»2
NND(F(R),p,q) Â·
F(R)(1 âˆ’F(R))
FN(Râ€²)(1 âˆ’FN(Râ€²))
â‰¤
1142
Î»2
N(2 + bN(log(1/F(R)))âˆ’1/2)log(1/F(R)) Â·

1 âˆ’25
24Î»N
âˆ’1
â‰¤9 Â· 1142 Â· 2
bN
â†’0
by (9) and as Î»N â‰¤2
3.
The other two events in AN obtain similarly. Above, we used the following
properties of Î»N:
Î»2
N log N â‰¥2
9 min(bN log 2,log N),
(8)
Î»2
N

2 +
bN
p
log(1/F(R))

log
1
F(R) â‰¥2bN/9.
(9)
For proof of those inequalities, note that Î»2
N log2
1
F (R) â‰¥4
9 Â· bN log2(1/F (R))
bN+log2(1/F (R)) â‰¥
2
9 min(bN,log2
1
F (R)). Now (8) follows since F(R) â‰¥2log N/N implies log N/
log2
1
F (R) â‰¥log 2. Applying the above inequality to the LHS of (9), yields
the lower bound 2
9 min(bN2/log2(e),bN
q
log
1
F (R)) â‰¥2
9bN.
For the proof of (B), note that by the construction of Rapp,N in the
proof of Corollary 1, the rectangle Râ€² belongs to Rapp,N(2âˆ’â„“,â„“âˆ’1/2) where
â„“:= âŒŠlog2
1
F (R)âŒ‹. Hence, result 2 of Theorem 1 yields #Rapp,N(2âˆ’â„“,â„“âˆ’1/2) â‰¤
K
1
F (R)(log2
1
F (R))3 for some universal constant K. Thus,
P0

max
ËœRâˆˆRapp,N(2âˆ’â„“,â„“âˆ’1/2)
T( ËœR) â‰¥log
1
F(R) + 6log log
1
F(R) + Î³

â‰¤
K
F(R)

log2
1
F(R)
3
(10)
Ã—
max
ËœRâˆˆRapp,N(2âˆ’â„“,â„“âˆ’1/2)
P0

T( ËœR) â‰¥log
1
F(R) + 6log log
1
F(R) + Î³

,
where P0 denotes the null distribution, i.e., the permutation distribution,
conditional on the N locations and on p = total no. of 1
,s
N
. Thus, under P0,
the number of 1â€™s in a rectangle ËœR follows the hypergeometric distribution
where # ËœR labels are drawn out of N, of which pN are 1â€™s. Theorem 4 implies
P0

T( ËœR) â‰¥log
1
F(R) + 6log log
1
F(R) + Î³


OPTIMAL AND FAST SCAN STATISTICS
19
â‰¤2C

log
1
F(R) + 6log log
1
F(R) + Î³ + 2

Ã— F(R)

log
1
F(R)
âˆ’6
exp(âˆ’Î³)
â‰¤6Î±
KÏ€2 F(R)

log2
1
F(R)
âˆ’5
for Î³ large enough, depending on Î± only. Thus, (10) is not larger than 6Î±
Ï€2 Ã—
(log2
1
F (R))âˆ’2 â‰¤
6Î±
Ï€2â„“2 by the deï¬nition of â„“. Now, (B) follows once it is shown
that
P0

max
ËœRâˆˆRapp,N(2âˆ’â„“,â„“âˆ’1/2)
T( ËœR) â‰¥qâ„“
 ËœÎ±
â„“2

â‰¥6Î±
Ï€2â„“2 .
(11)
But by the deï¬nition of qâ„“(Â·), the probability in (3) is not larger than
P
â„“â‰¥1 ËœÎ±/â„“2 â‰¤ËœÎ±Ï€2/6, hence ËœÎ± â‰¥6Î±/Ï€2 by the deï¬nition of ËœÎ±. Now (11) fol-
lows from the deï¬nition of qâ„“(Â·).
â–¡
Proof of Theorem 2(b1, b2).
The idea of the proof of (b1) is classical,
see, e.g., Lepski and Tsybakov (2000). Given the prescribed sequence of
values {F N(RN)} and {ÎµN}, partition R2 into rectangles ËœRN
1 , ËœRN
2 ,..., such
that F N( ËœRN
j ) = F N(RN) for j = 1,...,âŒŠ
1
F N(RN)âŒ‹. This is feasible since F N
is continuous, e.g., by partitioning one axis into intervals. Set q = qN := 1/2
and p = pN := q +
q
1
2NF (R)(1âˆ’F (R)) log
1
F (R)(1âˆ’ÎµN/8), where for notational
simplicity, we write F(R) for F N(RN) and also drop the index N from
F N,pN,qN, ËœRN
j in the following. Without loss of generality, we may assume
ÎµN < 8. Thus, q < p and for j = 1,...,âŒŠ
1
F (R)âŒ‹:
D(F( ËœRj),p,q)
= log(1/F(R))(1 âˆ’Îµn/8)2
Np
â‰¥log(1/F(R))(1 âˆ’Îµn/4)/N
1/2 + (log(1/F(R)))âˆ’1/2
by (12)
â‰¥(2 âˆ’ÎµN/2)

1 âˆ’2

log
1
F(R)
âˆ’1/2log(1/F(R))
N
â‰¥(2 âˆ’ÎµN)log(1/F(R))
N

20
G. WALTHER
for N large enough, as ÎµN
q
log
1
F (R) â†’âˆ. We used
NF(R)(1 âˆ’F(R)) â‰¥(1 + o(1)) log2 N â‰¥(1 + o(1)) log2
1
F(R),
(12)
which is a consequence of the assumptions on F(R) stated in the theorem.
Denote by Xi the location and by Yi the Bernoulli random variable that
gives the label of the ith observation, i = 1,...,N. Denote by PN,0 the model
where the Xi are i.i.d. F and all the Yi have probability of success q, while
we deï¬ne PN,j to be the model where instead Yi has probability of success
p if Xi âˆˆËœRj and q otherwise, i = 1,...,N. Thus, PN,0 belongs to H0. Deï¬ne
the likelihood ratio LN,j(X,Y) := QN
i=1 fN,j(Xi,Yi), where
fN,j(Xi,Yi) :=
ï£±
ï£²
ï£³
p
q1(Yi = 1) + 1 âˆ’p
1 âˆ’q 1(Yi = 0),
if Xi âˆˆËœRj,
1,
otherwise,
j = 1,...,âŒŠ
1
F (R)âŒ‹. Hence, if Ï†N(X,Y) is any level Î± test that depends on
the locations X and the labels Y, then by conditioning on X one veriï¬es
EN,jÏ†N(X,Y) = EN,0Ï†N(X,Y)LN,j(X,Y). We will show that
EN,0


1
F(R)
 âŒŠ1/F (R)âŒ‹
X
j=1
LN,j(X,Y) âˆ’1
 â†’0.
(13)
Then
min
j=1,...,âŒŠ1/F (R)âŒ‹EN,jÏ†N(X,Y) âˆ’Î±
â‰¤

1
F(R)
 âŒŠ1/F (R)âŒ‹
X
j=1
EN,jÏ†N(X,Y) âˆ’Î±
= EN,0
 
1
F(R)
 âŒŠ1/F (R)âŒ‹
X
j=1
LN,j(X,Y) âˆ’1
!
Ï†N(X,Y) + o(1)
â‰¤EN,0


1
F(R)
 âŒŠ1/F (R)âŒ‹
X
j=1
LN,j(X,Y) âˆ’1
 + o(1)
= o(1)
and the claim of (b1) follows. [Note that one can even allow Ï†N(X,Y) to
depend on F N(RN). Further, the continuity assumption on F N was only
used to allow for the above partition of R2 into rectangles and can be relaxed
accordingly.] To prove (13), note that conditional on X the LN,j(X,Y) are

OPTIMAL AND FAST SCAN STATISTICS
21
independent since LN,j(X,Y) is a function of only those Yi for which Xi âˆˆ
ËœRj. Further, one veriï¬es EN,0LN,j(X,Y) = EN,0(LN,j(X,Y)|X) = 1. Thus,
we can proceed similarly as in the proof of Lemma 7.4 in DÂ¨umbgen and
Walther (2008) and obtain (13) once we show that
max

p
q âˆ’1
,

1 âˆ’p
1 âˆ’q âˆ’1


â‰¤C

log

1
F(R)
âˆ’1/2
(14)
for some constant C,
s
log

1
F(R)

1 âˆ’NEN,0(fN,1 âˆ’1)2
2logâŒŠ1/F(R)âŒ‹

â†’âˆ.
(15)
Now |p
q âˆ’1| = 2
q
1
2NF (R)(1âˆ’F (R)) log
1
F (R)(1âˆ’ÎµN/8) â‰¤2(logâŒŠ
1
F (R)âŒ‹)âˆ’1/2 by
(12) and the same bound obtains for |1âˆ’p
1âˆ’q âˆ’1|, proving (14). Finally,
EN,0(fN,1(X1,Y1) âˆ’1)2
= EN,0
p
q1(Yi = 1) + 1 âˆ’p
1 âˆ’q 1(Yi = 0) âˆ’1
2X1 âˆˆËœR1

Ã— PN,0(X1 âˆˆËœR1)
=
2log(1/F(R))
NF(R)(1 âˆ’F(R))(1 âˆ’ÎµN/8)2F(R).
Together with
log x
logâŒŠxâŒ‹â‰¤1 +
1
logâŒŠxâŒ‹for x â‰¥2 one sees that the expression in
(15) is not smaller than
s
log

1
F(R)

1 âˆ’(1 + 1/logâŒŠ1/F(R)âŒ‹)(1 âˆ’ÎµN/8)
1 âˆ’F(R)

â‰¥
s
log

1
F(R)

ÎµN/8 âˆ’
1
logâŒŠ1/F(R)âŒ‹âˆ’F(R)

.
(1 âˆ’F(R))
â†’âˆ
as F(R) â†’0 and ÎµN
q
log
1
F (R) â†’âˆ, completing the proof of (b1). The
bounds on F N(RN) and bN given in the statement of (b2) guarantee that
there exists pN and qN such that D(F N(RN),pN,qN) â‰¥bN/N, e.g., take
pN = 1, qN = 0. Then the claim obtains with a contiguity argument similar
as in the proof of Theorem 4.1(c) in DÂ¨umbgen and Walther (2008).
â–¡

22
G. WALTHER
Proof of Theorem 3.
Part (a) continues to hold as intervals on the
axes are special cases of axis-parallel rectangles. Parts (b1) and (b2) continue
to hold as their proofs do not depend on the dimensionality of the space. In
fact, the proof of (b1) already uses a univariate partitioning of one axis into
âŒŠ
1
F N(RN)âŒ‹intervals, and the rest of the proof of (b1) goes through verbatim.
â–¡
Proof of Theorem 4.
Let k,x â‰¥0 be integers with x+k â‰¤min(n,R).
Then
P(X = x + k)
P(X = x)
=
k
Y
i=1
(R âˆ’x âˆ’k + i)(n âˆ’x âˆ’k + i)
(x + i)(N âˆ’R âˆ’n + x + i)
is nonincreasing in x. Hence, for x â‰¥âŒˆmâŒ‰
P(X â‰¥x) =
P(X = x)
P(X = âŒˆmâŒ‰)
X
kâ‰¥0
P(X = âŒˆmâŒ‰)P(X = x + k)
P(X = x)
â‰¤
P(X = x)
P(X = âŒˆmâŒ‰)
X
kâ‰¥0
P(X = âŒˆmâŒ‰)P(X = âŒˆmâŒ‰+ k)
P(X = âŒˆmâŒ‰)
â‰¤
P(X = x)
P(X = âŒˆmâŒ‰).
The connection between this hypergeometric probability and the log like-
lihood ratio statistic L obtains by applying Stirlingâ€™s formula and collecting
terms: the upper and lower bounds for Stirlingâ€™s formula in Feller [(1968),
page 54] yield
log
P(X = x)
P(X = âŒˆmâŒ‰)
â‰¤âˆ’L(x) + L(âŒˆmâŒ‰)
+ 1
2 log âŒˆmâŒ‰(R âˆ’âŒˆmâŒ‰)(n âˆ’âŒˆmâŒ‰)(N âˆ’R âˆ’n + âŒˆmâŒ‰)
x(R âˆ’x)(n âˆ’x)(N âˆ’R âˆ’n + x)
+
1
12p(1 âˆ’p)
 1
n +
1
N âˆ’n

.
Set L(n, Ë†p) := n(Ë†plog Ë†p
p + (1 âˆ’Ë†p)log 1âˆ’Ë†p
1âˆ’p). Using log b
a â‰¤bâˆ’a
a
for 0 < a < b
and Taylorâ€™s theorem, respectively, one ï¬nds
n(Ë†p âˆ’p)2
p(1 âˆ’p) â‰¥L(n, Ë†p) â‰¥
ï£±
ï£´
ï£´
ï£²
ï£´
ï£´
ï£³
n(Ë†p âˆ’p)2
2(1 âˆ’p),
if Ë†p â‰¥p,
n(Ë†p âˆ’p)2
2p
,
if Ë†p â‰¤p,

OPTIMAL AND FAST SCAN STATISTICS
23
which implies L(âŒˆmâŒ‰) â‰¤
1
p(1âˆ’p)( 1
n +
1
Nâˆ’n) and for Ë†p âˆˆ(p, nâˆ’1
n ]:
L(n, Ë†p) + 1 â‰¥
1 âˆ’p
4(1 âˆ’Ë†p)
(16)
[distinguish the cases Ë†p â‹š(3 + p)/4], as well as for Ë†q âˆˆ[
1
Nâˆ’n,p):
L(N âˆ’n, Ë†q) + 1 â‰¥p
4Ë†q .
(17)
First, consider the case âŒˆmâŒ‰â‰¤x < min(n,R). Then (17) gives
âŒˆmâŒ‰(R âˆ’âŒˆmâŒ‰)
x(R âˆ’x)
â‰¤R âˆ’m
R âˆ’x = p
Ë†q â‰¤4L(N âˆ’n, Ë†q) + 4
and analogously (16) implies
(n âˆ’âŒˆmâŒ‰)(N âˆ’R âˆ’n + âŒˆmâŒ‰)
(n âˆ’x)(N âˆ’R âˆ’n + x)
â‰¤4L(n, Ë†p) + 4.
The ï¬rst inequality of the theorem now follows from the arithmeticâ€“
geometric means inequality.
The case x = min(n,R) is treated similarly. For example, if x = n < R
then log P(X â‰¥x) = log P(X = x) â‰¤âˆ’L(X) + 1
2 log(R(Nâˆ’n)
(Râˆ’n)N ) + 1
12( 1
n +
1
Nâˆ’n)
and (17) gives
R(Nâˆ’n)
(Râˆ’n)N = p
Ë†q â‰¤4L(N âˆ’n, Ë†q) + 4, which yields the claimed
inequality.
The second inequality of the theorem obtains analogously. The third in-
equality follows from the ï¬rst two because the function x â†’L(x) is strictly
decreasing for x < m and strictly increasing for x > m.
â–¡
Proof of Proposition 1.
Sorting the data according to the X-coordinate
requires O(N log N) steps. Note that the test statistic inside the n-loop
can be computed in constant time: the rectangle Xjk Ã— [Y(a),Y(b)] contains
round(b) âˆ’round(a) + 1 locations, and the number of their labels that equal
1 is just the cumulative sum vector of the labels evaluated at index round(b)
minus the vector evaluated at round(a âˆ’1). These two quantities are suf-
ï¬cient to calculate the test statistic once the overall number of locations
N and the overall number of 1â€™s is known. Thus, there are O(1/Îµ) steps
for the n-loop, and hence O(2i/Îµ2) for the m-loop. Inside the k-loop the
number of steps required to extract the Njk locations (Xp,Yp), to sort the
corresponding Y -values, and to compute the cumulative sum is dominated
by the sorting, which requires O(Njk log Njk) steps. (Note that presorting
the locations according to their X-coordinate allows an eï¬ƒcient extraction.)
Thus, the total number of steps in the algorithm is bounded by
O(N log N) +
log2(N/(2log N))
X
â„“=3
â„“
X
i=0
â„“1/22â„“2âˆ’i
X
j=0
j+â„“1/2
X
k=j+1
(O(Njk log Njk) + O(2iâ„“)).

24
G. WALTHER
By deï¬nition, Njk â‰¤(kâˆ’j)Îµs2iN â‰¤2iâˆ’â„“N. Thus, the above sum is not larger
than
O(N log N)
+ C
log2(N/(2log N))
X
â„“=3
â„“
X
i=0
â„“2â„“2âˆ’i(2iâˆ’â„“N log N + 2iâ„“)
â‰¤CN log N
log2(N/(2log N))
X
â„“=3
â„“2
â‰¤CN(log N)4,
where the constant C may change from line to line.
â–¡
Acknowledgments.
I would like to thank one referee for the Derbeko, El-
Yaniv and Meir (2004) reference and another referee for the Rohde (2009)
reference.
REFERENCES
Alm, S. E. (1997). On the distribution of the scan statistic of a two-dimensional Poisson
process. Adv. in Appl. Probab. 29 1â€“16. MR1432927
Anderson, N. H. and Titterington, D. M. (1997). Some methods for investigating
spatial clustering, with epidemiological applications. J. Roy. Statist. Soc. Ser. A 160
87â€“105.
Chen, J. and Glaz, J. (1996). Two-dimensional discrete scan statistics. Statist. Probab.
Lett. 31 59â€“68. MR1421770
Derbeko, P., El-Yaniv, R. and Meir, R. (2004). Explicit learning curves for transduc-
tion and applications to clustering and compression algorithms. J. Artiï¬cial Intelligence
Res. 22 117â€“142. MR2129466
DÂ¨umbgen, L. and Spokoiny, V. G. (2001). Multiscale testing of qualitative hypotheses.
Ann. Statist. 29 124â€“152. MR1833961
DÂ¨umbgen, L. and Walther, G. (2008). Multiscale inference about a density. Ann. Statist.
36 1758â€“1785. MR2435455
Feller, W. (1968). An Introduction to Probability Theory and Its Applications, 3rd ed.
I. Wiley, New York. MR0228020
Glaz, J. and Balakrishnan, N. (eds.) (1999). Scan Statistics and Applications.
BirkhÂ¨auser, Boston. MR1697781
Glaz, J., Naus, J. and Wallenstein, S. (2001). Scan Statistics. Springer, New York.
MR1869112
Hoeffding, W. (1963). Probability inequalities for sums of bounded random. J. Amer.
Statist. Assoc. 58 13â€“30.
Kulldorff, M. (1997). A spatial scan statistic. Comm. Statist. Theory Methods 26 1481â€“
1496. MR1456844
Kulldorff, M. (1999). Spatial scan statistics: Models, calculations, and applications.
In: Scan Statistics and Applications (J. Glaz and N. Balakrishnan, eds.). BirkhÂ¨auser,
Boston. MR1697758

OPTIMAL AND FAST SCAN STATISTICS
25
Lepski, O. V. and Tsybakov, A. B. (2000). Asymptotically exact nonparametric hy-
pothesis testing in sup-norm and at a ï¬xed point. Probab. Theory Related Fields 117
17â€“48. MR1759508
Loader, C. R. (1991). Large-deviation approximations to the distribution of scan statis-
tics. Adv. in Appl. Probab. 23 751â€“771. MR1133726
Naiman, D. Q. and Priebe, C. E. (2001). Computing scan statistic p-values using impor-
tance sampling, with applications to genetics and medical image analysis. J. Comput.
Graph. Statist. 26 296â€“328. MR1939702
Naus, J. (1965). Clustering of random points in two dimensions. Biometrika 52 263â€“267.
MR0211433
Neill, D. and Moore, A. (2004a). A fast multi-resolution method for detection of sig-
niï¬cant spatial disease clusters. Adv. Neural Inf. Process. Syst. 10 651â€“658.
Neill, D. and Moore, A. (2004b). Rapid detection of signiï¬cant spatial disease clusters.
In Proc. Tenth ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining 256â€“265. ACM, New York.
Roederer, M. and Hardy, R. R. (2001). Frequency diï¬€erence gating: A multivariate
method for identifying subsets that diï¬€er between samples. Cytometry 45 56â€“64.
Roederer, M., Moore, W., Treister, A., Hardy, R. R. and Herzenberg, L. (2001).
Probability binning comparison: A metric for quantitating multivariate distribution
diï¬€erences. Cytometry 45 47â€“55.
Rohde, A. (2009). Sharp-optimal adjustment for multiple testing in the multivariate two-
sample problem. Manuscript. Preprint No. 1356, Weirstrass Institute, Berlin, Germany.
Rufibach, K. and Walther, G. (2009). The block criterion for multiscale inference about
a density, with applications to other multiscale problems. J. Comput. Graph. Statist.
In press.
Department of Statistics
Stanford University
390 Serra Mall
Stanford, California 94305
USA
E-mail: gwalther@stanford.edu
