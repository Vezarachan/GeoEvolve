arXiv:0911.3769v1  [math.ST]  19 Nov 2009
The Annals of Statistics
2009, Vol. 37, No. 6B, 3985â€“4010
DOI: 10.1214/09-AOS701
c
âƒInstitute of Mathematical Statistics, 2009
DETECTION OF SPATIAL CLUSTERING WITH AVERAGE
LIKELIHOOD RATIO TEST STATISTICS
By Hock Peng Chan1
National University of Singapore
Generalized likelihood ratio (GLR) test statistics are often used in
the detection of spatial clustering in case-control and case-population
datasets to check for a signiï¬cantly large proportion of cases within
some scanning window. The traditional spatial scan test statistic
takes the supremum GLR value over all windows, whereas the average
likelihood ratio (ALR) test statistic that we consider here takes an
average of the GLR values. Numerical experiments in the literature
and in this paper show that the ALR test statistic has more power
compared to the spatial scan statistic. We develop in this paper ac-
curate tail probability approximations of the ALR test statistic that
allow us to by-pass computer intensive Monte Carlo procedures to
estimate p-values. In models that adjust for covariates, these Monte
Carlo evaluations require an initial ï¬tting of parameters that can
result in very biased p-value estimates.
1. Introduction.
The detection of local clustering in spatial point pro-
cesses is of interest in epidemiological studies, forestry, geological studies,
neural imaging and astronomy. There are a number of excellent texts and
review papers on this, including [5, 13, 29]. A classical application that will
be used here as an illustrative example is the identiï¬cation of potential
sources of environmental pollution that have contributed to higher rates of
disease cases for residents living in their vicinity.
Let T = {ti :1 â‰¤i â‰¤I}, with ti âˆˆRd denoting the location of the ith case.
We are interested in the presence of an unusually large number of cases near
an unspeciï¬ed location v = (v1,...,vd) inside a bounded domain D. If T
is generated from a process with known and constant intensity under the
null hypothesis, we can test for the presence of clusters by computing the
Received November 2008; revised March 2009.
1Supported by grants from the National University of Singapore.
AMS 2000 subject classiï¬cations. Primary 60F10, 62G10; secondary 60G55.
Key words and phrases. Average likelihood ratio, change of measure, generalized like-
lihood ratio, logistic model, moderate deviations, scan statistic, spatial clustering.
This is an electronic reprint of the original article published by the
Institute of Mathematical Statistics in The Annals of Statistics,
2009, Vol. 37, No. 6B, 3985â€“4010. This reprint diï¬€ers from the original in
pagination and typographic detail.
1

2
H. P. CHAN
maximal number of cases in the cubic windows Qd
k=1[vk âˆ’w
2 ,vk + w
2 ], over all
v âˆˆD for a ï¬xed window size w > 0. The question of whether this number
is signiï¬cantly large or may have occurred with reasonable chance under the
null hypothesis was addressed in [21, 23], via asymptotic p-value calculations
and p-value bounds. Extensions to weighted counting using kernel functions
were also achieved in [27].
Rather than assuming that the underlying intensity is known and con-
stant, we can assume instead that a control dataset U = {uj :1 â‰¤j â‰¤J âˆ’I}
is available for estimation of the possibly nonconstant intensity function.
There has been considerable work done on the use of kernel functions to
smooth U to provide an intensity estimate, and the signiï¬cance of a clus-
ter of cases is calculated by assuming that the estimated intensity is the
true intensity (see, e.g., [1, 7, 9] and references therein). An alternative
approach, as considered in [6, 26], is to merge T and U into a combined
dataset X := {(ti,1):1 â‰¤i â‰¤I} âˆª{(uj,0):1 â‰¤j â‰¤J âˆ’I} and rewrite it as
{(xi,Xi):1 â‰¤i â‰¤J}. The SaTScan software developed by Kulldorï¬€and In-
formation Management Services Inc. [16] (see also [17]) considers merged
datasets, with generalized likelihood ratio (GLR) test statistics used to pro-
vide a score for each window, and the spatial scan statistic, the supremum
GLR score used to determine signiï¬cance. Instead of cubic windows, spher-
ical windows C(v,w) := {t: Pd
k=1(vk âˆ’tk)2 â‰¤w2} are considered.
In Section 2, we consider the average likelihood ratio (ALR) test statistic,
which uses an average rather than the supremum GLR score as the sum-
mary test statistic. Numerical studies in the literature and in this paper show
that the ALR test statistic has more power compared to the spatial scan
test statistic. We provide moderate deviation tail probability approxima-
tions in Section 2.1 for the ALR test statistic and illustrate their extensions
to logistic regression models for covariate adjustments in Section 3. These
p-value approximations allow us to avoid the use of computationally ex-
pensive Monte Carlo methods and are especially important when covariate
adjustments are required, as the Monte Carlo method currently in use re-
quires an initial ï¬tting of parameters that can result in very biased p-value
estimates (see Examples 1 and 2 in Section 3.1). In Section 4, we perform
comparison studies on real and simulated datasets. A discussion is provided
in Section 5 followed by derivations of the asymptotic formulae in Section
6. The appendices contain technical details and proofs.
2. The spatial scan and ALR test statistics.
Throughout this paper, we
shall use âˆ¥Â· âˆ¥to denote the L2 norm of a vector. For any set A, vector t and
real number b, we shall let t+bA = {t+ba:a âˆˆA}. We shall use I to denote
the indicator function and # to denote the number of elements in a ï¬nite
set. For constants an and bn, the notation an âˆ¼bn shall mean an/bn â†’1,
while for random variables Y1,Y2,... and Z1,Z2,..., the notation Yn âˆ¼Zn

DETECTION OF SPATIAL CLUSTERING
3
shall mean Yn/Zn
pâ†’1. We shall use Z to denote the set of integers and 0 to
denote the zero vector. We shall also adopt the conventions 0log 0 = 0 and
00 = 1.
Let X = {(xi,Xi):1 â‰¤i â‰¤J}, where xi denotes the location of the ith
subject, while Xi = 1 if the subject is a case and Xi = 0 otherwise. Condi-
tioned on x := (x1,...,xJ), the random vector X := (X1,...,XJ) consists
of independent Bernoulli random variables. Under the null hypothesis H0 of
no clustering, there exists p0 âˆˆ(0,1) such that
P0{Xi = 1} = p0
for all 1 â‰¤i â‰¤J.
(2.1)
Let B be a subset of Rd and H(1)
B
the hypothesis that there exists p1 > p2
such that
P{Xi = 1|xi âˆˆB} = p1,
(2.2)
P{Xi = 1|xi /âˆˆB} = p2
for all 1 â‰¤i â‰¤J.
Let bp0 = I/J be the maximum likelihood estimate (MLE) of p0 under H0
and let
Ï†(p) = plog
 p
bp0

+ (1 âˆ’p)log
 1 âˆ’p
1 âˆ’bp0

.
(2.3)
Let mB = PJ
i=1 I{xiâˆˆB,Xi=1} be the number of cases and nB = PJ
i=1 I{xiâˆˆB}
the number of subjects in B. The log GLR score for testing H0 against H(1)
B
is
S(1)(B) := log
n
sup
1â‰¥p1>p2â‰¥0
[pmB
1
(1 âˆ’p1)nBâˆ’mBpIâˆ’mB
2
(1 âˆ’p2)Jâˆ’Iâˆ’(nBâˆ’mB)]
o
âˆ’log[bpI
0(1 âˆ’bp0)Jâˆ’I]
=

nBÏ†
mB
nB

+ (J âˆ’nB)Ï†
I âˆ’mB
J âˆ’nB

I{mB/nB>bp0}.
To detect both over- and under-clustering, we compare H0 against the
two-sided alternative hypothesis H(2)
B
that (2.2) holds for some p1 Ì¸= p2. The
log GLR score is then
S(2)(B) := nBÏ†
mB
nB

+ (J âˆ’nB)Ï†
I âˆ’mB
J âˆ’nB

.
(2.4)
Let B be a ï¬nite class of measurable subsets of Rd, possibly dependent on x
but not on X. The spatial scan statistic for testing H0 vs. S
BâˆˆB H(k)
B , k = 1
or 2, is
M(k)
B
:= sup
BâˆˆB
S(k)(B).
(2.5)

4
H. P. CHAN
The spatial scan statistic has the drawback of not making full use of in-
formation provided by secondary clusters to conclude the presence of local
clustering. For example, if there are scores S(k)(B1) > S(k)(B2) for nonover-
lapping windows B1 and B2 both slightly smaller than the critical value, the
information provided by S(k)(B2) is not utilized in the decision not to reject
H0. Gangnon and Clayton [12] introduced the weighted ALR test statistic
X
BâˆˆB
wBeS(2)(B)
with wB > 0 for all B âˆˆB
and
X
BâˆˆB
wB = 1.
Unlike the spatial scan statistic, signiï¬cance for the weighted ALR test
statistic can be concluded based on many moderately large scores. The nu-
merical studies in [12] suggest that the weighted ALR is more powerful than
the spatial scan statistic in the detection of local clusters. Siegmund [28] also
reports a closely related test statistic that is slightly more powerful, com-
pared to the scan test statistic in a numerical study on the genome scan. This
is in contrast to global clustering test statistics like (#B)âˆ’1 P
BâˆˆB S(2)(B),
which are expected to have lower power compared to the spatial scan statistic
when only a few local clusters are present (see [18] for supporting numerical
results). We consider in this paper p-value approximations for the (log) ALR
test statistic
U(k)
B
:= 2log

(#B)âˆ’1 X
BâˆˆB
eS(k)(B)

.
(2.6)
An extension of these approximations to weighted ALR test statistics is
given in the appendices of [4].
2.1. Moderate deviation tail probabilities.
In this paper, we provide tail
approximations of the ALR test statistics under the following assumptions.
(A1) The domain D is a compact subset of Rd and satisï¬es
#{t âˆˆ(ÎµZ)d :t + [0,Îµ]d âŠ‚D} âˆ¼#{t âˆˆ(ÎµZ)d :(t + [0,Îµ]d) âˆ©D Ì¸= âˆ…} âˆ¼|D|/Îµd
as Îµ â†’0.
(A2) The locations x1,...,xJ are independent and identically distributed
(i.i.d.) random vectors generated from Î», a continuous and positive density
on D.
(A3) The class of scanning sets B is a sub-class of C := {v + wA:v âˆˆ
D,w0 â‰¤w â‰¤w1}, where A is a convex, open and bounded subset of Rd,
with 0 âˆˆA and 0 < w0 â‰¤w1 < (|D|/|A|)1/d.
In Theorem 1 below and Theorem 2 in Section 3, B(= Bc) may vary with
the critical value c and constraints are placed only on the growth of J (for
Theorem 1) and #B with respect to c. The class of C of candidate scanning
sets is, however, ï¬xed for all c > 0. The proofs of the theorems use change

DETECTION OF SPATIAL CLUSTERING
5
of measure arguments and linearization techniques developed by Lai and
Siegmund [19, 20] and Woodroofe [32, 33], to analyze GLR test statistics in
sequential analysis and are given in Section 5. A motivation of the proofs
is also given by a simpler Theorem 3 and its proof in Appendix A. Let Ï‡2
1
denote a chi-square random variable with one degree of freedom.
Theorem 1.
Assume (A1)â€“(A3) and let (2.1) hold for some 0 < p0 < 1.
Let log(#B) = o(c1/3) and assume that c âˆ¼ÎºJs for some Îº > 0 and 0 < s < 1.
Then as c â†’âˆ,
P0{U(k)
B
â‰¥c|x} âˆ¼kP{Ï‡2
1 â‰¥c}/2
for k = 1,2.
(2.7)
The assumptions (A2), (A3) and the relation c âˆ¼ÎºJs in the statement
of Theorem 1 are needed to ensure that the number of subjects in each
B âˆˆB approaches inï¬nity fast enough for a chi-square tail probability ap-
proximation of S(k)(B) to hold. This leads to the chi-square tail probability
approximation of U(k)
B . The uniform approximation when conditioning on x
in (2.7) ensures that we do not reject H0 unevenly with respect to the con-
ï¬guration of the locations. However, it is also important for us to check the
actual type I error probability when x is not conditioned on (see Example
2 in Section 3.1).
3. Logistic modeling.
To see why (2.7) extends to more complicated
models, it is useful to view it as resulting from two diï¬€erent asymptotics.
Let Î»B =
R
B Î»(t)dt, where Î» is the density in (A2). Let Ï‰ be Gaussian white
noise with Ï‰(B) âˆ¼N(0,Î»B) for B âŠ‚D and Ï‰(A),Ï‰(B) independent when-
ever A and B are disjoint. Let ZB = Î»âˆ’1/2
B
(1 âˆ’Î»B)âˆ’1/2[Ï‰(B) âˆ’Î»BÏ‰(D)].
The ï¬rst asymptotic is a weak convergence of S(2)(B) to Z2
B/2 uniformly
over B âˆˆC, and this holds largely because infBâˆˆC(nB/c) â†’âˆwhen c âˆ¼ÎºJs
for 0 < s < 1. The second asymptotic is like (2.7) [see (3.2) below], but with
ALRs U(2)
B
and U(1)
B
replaced by
U(2)
Z
:= 2log

(#B)âˆ’1 X
BâˆˆB
eZ2
B/2

and
(3.1)
U(1)
Z
:= 2log

(#B)âˆ’1 X
BâˆˆB
eZ2
B+/2

,
respectively, where ZB+ = max{ZB,0}.
Theorem 2.
Assume (A1), (A3) and let log(#B) = o(c1/3). Then as
c â†’âˆ,
P{U(k)
Z
â‰¥c} âˆ¼kP{Ï‡2
1 â‰¥c}/2
for k = 1,2.
(3.2)

6
H. P. CHAN
Since |U(2)
Z
âˆ’U(2)
B | â‰¤2supBâˆˆB |S(2)(B) âˆ’Z2
B/2| and |U(1)
Z
âˆ’U(1)
B | â‰¤2 Ã—
supBâˆˆB |S(1)(B)âˆ’Z2
B+/2|, the combination of the two asymptotics described
above provides us with chi-square tail approximations for U(k)
B .
Consider more generally datasets containing additional information like
the age, sex, diet and smoking habits of the subjects. These covariates
may inï¬‚uence the outcome and, hence, we may have to correct for spa-
tial imbalances of these covariates when testing for spatial clustering. Let
ui = (ui1,...,uir)â€² be the covariate vector of the ith subject, with ui1 = 1
denoting the intercept term, and let pi = P{Xi = 1|xi,ui}. Consider the
logistic model
pi = (1 + eâˆ’Î²â€²uiâˆ’Î¸i)âˆ’1,
(3.3)
where Î² = (Î²1,...,Î²r)â€² is a nuisance parameter vector. Under the null hy-
pothesis H0 of no clustering, Î¸i = 0 for all i, while under the one-sided
alternative hypothesis H(1)
B , Î¸i = Î¸I{xiâˆˆB} for some Î¸ > 0. Under the two-
sided alternative hypothesis H(2)
B , Î¸i = Î¸I{xiâˆˆB} for some Î¸ Ì¸= 0. Let bÎ² be
the MLE of Î² under H0 and ( bÎ²(k)
B , bÎ¸(k)
B ) the MLE of (Î²,Î¸) under H0 âˆªH(k)
B .
Deï¬ne
bpi = (1 + eâˆ’Ë†Î²â€²ui)âˆ’1,
bp(k)
iB = (1 + eâˆ’Ë†Î²(k)â€²
B
uiâˆ’Ë†Î¸(k)
B I(xiâˆˆB))âˆ’1,
(3.4)
Y (k)
iB = Xi log
 bp(k)
iB
bpi

+ (1 âˆ’Xi)log
1 âˆ’bp(k)
iB
1 âˆ’bpi

.
Then the ALR test statistics are
U(k)
B
= 2log

(#B)âˆ’1 X
BâˆˆB
eS(k)(B)

where S(k)(B) =
J
X
i=1
Y (k)
iB .
(3.5)
The scores S(k)(B) are asymptotically chi-square, even when Î² is inï¬nite
dimensional (see [2, 22] and references therein). The eï¬ƒcient score expan-
sions of the log proï¬le likelihoods that are used for deriving these chi-square
approximations can also be used to provide the covariance structure of the
limiting multivariate normal of âˆšnbÎ¸(2)
B
over B âˆˆB, and this structure de-
pends on the nuisance parameter under H0 (see Appendix B for more de-
tails). However, the chi-square approximations of U(k)
B
in the moderate de-
viations domain do not depend on the covariance structure of the limiting
multivariate normal. In other words,
P(0,Î²){U(k)
B
â‰¥c} âˆ¼kP{Ï‡2
1 â‰¥c}/2
for k = 1,2
(3.6)
uniformly over compact sets of Î² (see Appendix B).

DETECTION OF SPATIAL CLUSTERING
7
This is desirable because the p-value is in principle computed from the
worst-case scenario under H0. In this respect, the ALR test statistic shares
the same uniform asymptotics as the GLR test statistic for a composite null
hypothesis versus single composite alternative hypothesis with a dimension
diï¬€erence of one, diï¬€ering only in that for the GLR test statistic, the ap-
proximation occurs in the central limit domain as well. The spatial scan test
statistic does not have such uniform asymptotics over nuisance parameters.
Hence Theorems 1 and 2 are not just devices for p-value approximations,
but also theoretical results that provide understanding of the asymptotic
properties of the ALR test statistic. To reduce computational time for large
datasets, we can avoid searching for a new ( bÎ²(k)
B , bÎ¸(k)
B ) for each B âˆˆB by re-
placing S(2)(B) by a ï¬rst-order quadratic approximation (see either (4)â€“(6)
of [22] or (B.1) in Appendix B).
3.1. Monte Carlo evaluation of conditional p-values.
Under (2.1), the
conditional p-value P0{M(k)
B
â‰¥c|I,x} does not depend on p0 and can be
evaluated by a permutation test. Permutation tests are nonparametric tests
that compute p-values from permutations of the observations X1,...,XJ,
which are often assumed to be i.i.d. under the null hypothesis. In principle,
the p-value is the fraction of permutations with values of test statistics at
least as large as the original test statistic, though in practice the number
of permutations is usually too large for direct computations, and Monte
Carlo methods are used instead to sample a random subset of permuta-
tions for p-value estimation (for more details, see [10, 11]). In the SaTScan
software, users are prompted to select L = 99, 999 or 9999 random per-
mutations. For each 1 â‰¤â„“â‰¤L, compute M(k)
B,â„“from {(xi,Xiâ„“):1 â‰¤i â‰¤J},
where (X1â„“,...,XJâ„“) is a random permutation of (X1,...,XJ). Then the es-
timated conditional p-value is (1 + PL
â„“=1 I{M(k)
B,â„“â‰¥c})/(1 + L). The extension
of the method to estimate P0{U(k)
B
â‰¥c|I,x} is straightforward.
When covariates are present, the SaTScan software uses the following
Monte Carlo procedure, as advocated in [15]. Assume that there are nj
subjects at location vj for 1 â‰¤j â‰¤q, with nj large. Fit (3.3) under the null
hypothesis H0, that there are no spatial eï¬€ects, that is with Î¸i = 0 for all i.
The ï¬tted value bpi, given in (3.4), is the estimated risk of the ith subject. At
each vj, estimate the total risk by Î·j = P
i: xi=vj bpi. Let mj = P
i: xi=vj Xi,
mB = P
vjâˆˆB mj and Î·B = P
vjâˆˆB Î·j. Assume that under H0, m1,...,mq
are independent Poisson random variables with respective means Î·1,...,Î·q.
Then conditioned on m1 + Â· + mq = I, the adjusted spatial scan statistic for
testing H0 against S
BâˆˆB H(2)
B
is
f
M(2)
B
:= sup
BâˆˆB
eS(2)(B)
where

8
H. P. CHAN
Table 1
Comparison of the type I error probabilities and detection powers of e
M (2)
B
and U (2)
B
at
signiï¬cance levels Î± = 0.05 and Î± = 0.01 with 1000 independent copies of X
Î± = 0.05
Î± = 0.01
Î¸
MC: f
M
(2)
B
ALR: U (2)
B
MC: f
M
(2)
B
ALR: U (2)
B
0
0.026
0.048
0.004
0.008
0.2
0.088
0.158
0.021
0.054
0.4
0.367
0.499
0.137
0.261
0.6
0.740
0.849
0.506
0.676
(3.7)
eS(2)(B) := mB log
mB
Î·B

+ (I âˆ’mB)log
I âˆ’mB
I âˆ’Î·B

.
To simulate the Monte Carlo p-value for each 1 â‰¤â„“â‰¤L, where L is the
required number of simulation runs, generate (m1â„“,...,mqâ„“) from a multi-
nomial distribution with I trials and success probabilities (Î·1/I,...,Î·q/I),
then compute f
M(2)
B,â„“using (3.7). The estimated p-value is then
 
1 +
L
X
â„“=1
I{ Ëœ
M(2)
B,â„“â‰¥Ëœ
M(2)
B }
!
(1 + L).
Example 1.
Let D be a union of disjoint sets B1, B2 and B3, each
containing 1000 subjects. Generate dummy covariates ui âˆ¼N(0,1) if xi âˆˆ
B2 âˆªB3 and ui âˆ¼N(1,1) if xi âˆˆB1, then keep them ï¬xed for the remaining
part of this exercise. Let B = {B1,B2,B3} and let
P{Xi = 1|xi,ui} = (1 + eâˆ’Î²1âˆ’Î¸I{xiâˆˆB1})âˆ’1.
(3.8)
In our comparison study, we generate X = (X1,...,X3000) from (3.8) with
Î²1 = âˆ’3, Î¸ â‰¥0 and compute the Monte Carlo p-values of f
M(2)
B
with L = 999
simulation runs and also the p-values of U(2)
B
using chi-square tail probability
approximations. The scores S(2)(B) are computed from (3.4)â€“(3.5) with ui,
the only covariate of the ith subject. For each Î¸ â‰¥0, the above procedure is
repeated 1000 times, each time with a diï¬€erent copy of X. The estimated
type I error probabilities and power are summarized in Table 1. We see that
the Monte Carlo risk adjustment method provides very conservative p-values
(see [3] for alternative strategies to deal with this drawback).
Example 2.
We choose a slightly diï¬€erent design here to check the type
I error probability and power P{U(2)
B
â‰¥c} (without conditioning on x). In

DETECTION OF SPATIAL CLUSTERING
9
Table 2
Comparison of the type I error probabilities and detection powers of e
M (2)
B
and U (2)
B
at
signiï¬cance levels Î± = 0.05 and Î± = 0.01 with 1000 simulation runs
Î± = 0.05
Î± = 0.01
p1
MC: f
M
(2)
B
ALR: U (2)
B
MC: f
M
(2)
B
ALR: U (2)
B
0.05
0.026
0.053
0
0.007
0.2
0.054
0.119
0.008
0.026
0.4
0.243
0.395
0.111
0.209
0.6
0.514
0.682
0.327
0.484
each simulation run, twenty locations v1,...,v20 are generated uniformly
and randomly on the unit square [0,1]2. Let C0 be a circle of radius 0.3,
centered at (0.5,0.5). Fifty subjects are located at each vi, each of them
generated as a case with probability p0 = 0.05 if vi /âˆˆC0, and generated
as a case with probability p1 â‰¥p0 if vi âˆˆC0. Each subject at vi is given a
dummy covariate distributed as N(0,1) if vi /âˆˆC0 and distributed as N(1,1)
if vi âˆˆC0. For each 1 â‰¤i â‰¤20, let 0 = ri,1 < Â·Â·Â· < ri,20 be the ordered values
of âˆ¥vj âˆ’viâˆ¥for j = 1,...,20. We consider the class of scanning sets
B = {C(vi,ri,j):1 â‰¤i â‰¤20,1 â‰¤j â‰¤10},
where C(v,r) is a circle of radius r, centered at v. One thousand simulation
runs are used to estimate each type I error probability and power of the
adjusted scan statistic f
M(2)
B
(using L = 999 permutations) and the ALR test
statistic U(2)
B
(using the chi-square distribution) (see Table 2). We see that
the Monte Carlo method has low type I error probability and corresponding
loss of power when compared against the ALR test statistic.
4. Numerical examples.
We analyze a case-control dataset in Section
4.1, a case-population dataset in Section 4.2 and various simulated datasets
in Section 4.3.
4.1. Laryngeal cancer dataset.
This dataset consists of: (i) the locations
of 58 cases of laryngeal cancer occurring in two districts in Lancashire for
the period 1974â€“1985; and (ii) the locations of 978 control cases of lung
cancer for the same period and districts in the domain D = [34500,36500] Ã—
[41100,43100] (see [8] for more background). A key feature is a cluster of four
laryngeal cancer cases (see the bottom of the left plot of Figure 1) located
near an industrial waste incinerator, which is considered a potential source
of the cluster of laryngeal cancer cases. We want to test for the presence
of local clusters without biasing ourselves a priori with information on the

10
H. P. CHAN
possible sources of the laryngeal cancer cases. As the location co-ordinates
in the datasets are rounded to the nearest tens, we consider the covering
sets
Bw := {C(v,w):v âˆˆD âˆ©(10Z + 5)2,nC(v,w) â‰¥2}
with radii w = 40, 50, 60 and 70. Hence each circle in Bw contains at least
two subjects and has a center v with co-ordinates ending with 5 and lies
inside D. Express M(1)
Bw and U(1)
Bw more simply as M(1)
w
and U(1)
w , respectively.
In Table 3, we tabulate Monte Carlo conditional p-values of both M(1)
w
and U(1)
w
using the permutation method described in Section 3.1. We observe
that for both the spatial scan and ALR test statistics, p-values below 0.02
are obtained when w = 40. This is in contrast to p-values of 0.08 to 0.8
obtained using kernel-based methods (see [1]). The choice of window size
w aï¬€ects the p-value substantially when using M(1)
w , and this is also true
when using kernel-based methods. In contrast, the inï¬‚uence of window size
on the p-values of U(1)
w
is much smaller. In this sense, the ALR test statistic
is more robust against misspeciï¬cation of cluster shape and size, that is,
when H(1)
B
is true for some B /âˆˆB, because under such a situation there will
often be many windows having moderately large scores, and this will aid the
rejection of H0. The construction of Table 3 requires a substantial amount
of computation as there are more than 5000 scanning sets in each Bw.
A numerical power study (see Table 4) indicates that the ALR and spatial
scan test statistics do not dominate each other when there is only one source
of spatial clustering. In this study, we ï¬x the locations x and the total
number of cases I = 58. Consider a circle with radius 40 and let n be the
number of points in it. Let p be the probability that a point in the circle is
Fig. 1.
Scatter plots of the 58 laryngeal cancer cases (left) and the 978 lung cancer cases
(right).

DETECTION OF SPATIAL CLUSTERING
11
Table 3
Numerical values of the test statistics and Monte Carlo conditional p-value
estimates Â± standard error for Bw with 2000 simulation runs for each spatial scan
statistic p-value and 10,000 runs for each ALR test statistic p-value
Spatial scan statistic M (1)
w
ALR test statistic U (1)
w
w
Value
MC p-val. (cond.)
Value
MC p-val. (cond.)
40
9.21
0.016 Â± 0.003
5.29
0.0104 Â± 0.0010
50
7.95
0.090 Â± 0.006
4.47
0.0137 Â± 0.0012
60
7.95
0.078 Â± 0.006
4.07
0.0200 Â± 0.0014
70
7.95
0.079 Â± 0.006
3.89
0.0213 Â± 0.0014
simulated as a case and ep the probability that a point outside the circle is
simulated as a case. Thus the relative ratio (RR) is p/ep. The numbers p and
ep are determined from the constraint
np + (1036 âˆ’n)ep = 58.
In the â„“th simulation run, 1 â‰¤â„“â‰¤1000, we generate {Xiâ„“:1 â‰¤i â‰¤1036} with
success probabilities p (for xi inside circle) or ep (for xi outside circle), and
repeat until a total of 58 cases is observed before proceeding to compute
U(1)
40,â„“and M(1)
40,â„“. The estimated power is the proportion of runs in which the
critical value is equaled or exceeded.
We also try out scanning sets with diï¬€erent radii at diï¬€erent centers as
suggested by a referee, and obtain similar p-values for the spatial scan and
ALR test statistics (see Table 5). The classes of scanning sets considered
here are of the form
Bj = {C(xi,rij):1 â‰¤i â‰¤1036}
for j = 5,6,7,
where 0 = ri1 â‰¤ri2 â‰¤Â·Â·Â· are the ordered values of âˆ¥xi âˆ’xkâˆ¥for 1 â‰¤k â‰¤1036.
It is interesting to note that even though the largest window score of 9.21,
Table 4
Powers of U (1)
40 and M (1)
40 based on 1000 simulation runs for each entry, with estimated
1% critical values cM,0.01 = 9.49 and cU,0.01 = 5.29. In each row, the n points lying in a
circle centered at (v1,v2) with radius w = 40 are simulated as cases with probability RR
times larger than points lying outside the circle
v1
v2
n
RR
Power of U (1)
40
Power of M (1)
40
35565
41395
6
12
0.49 Â± 0.02
0.36 Â± 0.02
35195
42745
9
11
0.54 Â± 0.02
0.54 Â± 0.02
35515
42255
12
10
0.52 Â± 0.02
0.68 Â± 0.01
35255
42155
15
8
0.45 Â± 0.02
0.47 Â± 0.02
35595
42745
18
7
0.47 Â± 0.02
0.42 Â± 0.02

12
H. P. CHAN
Table 5
Numerical values of the test statistics and Monte Carlo conditional p-value
estimates Â± standard error with 2000 simulation runs in each entry for scanning sets with
diï¬€erent radii
Spatial scan statistic M (1)
ALR test statistic U (1)
j
Value
MC p-val. (cond.)
Value
MC p-val. (cond.)
5
9.21
0.016 Â± 0.003
5.38
0.012 Â± 0.002
6
7.95
0.043 Â± 0.005
5.76
0.006 Â± 0.002
7
7.04
0.079 Â± 0.006
3.70
0.027 Â± 0.004
obtained from a scanning set containing four cases and one control, is missed
when j = 6, the ALR score actually increased.
4.2. New York leukaemia dataset.
We use here an updated version of the
dataset presented in [31], which tracks leukaemia occurrences in 281 census
tracts in New York state. Let vj denote the centroid of the jth census tract
and let mj and nj be the number of leukaemia cases and population size,
respectively, at vj. Let mB = P
vjâˆˆB mj, nB = P
vjâˆˆB nj, I = P281
j=1 mj and
J = P281
j=1 nj. Gangnon and Clayton [12] considered the ALR test statistic
U(2)
B
with
B = {C(vi,rij):0 â‰¤rij â‰¤20,1 â‰¤i â‰¤281,1 â‰¤j â‰¤281},
where rij = âˆ¥vi âˆ’vjâˆ¥. We plot in Figure 2 simulated values of U(2)
B
under
the null hypothesis (2.1) with p0 = 5Ã—10âˆ’4( .= I/J), against quantiles of the
chi-square distribution with one degree of freedom and also against quantiles
of a distribution function G satisfying
G(x) = 1 âˆ’
2eâˆ’x
Ï€x
1/2
(4.1)
for x â‰¥x0 with x0 .= 0.42 satisfying 2eâˆ’x0/(Ï€x0) = 1.
The upper tail probabilities of G are expressions often seen in large devia-
tions saddlepoint approximations.
Since P{Ï‡2
1 â‰¥x} â‰¤1 âˆ’G(x) for all x â‰¥0 and P{Ï‡2
1 â‰¥x} âˆ¼1 âˆ’G(x) as
x â†’âˆ, p-value estimates of U(k)
B
obtained by comparing against G instead of
the chi-square distribution are slightly more conservative for small p-values.
From the qq-plots, we see that G provides a good ï¬t over a wider range
of values but for small p-values, which are of primary interest, the p-value
estimates are comparable.

DETECTION OF SPATIAL CLUSTERING
13
Fig. 2.
Qq-plots of simulated values of U (2)
B
against the chi-square distribution with one
degree of freedom (left) and the distribution G (right).
4.3. Simulated datasets.
The example in Section 4.2 is typical for ap-
plication of cluster detection methodology. More than 20,000 circles were
created from comparisons among the 281 census tracts. For larger number
of census tracts, the number of circles can easily run into the millions. The
computational burden is quite serious if say L = 999 or 9999 Monte Carlo
simulation runs are used to evaluate p-values. Small p-values are of statis-
tical interest, yet it is precisely for these cases that Monte Carlo methods
are less reliable. If a person is looking at multiple regions, end-points or
time-points, nominal p-values much smaller than 0.01 may be required for
signiï¬cance to be declared. For probability 0.05, L = 999 runs will give us
relative error of about 0.15, while the corresponding relative error is about
0.3 for a probability 0.01. In Example 3 below, we compare the analytical
chi-square and G tail approximations [see (4.1)] of the ALR for two diï¬€erent
arrangements of scanning sets. The key advantage of the analytical approx-
imations lies in composite null situations for which the usual Monte Carlo
methods may not work well (see Section 3).
Example 3.
Let v1,...,vn be generated uniformly from the unit square
[0,1]2, and let
B1 = {C(vi,rij):0 â‰¤rij â‰¤w1,1 â‰¤i â‰¤n,1 â‰¤j â‰¤n}
(4.2)
where rij = âˆ¥vi âˆ’vjâˆ¥.
We shall abuse notation here and denote #{i:vi âˆˆC} more simply by #C.
For each 1 â‰¤â„“â‰¤L with L large, generate independent standard normal
random variables Y1â„“,...,Ynâ„“and deï¬ne
ZCâ„“=
P
viâˆˆC(Yiâ„“âˆ’Â¯Yâ„“)
p
(#C)[1 âˆ’(#C)/n]
where Â¯Yâ„“= nâˆ’1
n
X
i=1
Yiâ„“.

14
H. P. CHAN
Let U(2)
Z,â„“= 2log((#B)âˆ’1 P
CâˆˆB eZ2
Câ„“/2). In Figure 3, we plot ordered values of
U(2)
Z,â„“against quantiles of both the chi-square and G distributions for w1 = 0.2
and various values of n. Approximately six hours of computer time were
taken up to generate the plot for n = 1000. The plots show the G distribution
to be more suitable for estimating moderately small p-values. For smaller
p-values, the chi-square and G distributions give similar approximations.
Similar plots are obtained when experimenting with w1 = 0.3.
5. Discussion.
The New York leukaemia dataset in Section 4.2 is a typi-
cal dataset in which the locations are concentrated on a number of geograph-
ical centers instead of spreading over a domain D, and strictly speaking, the
positive density assumption [see (A2)] does not hold. However, the purpose
of the assumption is to ensure that the number of subjects in each scanning
set goes to inï¬nity at a fast enough rate, and as this is satisï¬ed in this sit-
uation, the chi-square approximation is still valid. Similarly, the restriction
that the class of sets in (A3) has to be all of the same shape can be relaxed in
these types of datasets. The relaxation allows us to deal with the detection
of irregular shaped clusters considered in, for example, [25, 30]. The condi-
tion that B be dependent only on the locations xi and not on the responses
Xi is, however, necessary for the chi-square approximation to hold.
The qq-plots in Figures 2 and 3 show that the p-value approximations
are inaccurate for small thresholds. This is consistent with the conditions of
Theorem 1, which says that moderate or larger values of the threshold are
needed for the p-value approximations to be accurate. This is not a problem
because when large p-values are encountered, it suï¬ƒces to state that the
p-value is larger than a speciï¬ed signiï¬cance level. For very large thresholds,
the diï¬€erence of the approximated and empirical quantiles is due to the
inaccuracy of the Monte Carlo method. Though Theorem 1 is stated only in
terms of approximating unconditional p-values, a rough calculation shows
that the chi-square approximation on the four conditional p-values of the
ALR test statistics in Table 3 has the accuracy of about 4000 simulation
runs. The chi-square approximations are also within one standard error of
the Monte Carlo p-values in Table 5.
The overï¬tting of nuisance parameters when using Monte Carlo meth-
ods for p-value estimation of the spatial scan statistic was mentioned by
Neill, Moore and Cooper [24], and this phenomenon likely contributed to
the conservative p-values seen in Examples 1 and 2. The authors provided
convincing arguments for why quick detection of disease outbreaks is impor-
tant and cited the need to perform time-consuming Monte Carlo or boot-
strap replications to provide reliable p-values of the spatial scan statistic
as one justiï¬cation for developing alternative methodologies. In this paper,
we stick to the method of detection cluster via GLR values (but taking

DETECTION OF SPATIAL CLUSTERING
15
Fig. 3.
Qq-plots of U (2)
Z
against the chi-square and G distributions for B1 with n = 10,
100, 1000 locations and maximum radius w1 = 0.2.

16
H. P. CHAN
averages instead of maximums) popularized by the SaTScan software and
address its drawbacks by providing accurate and easy to compute p-value
approximations. These tail probability approximations can be applied even
when nuisance parameters are in the model, and they enhance the attrac-
tiveness of the GLR method by easing its use.
6. Proofs.
6.1. Proof of Theorem 1.
Let 0 < Î³0 < p0 < Î³1 < 1. Then by large devia-
tions,
P0{bp0 â‰¤Î³0} + P0{bp0 â‰¥Î³1} = o(câˆ’1/2eâˆ’c/2),
(6.1)
while by the law of large numbers, we may assume that
liminf
Jâ†’âˆinf
BâˆˆB(nB/J) > 0.
(6.2)
For each JÎ³0 â‰¤I â‰¤JÎ³1, let (pB, epB) be the roots (p, ep) of
nBp + (J âˆ’nB)ep = I,
(6.3)
nBÏ†(p) + (J âˆ’nB)Ï†(ep) = c/2
with p > bp0.
Under (6.2), (pB, epB) exists and are unique for all B âˆˆB when J is large.
For given values of bp0 and x, let QB be a probability measure under which
X1,...,XJ are independent Bernoulli random variables satisfying
QB{Xi = 1|xi âˆˆB} = pB,
QB{Xi = 1|xi /âˆˆB} = epB.
(6.4)
Let Î¸(p) = log(p/bp0) âˆ’log[(1 âˆ’p)/(1 âˆ’bp0)]. Then by (2.3) and (6.3),
â„“(B) := log
dQB
dPË†p0
(X)

=
X
xiâˆˆB

Î¸(pB)Xi + log
1 âˆ’pB
1 âˆ’bp0

(6.5)
+
X
xi /âˆˆB

Î¸(epB)Xi + log
1 âˆ’epB
1 âˆ’bp0

= c/2 + Î¸(pB)
X
xiâˆˆB
(Xi âˆ’pB) + Î¸(epB)
X
xi /âˆˆB
(Xi âˆ’epB).
The following supporting lemmas hold uniformly over Î³0 â‰¤bp0 â‰¤Î³1 under
the conditions of Theorem 1. The proof of Lemma 1 is given in Appendix
C, while the proof of Lemma 2(a) uses arguments in the proof of (6.11)
which is also given in Appendix C. The proof of Lemma 2(b) is relatively
straightforward and thus omitted.

DETECTION OF SPATIAL CLUSTERING
17
Lemma 1.
Assume (6.2).
(a) S(1)(B) â‰¥â„“(B) for all B âˆˆB.
(b) There exists Î·c â†’0 as c â†’âˆsuch that
|S(1)(B) âˆ’â„“(B)| â‰¤Î·c
whenever |S(1)(B) âˆ’c/2| â‰¤c1/3.
Lemma 2.
(a) Let
VB = log
 X
CâˆˆB
(dQC/dQB)(X)

= log
 X
CâˆˆB
eâ„“(C)âˆ’â„“(B)

.
Then whenever c â‰¤U(1)
B
â‰¤c + c1/3,
â„“(B) + VB âˆ’log(#B) = log

(#B)âˆ’1 X
CâˆˆB
eâ„“(C)

= U(1)
B /2 + o(1).
(b) QB{PJ
i=1 Xi = I|x} âˆ¼PË†p0{PJ
i=1 Xi = I|x} uniformly over B âˆˆB.
We shall now provide the key arguments in the proof of Theorem 1.
Let Bmax maximizes P
xiâˆˆB(Xi âˆ’pB) over B âˆˆB, with an arbitrary or-
dering imposed on B to break ties. Under QB, conditioned on c â‰¤U(1)
B
â‰¤
c + c1/3 and Bmax = B, â„“(B) has an asymptotic density (2Ï€c)âˆ’1/2 on the
interval (câˆ’c1/3
2
, c+c1/3
2
), and is asymptotically independent of both VB and
I{Bmax=B}. The random variable VB summarizes information on the local
ï¬‚uctuations of the GLR values for sets near B when Bmax = B, and its value
is determined chieï¬‚y by a small set of Xi with xi near the boundary of B,
because under QB, eâ„“(C)âˆ’â„“(B) is small for C, far from B. Similarly, I{Bmax=B}
is determined by the values of Xi with xi located near the boundary of B.
The test statistic â„“(B), on the other hand, is asymptotically N(c/2,c) un-
der QB and is asymptotically independent of any small set of Xi. We thus
obtain formally, for Î³0 â‰¤bp0 â‰¤Î³1,
PË†p0{U(1)
B
â‰¥c|I,x}
=
X
BâˆˆB
PË†p0{U(1)
B
â‰¥c,Bmax = B|I,x}
âˆ¼
X
BâˆˆB
EQ(B)(eâˆ’â„“(B)I{U(1)
B â‰¥c,Bmax=B}|I,x)
âˆ¼
X
BâˆˆB
EQ(B)(E[eâˆ’â„“(B)I{â„“(B)â‰¥c/2âˆ’VB+log(#B),Bmax=B}|VB]|I,x)
(6.6)
âˆ¼
X
BâˆˆB
EQ(B)

I{Bmax=B}
Z âˆ
c/2âˆ’VB+log(#B)
(2Ï€c)âˆ’1/2eâˆ’y dy
I,x


18
H. P. CHAN
= (2Ï€c)âˆ’1/2eâˆ’c/2(#B)âˆ’1 X
BâˆˆB
EQ(B)(eVBI{Bmax=B}|I,x)
= (2Ï€c)âˆ’1/2eâˆ’c/2(#B)âˆ’1 X
BâˆˆB
X
CâˆˆB
QC{Bmax = B|I,x}.
We then switch the summation signs in the last line of (6.6) to show that
PË†p0{U(1)
B
â‰¥c|I,x} âˆ¼(2Ï€c)âˆ’1/2eâˆ’c/2, and (2.7) for k = 1 then follow from (6.1).
By (6.5), PË†p0(A|x) = EQ(B)(eâˆ’â„“(B)IA|x), where A = {U(1)
B
â‰¥c,Bmax = B,
PJ
i=1 Xi = I}, and the relation between the ï¬rst and second lines of (6.6)
follows from Lemma 2(b). For additional details on (6.6), see Appendix C.
Since S(2)(B) = S(2)(D\B), and bp0 lies between mB/nB and mD\B/nD\B,
it follows that
eS(2)(B) = eS(1)(B) + eS(1)(D\B) âˆ’1.
(6.7)
Let eB = {D \B :B âˆˆB} and U(1)
BâˆªËœB = 2log([2(#B)]âˆ’1 P
BâˆˆBâˆªËœB eS(1)(B)). Then
by the arguments leading to (2.7) for k = 1,
P{U(1)
BâˆªËœB â‰¥c âˆ’2log 2} âˆ¼[2Ï€(c âˆ’2log 2)]âˆ’1/2eâˆ’(câˆ’2log 2)/2
(6.8)
âˆ¼[2/(Ï€c)]1/2eâˆ’c/2.
By (6.7), U(2)
B
= 2log((#B)âˆ’1 P
BâˆˆB eS(2)(B)) = U(1)
BâˆªËœB + 2log 2 + o(1) when
U(2)
B
â‰¥c, and hence (2.7) for k = 2 follows from (6.8).
6.2. Proof of Theorem 2.
Let Î£ = (ÏBC)B,CâˆˆB be the covariance matrix
of Z = (ZB)BâˆˆB, a multivariate normal with EZB = 0 and Var(ZB) = 1 for
all B âˆˆB under probability measure P. Hence ÏBC = Î»Bâˆ©C âˆ’Î»BÎ»C. Fix c >
0,
B âˆˆB
and
let
QB
be
a
probability
measure
under
which
Ï‰(A) âˆ¼N(Î»âˆ’1/2
B
(1 âˆ’Î»B)1/2Î»Ac1/2,Î»A) for A âŠ‚B and Ï‰(A) âˆ¼N(âˆ’Î»1/2
B (1 âˆ’
Î»B)âˆ’1/2Î»Ac1/2,Î»A) for A âŠ‚D \ B, with Ï‰(A),Ï‰(C) independent when A
and C are disjoint sets. Under QB, Z is multivariate normal with covari-
ance matrix Î£ and EQ(B)ZC = c1/2ÏBC for all C âˆˆB. Moreover,
â„“(B) := log
dQB
dP (Z)

= c1/2ZB âˆ’c/2.
(6.9)
We next use a linearization argument to justify the replacement of Z2
B+/2
in the expression of U(1)
Z
by â„“(B). By convexity, Z2
B+/2 â‰¥â„“(B) for all B âˆˆB,
with equality when ZB+ = c1/2. By a Taylor expansion,
sup
ZB : |Z2
B+âˆ’c|â‰¤2c1/3 |â„“(B) âˆ’Z2
B+/2| = O(câˆ’1/3)
as c â†’âˆ.
(6.10)

DETECTION OF SPATIAL CLUSTERING
19
Let VB = log{P
CâˆˆB(dQC/dQB)(Z)} = log(P
CâˆˆB eâ„“(C)âˆ’â„“(B)). Then by
(6.10), there exists Î¶c = O(câˆ’1/3) such that whenever c â‰¤U(1)
Z
â‰¤c + c1/3,
U(1)
Z /2 âˆ’Î¶c â‰¤â„“(B) + VB âˆ’log(#B)

= log

(#B)âˆ’1 X
CâˆˆB
eâ„“(C)

(6.11)
â‰¤U(1)
Z /2,
(see Appendix C). We then apply the steps in (6.6), without the conditioning
on I and x, to obtain the tail probabilities of U(1)
Z . For extensions to the tail
probabilities of U(2)
Z , apply the arguments in the last paragraph of Section
6.1.
APPENDIX A: THEOREM 3 AND ITS PROOF
Theorem 3.
Let S1c,...,Snc be random variables and assume that there
exists a constant K > 0 and random variables Ykj such that P{Ykj = 0} = 0
for all k Ì¸= j and as c â†’âˆ,
P{Skc â‰¥c + y} âˆ¼Kcâˆ’1/2eâˆ’câˆ’y,
(A.1)
while conditioned on Skc â‰¥c + y,
(Skc âˆ’S1c,...,Skc âˆ’Snc) â‡’(Yk1,...,Ykn)
(A.2)
for all 1 â‰¤k â‰¤n and y âˆˆR. Then
nâˆ’1
n
X
k=1
E
" n
X
j=1
eâˆ’Ykj
!
I{Ykjâ‰¥0 for all j}
#
= 1
(A.3)
and
P
(
nâˆ’1
n
X
j=1
eSjc â‰¥ec
)
âˆ¼Kcâˆ’1/2eâˆ’c
as c â†’âˆ.
(A.4)
Proof.
Let Mc = sup1â‰¤kâ‰¤n Skc. For a given Îµ > 0, let 0 = y1 < Â·Â·Â· < ym
be such that P{Ykj = yr} = 0 for all 1 â‰¤r â‰¤m, k Ì¸= j and sup1â‰¤râ‰¤m(eâˆ’yr âˆ’
eâˆ’yr+1) â‰¤Îµ, where ym+1 = âˆ. Then by (A.1) and (A.2), for all k Ì¸= j,
P{Sjc â‰¥c,Mc = Skc}
=
m
X
r=1
P{Sjc â‰¥c,Mc = Skc,yr â‰¤Skc âˆ’Sjc < yr+1}
â‰¤
m
X
r=1
P{Skc â‰¥c + yr,Mc = Skc,yr â‰¤Skc âˆ’Sjc < yr+1}
(A.5)

20
H. P. CHAN
âˆ¼Kcâˆ’1/2eâˆ’c
m
X
r=1
eâˆ’yrP{Yki â‰¥0 for all i,yr â‰¤Ykj < yr+1}
â‰¤Kcâˆ’1/2eâˆ’cE[(eâˆ’Ykj + Îµ)I{Ykiâ‰¥0 for all i}].
Similarly,
P{Sjc â‰¥c,Mc = Skc}
â‰¥(K + o(1))câˆ’1/2eâˆ’c
m
X
r=1
eâˆ’yr+1P{Yki â‰¥0 for all i,yr â‰¤Ykj < yr+1}
(A.6)
â‰¥(K + o(1))câˆ’1/2eâˆ’cE[(eâˆ’Ykj âˆ’Îµ)I{Ykiâ‰¥0 for all i}].
By selecting Îµ arbitrarily small, it follows from (A.5) and (A.6) that
P{Sjc â‰¥c,Mc = Skc} âˆ¼Kcâˆ’1/2eâˆ’cE(eâˆ’YkjI{Ykiâ‰¥0 for all i}).
(A.7)
The asymptotic relation (A.7) also holds for k = j by applying (A.1) and
(A.2) for y = 0, noting that Yjj is a zero-valued random variable for all
j. We then add up (A.7) over 1 â‰¤j â‰¤n, 1 â‰¤k â‰¤n and compare against
the asymptotic relation Pn
j=1 P{Sjc â‰¥c} âˆ¼Kncâˆ’1/2eâˆ’c, which follows from
(A.1), to obtain (A.3).
Since log(nâˆ’1 Pn
j=1 eSjcâˆ’Skc) â‰¤0 when Mc = Skc, by (A.1) and (A.2),
P
(
nâˆ’1
n
X
j=1
eSjc â‰¥ec,Mc = Skc
)
= P
(
Skc â‰¥c âˆ’log
 
nâˆ’1
n
X
j=1
eSjcâˆ’Skc
!
,Mc = Skc
)
(A.8)
âˆ¼Kcâˆ’1/2eâˆ’cE
" 
nâˆ’1
n
X
j=1
eâˆ’Ykj
!
I{Ykjâ‰¥0 for all j}
#
and (A.4) follows from (A.3) by adding (A.8) over 1 â‰¤k â‰¤n. To show the
last relation in (A.8), we use a discretization argument described earlier.
Given any Îµ > 0, select 0 = y1 < Â·Â·Â· < ym such that P{âˆ’log(nâˆ’1 Pn
j=1 eâˆ’Ykj)
= yr,Ykj â‰¥0 for all j} = 0 for all 1 â‰¤r â‰¤m, 1 â‰¤k â‰¤n and sup1â‰¤râ‰¤m(eâˆ’yr âˆ’
eâˆ’yr+1) â‰¤Îµ, with ym+1 = âˆ. We then express asymptotic upper and lower
bounds of
P
(
Skc â‰¥c âˆ’log
 
nâˆ’1
n
X
j=1
eSjcâˆ’Skc
!
,
Mc = Skc,yr â‰¤âˆ’log
 
nâˆ’1
n
X
j=1
eSjcâˆ’Skc
!
< yr+1
)
,

DETECTION OF SPATIAL CLUSTERING
21
in terms of Îµ and expectations involving Yki before letting Îµ â†’0. The details
are omitted.
â–¡
APPENDIX B: ASYMPTOTIC EXPANSIONS OF THE LOG
LIKELIHOOD FUNCTION
For a ï¬xed B âˆˆB, let zi(Î¸,Î²) = Î²â€²ui + Î¸I{xiâˆˆB} and let
â„“i(Î¸,Î²) = âˆ’Xi log(1 + eâˆ’zi(Î¸,Î²)) âˆ’(1 âˆ’Xi)log(1 + ezi(Î¸,Î²))
be the log likelihood function corresponding to the ith subject. Since âˆ‚â„“i/âˆ‚zi =
Xi âˆ’pi, where pi = (1 + eâˆ’zi)âˆ’1, evaluated at some parameter Î² and Î¸ = 0,
it follows that
dâ„“i
dÎ¸ = (Xi âˆ’pi)I{xiâˆˆB}
and
dâ„“i
dÎ²k
= uik(Xi âˆ’pi)
for 1 â‰¤k â‰¤r.
To motivate the form of the limiting distribution of S(k)(B), we use a
weighted Gramâ€“Schmidt orthogonalization procedure, rather than matrix
notation, to describe the ï¬rst-order quadratic term in a Taylor expansion
of S(2)(B). Let wi = pi(1 âˆ’pi) and let weighted dot product (a Â· b)w =
PJ
i=1 aibiwi and norm âˆ¥aâˆ¥w = (a Â· a)w. Deï¬ne recursively eu1 = u1 and euk =
uk âˆ’Pkâˆ’1
s=1 akseus, where aks = (uk Â· eus)w/âˆ¥eusâˆ¥2
w, for 2 â‰¤k â‰¤r. Then (euk Â·
eus)w = 0 for all k Ì¸= s. Let euk = (eu1k,..., euJk). Under suï¬ƒcient regularity
conditions, S(2)
B
is equal to, up to a o(1) term,
(2v2
B)âˆ’1
( J
X
i=1
 
I{xiâˆˆB} âˆ’
r
X
k=1
(Î±B Â· euk)weuik
âˆ¥eukâˆ¥2w
!
(Xi âˆ’pi)
)2
,
(B.1)
where Î±B = (I{x1âˆˆB},...,I{xJâˆˆB})â€²
and v2
B =
J
X
i=1
wi
 
I{xiâˆˆB} âˆ’
r
X
k=1
(Î±B Â· euk)weuik
âˆ¥eukâˆ¥2w
!2
.
We will next consider a characterization of the limiting distributions of
S(2)(B), B âˆˆB. Let Î·(t) = Î»(t)E(w1|x1 = t)/E(w1) and gk(t) = E(u1kw1|x1 =
t)/E(w1|x1 = t) for 1 â‰¤k â‰¤r and assume that they are positive and con-
tinuous on D. Let eg1 = g1(= 1) and deï¬ne recursively for k â‰¥2,
egk(t) = gk(t) âˆ’
kâˆ’1
X
s=1
Âµksegs(t),
where
Âµks = bâˆ’1
s
Z
D
gk(t)egs(t)Î·(t)dt
and
bs =
Z
D
eg2
s(t)Î·(t)dt.

22
H. P. CHAN
Then
R
D egk(t)egs(t)Î·(t)dt = 0 for all k Ì¸= s. Let Ï‰ be Gaussian white noise
on D with Ï‰(B) âˆ¼N(0,Î·B), where Î·B =
R
B Î·(t)dt. Then S(2)(B) converges
weakly to Z2
B/2, where
ZB = vâˆ’1
B
"
Ï‰(B) âˆ’
r
X
k=1

bâˆ’1
k
Z
B
egk(t)Î·(t)dt

Ï‰k(D)
#
with Ï‰k(D) =
R
D egk(t)Ï‰(dt) and vB is a normalizing constant to ensure
Var(ZB) = 1.
The justiï¬cation behind (3.6) requires arguments used in the proof of
Theorem 2. For a given c > 0 and B âˆˆB, let QB be a probability mea-
sure such that Ï‰(A) âˆ¼N(
R
A Âµ(t)Î·(t)dt,Î·A), where Âµ(t) = c1/2vâˆ’1
B [I{tâˆˆB} âˆ’
Pr
k=1 Î³kBegk(t)] and Î³kB = bâˆ’1
k
R
B egk(t)Î·(t)dt. Moreover, under QB, Ï‰(A)
and Ï‰(C) are independent whenever A and C are disjoint. By Girsanovâ€™s
theorem (see Chapter 3.5 of [14]),
â„“(B) := log
dQB
dP (Ï‰)

=
Z
D
Âµ(t)Ï‰(dt) âˆ’1
2
Z
D
Âµ2(t)Î·(t)dt = c1/2ZB âˆ’c/2.
We can then proceed, as in the proof of Theorem 2 in Section 6.2, by ana-
lyzing the behavior of U(k)
Z
under QB and using a linearization argument to
estimate Z2
B/2 by â„“(B) when ZB is close to c1/2. The details are omitted.
APPENDIX C: PROOFS OF LEMMA 1, (6.11) AND (6.6)
Proof of Lemma 1.
Let Î±B = nB/J and f(p) = Î±BÏ†(p) + (1 âˆ’Î±B) Ã—
Ï†((bp0 âˆ’Î±Bp)/(1 âˆ’Î±B)). The tangent of f at p = pB is
g(p) := Î±B{Î¸(pB)p + log[(1 âˆ’pB)/(1 âˆ’bp0)]}
+ (1 âˆ’Î±B){Î¸(epB)(bp0 âˆ’Î±Bp)/(1 âˆ’Î±B) + log[(1 âˆ’epB)/(1 âˆ’bp0)]}.
Since S(1)(B) = Jf(mB/nB) and â„“(B) = Jg(mB/nB), Lemma 1(a) follows
from the convexity of f.
Next, let K = [pB,p] if pB â‰¤p and K = [p,pB] if pB > p. Since f(pB) =
g(pB) and g is linear,
|f(p) âˆ’g(p)| â‰¤
h
sup
qâˆˆK
f â€²â€²(q)
i
(p âˆ’pB)2/2,
(C.1)
|f(p) âˆ’f(pB)| â‰¥
h
inf
qâˆˆK f â€²(q)
i
|p âˆ’pB|.
Select p = mB/nB. Since f(bp0) = f â€²(bp0) = 0 and f(pB) = c(2J)âˆ’1 = o(1), it
follows that f â€²(pB) is of order (c/J)1/2. If J|f(p)âˆ’f(pB)|(= |S(B)âˆ’c/2|) â‰¤
c1/3, then by the ï¬rst inequality of (C.1), |p âˆ’pB| = O(câˆ’1/6Jâˆ’1/2). Since

DETECTION OF SPATIAL CLUSTERING
23
|S(1)(B)âˆ’â„“(B)| = J|f(p)âˆ’g(p)| and f â€²â€² is order 1 in K, Lemma 1(b) follows
from second inequality of (C.1).
â–¡
Proof of (6.11).
The upper bound follows from Z2
C+/2 â‰¥â„“(C) for all
C. Next, observe that the constraints U(1)
Z
â‰¤c + c1/3 and log(#B) = o(c1/3)
together imply that supCâˆˆB Z2
C+ â‰¤c + 2c1/3 for all large c. Since
(#B)âˆ’1 X
CâˆˆB
(eZ2
C+/2I{Z2
C+<câˆ’2c1/3}) = o(ec/2),
the lower bound follows from applying (6.10) on
(#B)âˆ’1 X
CâˆˆB
(eZ2
C+/2I{|Z2
C+âˆ’c|â‰¤2c1/3}).
â–¡
Proof of (6.6).
Let âˆ‚B denote the boundary of B and let
âˆ‚ÎµB = {t âˆˆD :âˆ¥t âˆ’uâˆ¥â‰¤Îµ for some u âˆˆâˆ‚B}
with Îµ = câˆ’3/5.
Let B â–³C = (B \ C) âˆª(C \ B) and let B1 = {C âˆˆB :B â–³C âŠ‚âˆ‚ÎµB}, the
class of C âˆˆB that are â€œcloseâ€ to B. In Lemma 3(a) below, we show that
â„“(C) âˆ’â„“(B) can be approximated by
hB(C) :=
X
xiâˆˆC\B
[Î¸(pC)(Xi âˆ’pB) âˆ’Î¸(epC)(Xi âˆ’epB)]
(C.2)
âˆ’
X
xiâˆˆB\C
[Î¸(pC)(Xi âˆ’pB) âˆ’Î¸(epC)(Xi âˆ’epB)]
for all C âˆˆB1. We show in Lemma 3(b) that P
C /âˆˆB1 eâ„“(C)âˆ’â„“(B) is asymptoti-
cally negligible. Hence VB = log(P
CâˆˆB1 ehB(C))+o(1). But log(P
CâˆˆB1 ehB(C))
depends only on XB = {(xi,Xi):xi âˆˆâˆ‚ÎµB} and because Îµ = o(câˆ’1/2), â„“(B)
is asymptotically independent of XB. Let
Î“Î²1,Î²2(B) = {x:#(âˆ‚ÎµB) â‰¤Î²1JÎµ and #(Bâ–³C) â‰¥Î²2JÎµ for all C âˆˆB\B1}. â–¡
Lemma 3.
There exists Î²1 > 0 large enough and Î²2 > 0 small enough
such that
1 âˆ’P(Î“Î²1,Î²2(B)) = o(eâˆ’c1/3)
uniformly over B âˆˆB.
(C.3)
Moreover, for ï¬xed Î²1 > 0 and Î²2 > 0, the following holds uniformly over
x âˆˆÎ“Î²1,Î²2(B).
(a) If c/2 â‰¤â„“(B) â‰¤c/2 + c1/3 and PJ
i=1 Xi = I, then
â„“(C) âˆ’â„“(B) = hB(C) + o(1)
uniformly over C âˆˆB1.
(C.4)
(b) Let Î›(C) = {â„“(B) â‰¥(c/2) and â„“(C) â‰¥(c/2) âˆ’c1/3}. Then
P{Î›(C)|I,x} = o(eâˆ’c/2âˆ’c1/3)
uniformly over C âˆˆB \ B1.
(C.5)

24
H. P. CHAN
Proof.
Let Ïƒdâˆ’1(Â·) denote a (d âˆ’1)-dimensional volume element. By
(A2), #(âˆ‚ÎµB) âˆ¼Bin(J,q), where q âˆ¼ÎµÎ¶B and Î¶B = 2
R
âˆ‚B Î»(t)Ïƒdâˆ’1(dt). Then
P{#âˆ‚ÎµB â‰¥3Î¶BÎµJ} = o(eâˆ’Î¶BÎµJÎ·0)
for some Î·0 > 0.
(C.6)
Similarly, there exists ÎºB > 0 such that for all C âˆˆB \ B1 and J large,
#(B â–³C) âˆ¼Bin(J,qC), where qC â‰¥ÎµÎºB. Hence
P{#(B â–³C) â‰¤ÎºBÎµJ/3} = o(eâˆ’ÎºBÎµJÎ·1)
for some Î·1 > 0.
(C.7)
Since ÎµJ/c1/3 â†’âˆand log(#B) = o(c1/3), (C.3) follows from (C.6) and
(C.7).
(a) By (6.3) and (6.5),
â„“(B) = nBÏ†(pB) + (J âˆ’nB)Ï†(epB)
+ Î¸(pB)
X
xiâˆˆB
(Xi âˆ’pB) + Î¸(epB)
X
xi /âˆˆB
(Xi âˆ’epB),
â„“(C) = nC{pB log(pC/bp0) + (1 âˆ’pB)log[(1 âˆ’pC)/(1 âˆ’bp0)]}
+ (J âˆ’nC){epB log(epC/bp0) + (1 âˆ’epB)log[(1 âˆ’epC)/(1 âˆ’bp0)]}
+ Î¸(pC)
X
xiâˆˆC
(Xi âˆ’pB) âˆ’Î¸(epC)
X
xi /âˆˆC
(Xi âˆ’epB).
If c/2 â‰¤â„“(B) â‰¤c/2 + c1/3, then by (C.2),
â„“(C) âˆ’hB(C) = nC{pB log(pC/bp0) + (1 âˆ’pB)log[(1 âˆ’pC)/(1 âˆ’bp0)]}
+ (J âˆ’nC){epB log(epC/bp0)
+ (1 âˆ’epB)log[(1 âˆ’epC)/(1 âˆ’bp0)]}
+ Î¸(pC)
X
xiâˆˆB
(Xi âˆ’pB) + Î¸(epC)
X
xi /âˆˆB
(Xi âˆ’epB)
= â„“(B) + O(J(pC âˆ’pB)2) + O(c1/3|pC âˆ’pB|).
Under Î“Î²1,Î²2(B), if C âˆˆB1, then by (6.3), |pC âˆ’pB| = O(c1/2|nâˆ’1/2
B
âˆ’nâˆ’1/2
C
|) =
O(c1/2|nB âˆ’nC|Jâˆ’3/2) = O(c1/2Jâˆ’1/2Îµ) and we conclude (C.4).
(b) For given bp0 and x generated according to (A2), let QB,C be a prob-
ability measure under which X1,...,XJ are independent Bernoulli random
variables satisfying
QB,C{Xi = 1} = (pBI{xiâˆˆB} + epBI{xi /âˆˆB} + pCI{xiâˆˆC} + epCI{xi /âˆˆC})/2.
By the AM â‰¥GM inequality and (6.4),
QB,C{Xi = a} â‰¥(QB{Xi = a}QC{Xi = a})1/2,
a = 0,1.
(C.8)

DETECTION OF SPATIAL CLUSTERING
25
By (6.3) and the identity (x + y)/2 âˆ’(x1/2y1/2) = (x1/2 âˆ’y1/2)2/2, there
exists Î³ > 0 such that whenever xi âˆˆB â–³C,
QB,C{Xi = a} â‰¥ecÎ³/J(QB{Xi = a}QC{Xi = a})1/2,
a = 0,1.
(C.9)
Let C âˆˆB \ B1. By (C.8), (C.9) and the relation PË†p0{PJ
i=1 Xi = I} âˆ¼
QB,C{PJ
i=1 Xi = I},
P{Î›(C)|I,x} â‰¤(1 + o(1))EQ(B,C)(eâˆ’[â„“(B)+â„“(C)]/2âˆ’(cÎ³/J)(#Bâ–³C)IÎ›(C)|I,x)
and (C.5) holds because under Î“Î²1,Î²2(B), #(B â–³C) â‰¥Î²2JÎµ for C âˆˆB \ B1.
â–¡
To show that the second and ï¬fth lines of (6.6) are asymptotically equiv-
alent, assume without loss of generality that x âˆˆ[T
BâˆˆB Î“Î²1,Î²2(B)] for Î²1 > 0
and Î²2 > 0 satisfying (C.3). By (6.3), if P
xiâˆˆB(Xi âˆ’pB) < 0 for all B âˆˆB,
then S(1)(B) < c/2 for all B âˆˆB and hence UB < c. The condition UB â‰¥c
thus ensures that P
xiâˆˆBmax(Xi âˆ’pBmax) â‰¥0, and, consequently, â„“(Bmax) â‰¥
c/2 [see (6.5)].
Let â„¦B = {â„“(B) â‰¥c/2 and â„“(C) < (c/2) âˆ’c1/3 for all C âˆˆB \ B1} and
WB = log((#B)âˆ’1 P
CâˆˆB eâ„“(C)). By Lemma 2(a) and (C.5), there exists câ€² =
c + o(1) such that
EQ(B)(eâˆ’â„“(B)I{UBâ‰¥c,Bmax=B}|I,x)
â‰¥EQ(B)(eâˆ’â„“(B)I{câ€²+c1/3â‰¥2WBâ‰¥câ€²,Bmax=B}|â„¦B,I,x)
(C.10)
+ o((#B)âˆ’1câˆ’1/2eâˆ’c/2).
Let XB = {(xi,Xi):xi âˆˆâˆ‚ÎµB} and assume â„¦B. Then I{Bmax=B} is deter-
mined on knowing XB, and, in addition, by (C.4), VB = log(P
CâˆˆB1 ehB(C))+
o(1). Moreover, by (C.2), log(P
CâˆˆB1 ehB(C)) is determined on knowing XB
and x. Hence there exists câˆ—= c + o(1) such that
EQ(B)(eâˆ’â„“(B)I{câ€²+c1/3â‰¥2WBâ‰¥câ€²,Bmax=B}|â„¦B,I,x,XB)
â‰¥(1 + o(1))I{Bmax=B}(#B)âˆ’1eVB
(C.11)
Ã— EQ(B)(eâˆ’WBI{câˆ—/2+c1/3â‰¥WBâ‰¥câˆ—/2}|â„¦B,I,x,XB).
It follows from a local limit theorem that under QB, WB conditioned on â„¦B
has an asymptotic density of (2Ï€c)âˆ’1/2 uniformly over [câˆ—/2,câˆ—/2 + c1/3].
Replace this asymptotic density into (C.11), take expectation over XB and
substitute the remaining expression into (C.10) to obtain
EQ(B)(eâˆ’â„“(B)I{UBâ‰¥c,Bmax=B}|I,x)
â‰¥(1 + o(1))(2Ï€c)âˆ’1/2eâˆ’c/2
(C.12)
Ã— (#B)âˆ’1EQ(B)(eVBI{Bmax=B}|I,x) + o((#B)âˆ’1câˆ’1/2eâˆ’c/2).

26
H. P. CHAN
Similarly, EQ(B)(eâˆ’â„“(B)I{UBâ‰¥c+c1/3,Bmax=B}|I,x) = o((#B)âˆ’1câˆ’1/2eâˆ’c/2) and
(C.12) with the inequality reversed can be obtained. Hence the second and
ï¬fth lines of (6.6) are asymptotically equivalent.
Acknowledgments.
The author would like to thank Professor P. J. Dig-
gle for the use of the laryngeal-lung cancer datasets. He would also like to
thank the reviewers for their comments which led to improvements of the
manuscript.
REFERENCES
[1] Anderson, N. H. and Titterington, D. M. (1997). Some methods for investigating
spatial clustering, with epidemiological applications. J. Roy. Statist. Soc. Ser.
A 160 87â€“105.
[2] Begun, J. M., Hall, W. J., Huang, W. M. and Wellner, J. A. (1983). In-
formation and asymptotic eï¬ƒciency in parametricâ€“nonparametric models. Ann.
Statist. 11 432â€“452. MR0696057
[3] Chan, H. P. and Tu, I. (2009). P-value computations for cluster detection with
covariate adjustments. Technical report, National Univ. Singapore.
[4] Chan, H. P. and Zhang, N. R. (2009). Local average likelihood ratio test statis-
tics with applications in genomics and change-point detection. Technical report,
National Univ. Singapore.
[5] Cressie, N. (1993). Statistics for Spatial Data. Wiley, New York. MR1239641
[6] Cuzick, J. and Edwards, R. (1990). Spatial clustering for inhomogeneous popula-
tions (with discussions). J. Roy. Statist. Soc. Ser. B 52 73â€“104. MR1049303
[7] Diggle, P. J. and Chetwynd, A. G. (1991). Second-order analysis of spatial clus-
tering for inhomogeneous populations. Biometrics 47 1155â€“1163.
[8] Diggle, P. J., Gatrell, A. C. and Lovett, A. A. (1990). Modelling the prevalence
of cancer of the larynx in part of Lanchashire: A new methodology for spatial
epidemiology. In Spatial Epidemiology. Pion, London.
[9] Diggle, P. J. and Marron, J. S. (1988). Equivalence of smoothing parameter
selectors in density and intensity estimation. J. Amer. Statist. Assoc. 83 793â€“
800. MR0963807
[10] Dwass, M. (1957). Modiï¬ed randomization tests for nonparametric hypotheses. Ann.
Math. Statist. 28 181â€“187. MR0087280
[11] Edgington, E. S. (1995). Randomization Tests, 3rd ed. Marcel Dekker, New York.
[12] Gangnon, R. and Clayton, M. (2001). A weighted average likelihood ratio test for
spatial clustering of disease. Stat. Med. 20 2977â€“2987.
[13] Haining, R. (2003). Spatial Data Analysis: Theory and Practice. Cambridge Univ.
Press, Cambridge.
[14] Karatzas, I. and Shreve, S. (1991). Brownian Motion and Stochastic Calculus.
Springer, New York. MR1121940
[15] Kulldorff, M. (1997). A spatial scan statistic. Comm. Statist. Theory Methods 26
1481â€“1496. MR1456844
[16] Kulldorff, M. and Information Management Services Inc. (2009). SaTScan
user guide. Available at http://www.satscan.org/techdoc.html.
[17] Kulldorff, M. and Nagarwalla, N. (1995). Spatial disease clusters: Detection
and inference. Stat. Med. 14 799â€“810.

DETECTION OF SPATIAL CLUSTERING
27
[18] Kulldorff, M., Tango, T. and Park, P. (2003). Power comparisons for disease
clustering tests. Comput. Statist. Data Anal. 42 665â€“684. MR1977177
[19] Lai, T. L. and Siegmund, D. (1977). A nonlinear renewal theory with applications
to sequential analysis I. Ann. Statist. 5 946â€“954. MR0445599
[20] Lai, T. L. and Siegmund, D. (1979). A nonlinear renewal theory with applications
to sequential analysis II. Ann. Statist. 7 60â€“76. MR0515684
[21] Loader, C. (1991). Large-deviation approximation to the distribution of scan statis-
tics. Adv. in Appl. Probab. 23 751â€“771. MR1133726
[22] Murphy, S. and van der Vaart, A. W. (2000). On proï¬le likelihood. J. Amer.
Statist. Assoc. 95 449â€“465. MR1803168
[23] Naus, J. I. (1965). Clustering of random points in two dimensions. Biometrika 52
263â€“267. MR0211433
[24] Neill, D., Moore, A. W. and Cooper, G. (2006). A Bayesian spatial scan statistic.
In Advances in Neural Information Processing Systems (Y. Weiss, B. Scholkopf,
J. Platt, eds.) 18 1003â€“1010. MIT Press, Boston, MA.
[25] Patil, G. P. and Taillie, C. (2004). Upper level set scan statistic for detecting
arbitrarily shaped hot-spots. Environ. Ecol. Stat. 11 183â€“197. MR2086394
[26] Rabinowitz, D. (1994). Detecting Clusters in Disease Incidence. IMS Lecture Notesâ€“
Monograph Series 23 255â€“275. IMS, Hayward, CA. MR1477929
[27] Rabinowitz, D. and Siegmund, D. (1997). The approximate distribution of the
maximum of a smoothed Poisson random ï¬eld. Statist. Sinica 7 167â€“180.
MR1441152
[28] Siegmund, D. (2001). Is peak height suï¬ƒcient? Genetic Epidemiology 20 403â€“408.
[29] Stoyan, D. and Penttinen, A. (2000). Recent applications of point process methods
in forestry studies. Statist. Sci. 15 16â€“78. MR1842237
[30] Tango, T. and Takahashi, K. (2005). A ï¬‚exibly shaped spatial scan statistic for
detecting clusters. J. Internat. Health Geographics 4 4â€“11.
[31] Waller, L. A. and Gotway, C. A. (2004). Applied Spatial Statistics for Public
Health Data. Wiley, New York. MR2075123
[32] Woodroofe, M. (1978). Large deviations of the likelihood ratio statistics with ap-
plications to sequential testing. Ann. Statist. 6 72â€“84. MR0455183
[33] Woodroofe, M. (1982). Nonlinear Renewal Theory in Sequential Analysis. SIAM,
Philadelphia, PA. MR0660065
Department of Statistics
and Applied Probability
National University of Singapore
6 Science Drive 2
Singapore 117546
E-mail: stachp@nus.edu.sg
